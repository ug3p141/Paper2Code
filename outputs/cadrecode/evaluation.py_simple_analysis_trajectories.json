[{"role": "system", "content": "You are an expert researcher, strategic analyzer and software engineer with a deep understanding of experimental design and reproducibility in scientific research.\nYou will receive a research paper in JSON format, an overview of the plan, a design in JSON format consisting of \"Implementation approach\", \"File list\", \"Data structures and interfaces\", and \"Program call flow\", followed by a task in JSON format that includes \"Required packages\", \"Required other language third-party packages\", \"Logic Analysis\", and \"Task list\", along with a configuration file named \"config.yaml\". \n\nYour task is to conduct a comprehensive logic analysis to accurately reproduce the experiments and methodologies described in the research paper. \nThis analysis must align precisely with the paper\u2019s methodology, experimental setup, and evaluation criteria.\n\n1. Align with the Paper: Your analysis must strictly follow the methods, datasets, model configurations, hyperparameters, and experimental setups described in the paper.\n2. Be Clear and Structured: Present your analysis in a logical, well-organized, and actionable format that is easy to follow and implement.\n3. Prioritize Efficiency: Optimize the analysis for clarity and practical implementation while ensuring fidelity to the original experiments.\n4. Follow design: YOU MUST FOLLOW \"Data structures and interfaces\". DONT CHANGE ANY DESIGN. Do not use public member functions that do not exist in your design.\n5. REFER TO CONFIGURATION: Always reference settings from the config.yaml file. Do not invent or assume any values\u2014only use configurations explicitly provided.\n     \n"}, {"role": "user", "content": "## Paper\n{'paper_id': 'cadrecode', 'title': 'CAD-Recode: Reverse Engineering CAD Code from Point Clouds', 'abstract': 'Computer-Aided Design (CAD) models are typically constructed by sequentially drawing parametric sketches and applying CAD operations to obtain a 3D model. The problem of 3D CAD reverse engineering consists of reconstructing the sketch and CAD operation sequences from 3D representations such as point clouds. In this paper, we address this challenge through novel contributions across three levels: CAD sequence representation, network design, and training dataset. In particular, we represent CAD sketch-extrude sequences as Python code. The proposed CAD-Recode translates a point cloud into Python code that, when executed, reconstructs the CAD model. Taking advantage of the exposure of pre-trained Large Language Models (LLMs) to Python code, we leverage a relatively small LLM as a decoder for CAD-Recode and combine it with a lightweight point cloud projector. CAD-Recode is trained on a procedurally generated dataset of one million CAD sequences. CAD-Recode significantly outperforms existing methods across the DeepCAD, Fusion360 and realworld CC3D datasets. Furthermore, we show that our CAD Python code output is interpretable by off-the-shelf LLMs, enabling CAD editing and CAD-specific question answering from point clouds.', 'pdf_parse': {'paper_id': 'cadrecode', 'abstract': [{'text': 'Computer-Aided Design (CAD) models are typically constructed by sequentially drawing parametric sketches and applying CAD operations to obtain a 3D model. The problem of 3D CAD reverse engineering consists of reconstructing the sketch and CAD operation sequences from 3D representations such as point clouds. In this paper, we address this challenge through novel contributions across three levels: CAD sequence representation, network design, and training dataset. In particular, we represent CAD sketch-extrude sequences as Python code. The proposed CAD-Recode translates a point cloud into Python code that, when executed, reconstructs the CAD model. Taking advantage of the exposure of pre-trained Large Language Models (LLMs) to Python code, we leverage a relatively small LLM as a decoder for CAD-Recode and combine it with a lightweight point cloud projector. CAD-Recode is trained on a procedurally generated dataset of one million CAD sequences. CAD-Recode significantly outperforms existing methods across the DeepCAD, Fusion360 and realworld CC3D datasets. Furthermore, we show that our CAD Python code output is interpretable by off-the-shelf LLMs, enabling CAD editing and CAD-specific question answering from point clouds.', 'section': 'Abstract', 'sec_num': None}], 'body_text': [{'text': \"Computer-Aided Design (CAD) modeling is the standard approach for designing manufactured objects, ranging from furniture to mechanical components [3, 30] . However, creating a 3D CAD model is a time-consuming task that demands specialized expertise, as the model must not only capture the object's shape but also maintain its functional requirements-commonly referred to as the design intent [4, 27] . To streamline this process, 3D CAD reverse engineering aims at generating CAD models directly from 3D scanned objects, offering a faster and more accessible pathway to CAD creation [17] . Automated 3D CAD reverse engineering has a long history in the fields of computer vision and graphics [13, 43] , with goals evolving alongside advancements in the field. These objectives have progressed from identifying CAD parts in 3D point clouds [43] to predicting the sequence of steps a designer may take to recreate a 3D scanned object in CAD software [21, 34] . This latter goal is particularly appealing, as it aims not only to produce a final CAD parametric model but also to capture the design steps behind it, enabling further editing within CAD software [21, 45] . In CAD software, designers typically construct their CAD model as feature-based design sequences, where a sequence of 2D sketches is transformed into 3D objects via opera-tions such as extrusion and revolution [47, 50] . Following the release of large CAD datasets [7, 22, 47] , recent works have focused on learning feature-based CAD sequences from input point clouds, specifically as sketchextrude sequences [12, 21, 28, 33, 39, 45, 48] . As depicted in Figure 1 (a), although varying in methodology, these approaches share a common pipeline: (1) crafting a CAD sketch-extrude sequence representation, (2) converting raw CAD data [22, 47] into this format, and (3) training dedicated neural networks to output these representations from input point clouds.\", 'section': 'Introduction', 'sec_num': '1.'}, {'text': 'Despite recent advances in feature-based CAD reverse engineering, key limitations constrain the broader applicability of existing approaches. Firstly, existing methods often use customized CAD representations, such as custom CAD languages [12, 21, 34, 48] or simplified extrusion shapes [28, 39, 45] , to facilitate model training. These representations are difficult to interpret, require postprocessing to be compatible with CAD tools, and restrict design capabilities to basic operations. Secondly, these approaches typically rely on designing networks that output language-like CAD representations [12, 21] and training them from scratch. This requires the networks to learn not only the geometry of the point clouds, but also the syntax of the CAD sequence representation.', 'section': 'Introduction', 'sec_num': '1.'}, {'text': 'In this paper, we pose the following question: In view of the recent breakthrough performance of Large Language Models (LLMs), how can their advanced language understanding be leveraged for CAD reverse engineering?', 'section': 'Introduction', 'sec_num': '1.'}, {'text': 'To address this question, we base our approach on three key observations: (1) LLMs can generate valid Python code [36, 55] , (2) modern CAD software increasingly supports modeling through Python scripting [10] , and (3) recent efforts have shown that LLMs can be fine-tuned to process point clouds [49, 61] . As shown in Figure 1 (b), we propose CAD-Recode, a solution for CAD reverse engineering by fine-tuning an LLM to map input point clouds into CAD sketch-extrude sequences represented as Python code. In particular, instead of crafting a CAD representation, we base our representation on the existing Python CadQuery library [10] . This code-based representation is not only interpretable but also inherently allows for incorporating modular CAD features and design practices such as reusing design elements and abstracting low-level design steps (e.g. 3D box to represent a four-line sketch of a square and its extrusion). To learn the mapping between point clouds and CAD Python code, we fine-tune a pre-trained LLM, Qwen2-1.5B [55], augmented with a lightweight, trainable point cloud projector. To train CAD-Recode, a potential approach could be using existing sketch-extrude datasets [47, 48] and converting them to Python CadQuery code. However, these datasets are limited in size and design features included due to the efforts required to con-vert their original proprietary representation into one that is suitable for learning. As a solution, we propose a procedurally generated training dataset composed of one million CAD sketch-extrude sequences as Python CadQuery code. This dataset consists of CadQuery Python scripts generated following predefined heuristics with randomized parameter selection. The execution of each generated script results in a parametric CAD model. Unlike existing CAD datasets, this procedurally generated dataset provides an alternative for learning the mapping between point clouds and CAD sketch-extrude sequences in Python code, with full control over the design features, patterns and dataset size included during training. Our contributions can be summarized to: \u2022 A CAD sketch-extrude sequence representation in Python code using CadQuery [10] for CAD reverse engineering.', 'section': 'Introduction', 'sec_num': '1.'}, {'text': '\u2022 CAD-Recode, the first LLM-based CAD reverse engineering model designed to predict CAD Python code from point clouds. The model, consisting of a pre-trained LLM and a point cloud projector is trained end-to-end to generate code that reconstructs the input geometry. \u2022 A one million procedurally generated training dataset of CAD sketch-extrude sequences as CadQuery Python code. This provides precise control over dataset size, features, and design patterns included during training, re-', 'section': 'Introduction', 'sec_num': '1.'}, {'text': 'sulting in significant performance improvement. We will make this dataset publicly accessible. \u2022 Extensive experiments on three publicly available datasets show that CAD-Recode achieves substantial improvements over state-of-the-art methods in CAD reverse engineering. Moreover, we show that CAD-Recode, when operating on point clouds and generating CAD code, can be integrated with an off-the-shelf LLM to perform CAD Question Answering (CAD-QA) and CAD editing from point clouds. Paper Organization: The rest of the paper is organized as follows. Section 2 reviews related works. Section 3 introduces the CAD code representation and the proposed synthetic dataset. CAD-Recode is formulated and described in Section 4. Experiments are presented in Section 5. Finally, conclusions and future works are given in Section 6.', 'section': 'Introduction', 'sec_num': '1.'}, {'text': 'LLM, Point Cloud and CAD: Recent works have explored integrating point clouds with LLMs for various tasks, including 3D generation [56, 62] , captioning [16, 18, 49] , and question answering [6, 19] . These approaches typically employ complex point cloud encoders, either aligning with CLIP embeddings [31, 53, 54, 61, 64] or directly with LLM feature spaces [49] . Such methods require two-stage training: first pre-training the point cloud encoder, then finetuning with the LLM through instruction-based prompts.', 'section': 'Related Works', 'sec_num': '2.'}, {'text': \"In parallel, recent works have started exploring LLMs' capabilities in a range of CAD-related tasks. Reparam-CAD [23] infers shape variations from parametric models and text descriptions, while CADTalk [60] generates semantic descriptions of CAD parts. The works in [1, 2] focus on the generation of CAD models from text using LLMs, and SGP-Benchmark [38] evaluates LLMs' understanding of CAD sketch-extrude sequences using CADspecific question answering. While Img2CAD [57] attempts CAD reverse engineering from images using GPT-4V [36] , it still requires a separate transformer for parameter inference. In contrast, CAD-Recode introduces the first approach for point cloud to CAD reconstruction combining point clouds with the sequence modeling capabilities of pre-trained LLMs.\", 'section': 'Related Works', 'sec_num': '2.'}, {'text': 'CAD Reverse Engineering from Point Cloud: CAD reverse engineering aims to reconstruct parametric CAD models from 3D shapes (e.g., meshes or point clouds) in a compatible representation with CAD software. A key challenge lies in the choice of this representation. A line of works attempts to address sub-problems of the CAD reverse engineering task by focusing on parameter estimation for edges and surface primitives [8, 9, 15, 26, 32, 42, 46, 63] or reconstructing B-Rep construction history [11, 24, 47, 50] .', 'section': 'Related Works', 'sec_num': '2.'}, {'text': 'In order to obtain a representation that is closer to CAD modelling, several methods [14, 20, 29, 58, 59 ] use Constructive Solid Geometry (CSG), representing models as compositions of 3D primitives and Boolean operations. While this enables reconstruction, the CSG representation diverges from modern CAD workflows [50] .', 'section': 'Related Works', 'sec_num': '2.'}, {'text': 'Recent works have adopted the more CAD-aligned sketch-extrude representation, introduced by Deep-CAD [48] for CAD generation [51, 52] or predicting extrusion cylinder [39, 45] . Considering the sequential nature of sketch-extrude operations, methods have explored a template-based approach [25] given a rounded voxel input representation. Furthermore, transformer architectures have been investigated for both autoregressive [21] and non-autoregressive [12, 48] prediction of sketch-extrude sequences from point clouds. The work in [34] combines a lightweight pre-trained language model [40] with a point cloud encoder using a diffusion-based approach. Alternative methods using self-supervised [28] or unsupervised [29] learning still face integration challenges due to their non-standard sketch representations (e.g., signed distance functions). In contrast to these approaches that require full parameter learning of specialized networks for both CAD geometry and representation syntax, we leverage pre-trained LLMs that have been exposed to programming patterns through large-scale training on code repositories. Our method outputs Python code using the CadQuery library [10] that is directly executable and can easily be interpreted. Additionally, we address the data limitation through automated generation of a large-scale training dataset, enabling full control over design features included during training. Modern feature-based CAD modeling relies on sequences of 2D sketches and operations to create 3D models. Designers first draw geometric primitives (lines, arcs, circles) on a selected plane, then apply operations like extrusion or revolution to generate 3D geometry [50] . As depicted in Figure 2 (a), we focus on sketch-extrusion sequences, a fundamental CAD modeling pattern widely adopted in previous works [21, 48, 51] . Below, we present our CAD representation, highlighting its advantages over existing language-like encodings, and describe our procedurally generated training data.', 'section': 'Related Works', 'sec_num': '2.'}, {'text': 'Recent approaches in CAD language modeling [12, 21, 33, 48, 51] encode sketch-extrude sequences as numerical vectors representing features and their parameters as shown in Figure 2(b) . However, this representation constrains the modeling to specific CAD practices, lacks interpretability, and requires post-processing for CAD kernel compatibility. We propose using CadQuery [10] Python code to represent sketch-extrude sequences for CAD reverse engineering, offering the following advantages:', 'section': 'CadQuery Code', 'sec_num': '3.1.'}, {'text': 'Modularity of CAD Features and Design Practices: Existing language-based CAD reverse engineering methods rely on custom representations of low-level geometric features (lines, arcs, circles) for sketch construction [41, 48] . This approach inherently limits the range of implementable features and design practices. In contrast, CadQuery provides comprehensive built-in CAD functionality, encom-passing both low-level features and higher-level geometries like cylinders and boxes as shown in Figure 2(c ). Furthermore, its programmatic nature enables variable reuse and code modularity. This allows reusing common design features or practices across models, as illustrated by the shared center coordinates across two circles in Figure 2 (c) . This representation naturally accommodates diverse CAD features and design practices without requiring complex custom encodings or post-processing steps. The training of current CAD sketch-extrude reverse engineering methods [12, 21, 33, 34, 48] predominantly rely on datasets collected from CAD model repositories [7, 22, 47] . Considerable efforts are required to parse the CAD models from their original proprietary representations to a suitable one for deep learning [47, 48] . As a result, existing datasets are restricted not only in scale, but also in control over the design features and patterns included in training.', 'section': 'CadQuery Code', 'sec_num': '3.1.'}, {'text': 'To address these limitations, we propose to procedurally generate a training dataset of one million CAD models in the form of sketch-extrude sequences written in Python CadQuery [10] code. Our proposed pipeline randomly generates sketch and CAD operation parameters guided by topological and geometrical heuristics to ensure control over the amount of generated models and the features in the generated codes. The algorithm outlining the steps of this generation pipeline is provided in the supplementary materials along with further statistical analysis of the generated dataset. The modularity of CAD features is incorporated by utilizing both low-level primitives (i.e. circles, lines, and arcs) and their abstractions (i.e. boxes, cylinders, and rectangles) as well as reusing design elements within the generated sequences. In this work, we focus on some aspects of modularity (i.e., reusing point coordinates, extrusion planes, and abstracting basic shapes such as boxes and cylinders). Further modularity features (e.g., reusing functions corresponding to arbitrary CAD parts, additional CAD operations) can also be integrated in the future. Note that although our generated dataset does not include sequences from human-designed CAD models, it offers significant control over the features and design patterns to which the network is exposed during training. Examples of generated CAD models are shown in Figure 3 .', 'section': 'Procedurally Generated Training Dataset', 'sec_num': '3.2.'}, {'text': 'Building on the introduced CAD code representation and generated training dataset outlined in the previous section, this section introduces CAD-Recode, our proposed model for predicting CAD sketch-extrude sequences as code from input 3D point clouds. We formalize the problem of CAD code prediction, describe the architecture of CAD-Recode, and detail its training and inference processes.', 'section': 'CAD-Recode', 'sec_num': '4.'}, {'text': 'Let us denote the set of all possible code strings as \u03a3 * , where each code string is composed of elements from the finite set of alphanumeric characters and operators in the programming language \u03a3. Let \u03d5 syn : \u03a3 * \u2192 {True, False} represent the syntactic validation function for Python programming rules (e.g., variable declarations, expression syntax, and statement structure), and \u03d5 cad : \u03a3 * \u2192 {True, False} denote the validation function for CAD-specific rules. The latter includes the syntactic validity of the code w.r.t. to the CAD library, i.e. CadQuery [10] , and the geometric validity of the reconstructed model from the code (e.g., an extrusion can only be applied on a closed loop of 2D primitives, a circle radius cannot be negative). An executable valid CAD code can be formally described by a code string C \u2208 C, where', 'section': 'Problem Statement', 'sec_num': '4.1.'}, {'text': 'C = {w \u2208 \u03a3 * | \u03d5 syn (w) \u2227 \u03d5 cad (w)} ,', 'section': 'Problem Statement', 'sec_num': '4.1.'}, {'text': 'represents the set of all valid CAD codes. This formulation ensures that any code string w in C satisfies both the syntactic requirements of Python (\u03d5 syn ) and the CAD code validation rules (\u03d5 cad ). Let P = {p i } n i=1 \u2208 R n\u00d73 denote an input point cloud, where each point p i \u2208 R 3 represents 3D Cartesian coordinates. The objective of CAD-Recode is to learn a mapping', 'section': 'Problem Statement', 'sec_num': '4.1.'}, {'text': \"... Point Cloud CAD model <s> import cadquery ... extrude(15) Large Language Model import ... Python interpreter Tokenizer ... ... Linear Layer finalize().extrude(15)<e> \u03a8 : R n\u00d73 \u2192 C, C = \u03a8(P) , that maps the input point cloud to a valid CAD code C \u2208 C such that the code, when executed, produces a CAD model geometrically approximating the input point cloud P. Note that the CAD code execution results in a Boundary-Representation (B-Rep) [24]. Unlike meshes or point clouds, B-Rep is a parametric representation of the CAD model's geometry, enabling seamless integration into modern CAD software and allowing for further modifications. The goal of CAD-Recode is to infer the CAD code describing the design steps of the CAD model, that when executed results in a B-Rep.\", 'section': 'Problem Statement', 'sec_num': '4.1.'}, {'text': 'CAD-Recode builds on pre-trained LLMs and their prior exposure to Python code, augmenting these with point cloud processing capabilities and CAD-specific Python code knowledge. As shown in Figure 4 , its architecture consists of two components: (1) a point cloud projector mapping the 3D point cloud into learnable tokens, and (2) a pretrained LLM-based auto-regressive CAD code decoder.', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': 'Point Cloud Projection Module: CAD-Recode introduces a lightweight projection module \u03a8 p that directly maps a dense point cloud P \u2208 R n\u00d7dp , where d p = 3 corresponds to the dimension of point coordinates, into a sequence of n p \u226a n query tokens', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': 'Q p = [q 1 p , . . . , q np p ] \u2208 R np\u00d7dq , of embedding dimension d q .', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': 'The point cloud projector, trained in an end-to-end manner with the CAD code decoder module, consists of three simple components:', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': '(1) furthest point sampling to downsample the input point clouds to n p points, (2) Fourier positional encoding [62] of coordinates, and (3) a linear layer projecting the encoded coordinatesinto Q p .', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': \"LLM as CAD Code Decoder: Our CAD code decoder, denoted as \u03a8 LLM , adapts a pre-trained LLM for the specific task of CAD code generation. We leverage the Qwen2-1.5B model [55] as our LLM backbone, chosen for its balanced trade-off between model capacity and computational re-quirements. The decoder's input consists of point query tokens Q p from the point cloud projector, augmented with n t code tokens Q t \u2208 R nt\u00d7dq obtained by tokenizing the input code as in [55]. The complete input sequence is denoted as\", 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': '[Q p ; Q t ] \u2208 R (np+nt)\u00d7dq', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': ', where semicolon indicates concatenation along the sequence dimension. The LLM decoder generates the CAD code sequence through next-token prediction. As in [55], each predicted token is mapped to a symbol from the vocabulary \u03a3, which includes alphanumeric characters and operators.', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': \"Overall, CAD-Recode repurposes the LLM's sequence modeling capabilities for the specialized task of translating geometric point clouds into executable CAD code.\", 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': 'Training Strategy: Our training process consists of a single stage. The model operates on query tokens of dimension d q = 1536 and processes input point clouds downsampled to n p = 256 points. Gaussian noise with mean zero and standard deviation of 0.01 is added to the coordinates of the input points with a probability of 0.5 per model. The network is trained on the procedurally generated CAD codes, hence exposed to the CAD features and design practices that were included in the algorithm. The training objective minimizes the Negative Log-Likelihood (NLL) of the target CAD code sequence, using special tokens (<s> and <e>) to demarcate sequence boundaries. The point cloud projector \u03a8 p learns geometric features from scratch, while the pre-trained decoder \u03a8 LLM is fine-tuned for CAD code generation.', 'section': 'Training and Inference Details', 'sec_num': '4.3.'}, {'text': 'Inference Strategy: At inference time, the point cloud projector \u03a8 p processes the input point cloud P to generate query tokens Q p , which are then fed to the decoder along with the start token <s>. The model autoregressively generates CAD code tokens until producing a complete code sequence C ending with token <e>. Following [21] , we employ a test-time sampling approach where we generate ten distinct CAD code candidates, each from a different sampling of the input point cloud. For each candidate, we sam- ', 'section': 'Training and Inference Details', 'sec_num': '4.3.'}, {'text': 'In order to validate the effectiveness of CAD-Recode, we conduct a series of experiments across two different scenarios. The first scenario focuses on the reverse engineering task, where the goal is to reconstruct a CAD sketch-extrude sequence in Python code from a given input point cloud.', 'section': 'Experiments', 'sec_num': '5.'}, {'text': 'The second assesses the interpretability and editibility of the generated CAD code with a proprietary LLM [36] .', 'section': 'Experiments', 'sec_num': '5.'}, {'text': 'Experimental Setup: CAD-Recode is evaluated on three test datasets: DeepCAD [48] (8046 models), Fu-sion360 [47] (1725 models), and the real-world CC3D [35] (2973 models). The point clouds are obtained by sampling points on the meshes for DeepCAD and Fusion360. The CC3D dataset provides a real-world scenario with input point clouds sampled from actual 3D scans of CAD models containing surface noise, smoothed edges and missing parts (see supplementary materials for more details). Implementation details are provided in the supplementary.', 'section': 'Reverse Engineering', 'sec_num': '5.1.'}, {'text': 'To evaluate the quality of the predicted CAD sketch-extrude sequences, we use three metrics: Chamfer Distance (CD) [21] , Intersection over Union (IoU) [34] , and Invalidity Ratio (IR) [48] . We report both mean and median CD values computed using 8192 points to assess geometric accuracy. Reported CD values have been multiplied by 10 3 . The IoU is computed from the resulting CAD model meshes and expressed as a percentage. The IR indicates the percentage of generated sequences that fail to produce a valid CAD model.', 'section': 'Metrics:', 'sec_num': None}, {'text': 'Results & Analysis: Table 1 presents results on the test sets of DeepCAD and Fusion360 datasets, where CAD-Recode establishes new state-of-the-art performance across all metrics. Note that the results of stateof-the-art methods in Table 1 are borrowed from [34] , except for CAD-SIGNet [21] , MultiCAD [33] , Tran-sCAD [12] , and DeepCAD [48] which were taken from [21] and [12] . First, we convert the DeepCAD dataset (160 k models) to CadQuery Python code and use it to train CAD-Recode (results are in row before last of Table 1 ). When trained on DeepCAD dataset as existing methods, CAD-Recode outperforms them in almost all metrics. These results showcase the effectiveness of CAD-Recode and the proposed CAD code representation.', 'section': 'Metrics:', 'sec_num': None}, {'text': 'Training on 1 M generated samples results in substantial improvements in CD and IoU metrics while maintaining a negligibly low invalidity ratio (last row of Table 1 ), reflecting significantly better geometric fidelity in the predicted CAD models. CAD-Recode demonstrates a ten-fold improvement in mean CD and an increase of IoU by over 10% on both DeepCAD and Fusion360 datasets compared to the existing best methods. These results confirm that our largescale procedurally generated training dataset provides substantial benefits.', 'section': 'Metrics:', 'sec_num': None}, {'text': 'As illustrated in Figure 5 , this translates to consistent reconstruction quality, where CAD-Recode reliably produces CAD models that accurately capture the geometry from the input point cloud. In contrast, CAD-SIGNet [21] can generate shapes that deviate significantly from the target geometry, further highlighting the advantages of our approach.', 'section': 'Metrics:', 'sec_num': None}, {'text': 'In Table 2 , we evaluate DeepCAD Dataset Fusion360 Dataset Real-world CC3D Dataset Point Cloud CAD-SIGNet CAD-Recode GT Figure 5. Qualitative results on the DeepCAD, Fusion360, and CC3D datasets. For each input point cloud (first row), we compare CAD models produced by CAD-SIGNet (second) and our CAD-Recode trained on our dataset (third) with a ground truth CAD model (bottom row). While CAD-SIGNet often fails to restore the general shape, CAD-Recode outputs only slightly deviate from ground truth in most cases. Method Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 DeepCAD [48] -263 -12.7 CAD-SIGNet [21] 14.82 2.90 42.6 2.5 CAD-Recode 0.76 0.31 74.2 0.3 Table 2. Results on the CC3D dataset, where input point clouds are sampled from real 3D scans. CAD-Recode significantly outperforms DeepCAD, and CAD-SIGNet.', 'section': 'Real-world Scenario:', 'sec_num': None}, {'text': 'CAD-Recode on the real-world CC3D dataset, where input point clouds are sampled from 3D scans and contain artifacts such as surface noise, smooth edges, and missing parts. Even under these challenging conditions, our method achieves significant improvements over CAD-SIGNet [21] , with a 89% lower median CD and a 30% higher IoU, while maintaining a low IR. From the CC3D qualitative results in Figure 5 , CAD-Recode is able to recover geometries that are much closer to the ground truth than current state-of-the-art. However, it can be observed that CAD-Recode still lacks the expressiveness to model complex shapes that contain operations beyond the extrusion operation such as revolution and fillet. This can be attributed to the choice of features and design practices in the procedurally generated training dataset. Nevertheless, we believe that this can be addressed in future works by incorporating further features in the dataset generation procedure. Our results on CC3D are compared with methods previously reported for this dataset [21] , namely CAD-SIGNet and DeepCAD.', 'section': 'Real-world Scenario:', 'sec_num': None}, {'text': 'Ablation Study: To evaluate the different components of CAD-Recode, we conduct a comprehensive ablation study on the amount of training data, test-time sampling, and the number of input points and model parameters.', 'section': 'Real-world Scenario:', 'sec_num': None}, {'text': 'Training CAD-Recode on 160 k procedurally generated samples using the method described in Section 3.2 leads to significant improvements in geometric fidelity of the predicted samples over training on the DeepCAD dataset with the same amount of data (see row 2 and 3 of Table 3 ). Furthermore, scaling our training dataset to 1 M samples provides further improvements across all datasets (row 4 of Table 3 ). As compared to DeepCAD training dataset, our procedural dataset generation provides a better way of learning the mapping between point clouds and CAD codes which can be further improved by scaling up the dataset size.', 'section': 'Real-world Scenario:', 'sec_num': None}, {'text': 'We investigate the effectiveness of the test-time sampling approach that generates multiple CAD code predictions through different point cloud samplings, as described in Section 4.3. As shown in the third and last row of Table 3 , the test-time sampling approach mainly helps reducing the ratio of invalid predicted CAD codes (IR). For comparison, CAD-SIGNet [21] employs a probability-based sampling. Yet, even without test-time sampling our method still performs better on the reconstruction metrics than CAD-SIGNet [21] .', 'section': 'Real-world Scenario:', 'sec_num': None}, {'text': 'Results in Table 4 show an ablation of the input point cloud size and the number of parameters of the LLM backbone. It can be observed that using an input point cloud of 256 points and Qwen1.5b results in the highest IoU. This setting with a relatively small input point cloud and lightweight LLM backbone provides the best balance between prediction accuracy and memory requirements. Results on all metrics are included in the supplementary materials.', 'section': 'Real-world Scenario:', 'sec_num': None}, {'text': \"CAD-QA and LLM Interpretability: CAD SGP-Bench [38] quences encoded as in DeepCAD [48] . These questions require analyzing various geometric aspects, such as relative sizes and 3D primitive types. We extend this benchmark to evaluate CAD reverse engineering methods by using point clouds as input instead of CAD sequences. Our evaluation follows a two-stage process: first predicting sketch-extrude sequences from point clouds as CadQuery code with CAD-Recode, then using GPT-4o [36] to answer CAD-specific questions. Without requiring additional interpretation hints, our approach achieves 76.5% accuracy on this CAD-QA task (Table 5 ). For comparison, we evaluate two baseline approaches: CAD-SIGNet [21] and PointLLM [49] . When using CAD-SIGNet's output with GPT-4o, even with provided interpretation hints explaining the sequence format, the accuracy reaches only 63.2%.\", 'section': 'CAD-QA and Editability', 'sec_num': '5.2.'}, {'text': 'PointLLM, which directly processes point clouds for language tasks, achieves 42.3% accuracy when prompted with the CAD-specific questions. These results demonstrate that CAD-Recode effectively captures CAD geometric information while generating an output in a format that proprietary LLMs can naturally interpret and process.', 'section': 'CAD-QA and Editability', 'sec_num': '5.2.'}, {'text': 'Editing Pipeline: Leveraging the interpretable nature of our code-based output, we present an automated editing pipeline using GPT-4o [36] . Through a simple prompt, the system refactors the generated code to expose geometric parameters via interactive sliders, enabling direct manipulation of the reconstructed model. As shown in Figure 6 , the resulting code can be directly executed in a Python environment to provide an interactive editing interface. Implementation details are provided in the supplementary materials. ', 'section': 'CAD-QA and Editability', 'sec_num': '5.2.'}, {'text': 'This work rethinks the problem of feature-based CAD reverse engineering by approaching it through pre-trained LLMs taking advantage of CAD Python-based representation. Our key contributions include a new CAD code representation for reverse engineering sketch-extrude sequences, very large-scale procedurally generated training dataset in the form of CAD programs, and a point cloud-to-CAD code model. We demonstrate that CAD-Recode outperforms existing methods by a large margin on three datasets, including the real-world CC3D dataset. We also showcase that combining pre-trained LLMs with geometric understanding enables powerful new workflows, where designers can reconstruct CAD models from point clouds and modify them through natural language. We believe that this work will open new perspectives for CAD reverse engineering.', 'section': 'Conclusion', 'sec_num': '6.'}, {'text': 'We identify the following interesting future works: (1) further exploiting the modularity of the proposed CAD code representation, (2) scaling up the LLM and the dataset to enable reverse engineering of more complex CAD models.', 'section': 'Conclusion', 'sec_num': '6.'}, {'text': 'Acknowledgement: The present project is supported by the National Research Fund, Luxembourg under the BRIDGES2021/IS/16849599/FREE-3D and IF/17052459/CASCADES projects, and by Artec 3D.', 'section': 'Conclusion', 'sec_num': '6.'}, {'text': 'The CAD-Recode implementation uses Qwen2-1.5B as the LLM decoder. The training configuration employs the AdamW optimizer with a learning rate of 0.0002 and weight decay of 0.01, while maintaining other parameters at their default values from the HuggingFace implementation [44] , including the cosine learning rate scheduler. The training process is conducted for 100 k iterations, incorporating an initial warmup period of 1 k iterations. Using a single NVIDIA H100 GPU with a batch size of 18, the complete training process takes approximately 12 hours. For ablation study examining decoder size impact (Section 5.1 of the main paper), we utilize Qwen2-0.5B.', 'section': 'Appendix A. Training Details', 'sec_num': None}, {'text': 'In Section 3.2, the procedurally generated training dataset is presented. The main advantage of generating data over using the existing DeepCAD dataset for training is that the algorithm allows full control over the amount of data as well as the features and design patterns that the network is exposed to during training. We generate one million valid Python CadQuery code snippets, through an automated pipeline leveraging PythonOCC [37] and CadQuery [10] .', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': 'The generation process consists of two primary components: (1) a sketch profile generator (Algorithm 1) that creates valid 2D sketches, and (2) a CAD model generator (Algorithm 2) that produces 3D CAD models from these sketches.', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': 'The sketch generation process combines primitive shapes (circles and rectangles) through boolean operations (union and cut). From each generated sketch, we extract the primitives (lines, arcs, and circles) from both inner and outer loops. The validity of the generated sketch is ensured through multiple verification steps, including verifying that loops do not intersect, and each primitive has a length greater than zero. Finally, we ensure that the randomly generated CAD code has not previously been generated using the duplicate detection protocol outlined in [51] . This ensures that each sample in the dataset is unique.', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': 'The CAD model generation procedure extrudes the validated sketches and combines them through union operations. The planes on which the sketches lie are randomly generated by choosing one of the three canonical planes translated by a random amount. Each resulting model undergoes normalization to fit within a unit bounding box centered at the origin. The parameters are quantized so that the coordinates of any point on the CAD surface are within the range -100 to 100 with a minimum resolution of 1 unit. We then simplify the sequence using higher level abstractions (rectangle, box, and cylinder) by considering the sequence parameters. Our validation framework verifies that a generated code w executes without errors (\u03d5 syn ). Furthermore, we check that the executed code produces a geometric valid CAD model (\u03d5 cad ) using the BRepCheck Analyzer function from PythonOCC as in [48] . Invalid models are excluded from the dataset.', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': 'Figure 7 presents examples of CAD models alongside their corresponding CadQuery Python code from our procedurally generated dataset. It is worth noting that the generated codes are fairly compact, this was designed to facilitate training. All code examples are directly executable using a standard Python interpreter with the CadQuery library. The codes follow a consistent three-part structure:', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': '(1) necessary library import, (2) definition of sketch planes, and (3) sketch-extrude operations combined through union.', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': 'The training dataset generation procedure provides full control over the features included. In Figure 8 , it can be observed that the distribution of our CAD models is skewed towards models with larger face and edge count per model with interquartile ranges. As a result, our procedurally generated dataset provides a larger variety of models.', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': 'Results on the real-world CC3D [7, 35] dataset are presented in Table 3 of the main paper. This scenario provides an experimental evaluation in a realistic setting, as the input point clouds are sampled from actual 3D scans of CAD models. Sample models are depicted in Figure 9 , where artifacts such as surface noise, smoothed edges, and missing parts can be observed. Furthermore, several models from the CC3D dataset are constructed using a range of operations beyond simple extrusion, including revolution, chamfer, and fillet. Consequently, the real-world CC3D dataset provides a challenging set of inputs that enables robust inthe-wild evaluation of our proposed method.', 'section': 'C. Real-World CC3D Dataset', 'sec_num': None}, {'text': 'Qualitative Results: Additional qualitative results for the reverse engineering of CAD models from point clouds are presented for DeepCAD (Figure 10 ), Fusion360 (Figure 11 ), and real-world CC3D (Figure 12 ) datasets. As de-', 'section': 'D. Further Experimental Results', 'sec_num': None}, {'text': 'Algorithm 1 Generate2DSketch 1: function GENERATE2DSKETCH 2: numP rimitives \u2190 RandInt(3, 8) \u25b7 Choose random number of shape primitives 3: compositeShape \u2190 \u2205 \u25b7 Initialize empty shape 4: for i \u2190 1 to numP rimitives do \u25b7 Build shape by combining primitives 5: primitive \u2190 random from {Circle, RotatedRectangle} 6: booleanOperation \u2190 random from {Union, Cut} \u25b7 Union adds, Cut subtracts 7: compositeShape \u2190 ApplyOperation(compositeShape, primitive, booleanOperation) 8: end for 9: boundaryLoops \u2190 ExtractBoundaryLoops(compositeShape) \u25b7 Extract shape boundaries 10: boundaryComponents \u2190 \u2205 11: for loop \u2208 boundaryLoops do \u25b7 Process each boundary loop 12: (edgeSequence, isOuter) \u2190 AnalyzeBoundary(loop) \u25b7 List of parametric curves (lines, arcs, circles) 13: boundaryComponents.Append((edgeSequence, isOuter)) 14: end for 15: boundaryComponents \u2190 V alidateShapeT opology(boundaryComponents) \u25b7 Ensure valid shape topology 16: return boundaryComponents \u25b7 Returns list of (edges, boolean) tuples 17: end function Algorithm 2 GenerateCAD 1: function GENERATECAD 2: cadM odel \u2190 \u2205 \u25b7 Initialize empty CAD model 3: planes \u2190 GenerateRandomP lanes() \u25b7 Create set of reference planes 4: sketches \u2190 Generate2DSketch() \u25b7 Get sketches from Algorithm 1 5: for sketch \u2208 sketches do \u25b7 Create 3D volumes from sketches 6: plane \u2190 RandomSelect(planes) \u25b7 Select random reference plane 7: volume \u2190 ExtrudeSketch(sketch, plane) \u25b7 Create 3D volume by extrusion 8: cadM odel \u2190 BooleanU nion(cadM odel, volume) \u25b7 Add volume to model 9: end for 10: cadM odel \u2190 N ormalizeM odel(cadM odel) \u25b7 Ensure the model fits within a unit box 11: cadM odel \u2190 QuantizeP arameters(cadM odel) \u25b7 Discretize model parameters 12: cadM odel \u2190 Simplif yCADM odel(cadM odel) \u25b7 Identify high-level abstractions (rectangle, box, and cylinder) 13: cadM odel \u2190 V alidateCADM odel(cadM odel) \u25b7 Ensure validity of CadQuery code and CAD model geometry 14: cadM odel \u2190 CheckDuplicate(cadM odel) \u25b7 Ensure that the sequence has not previously been generated. 15:', 'section': 'D. Further Experimental Results', 'sec_num': None}, {'text': 'return cadM odel 16: end function tailed in Section 5.1 of the main paper, CAD-Recode consistently generates shapes that closely approximate the input point cloud geometry, whereas CAD-SIGNet [21] can generate predictions that greatly differ from the input. Ablation Results: Table 6 shows the architecture ablation results on all metrics, complementing Table 4 of the main paper. Results show that for the same size of input point clouds Qwen1.5b always produces better geometric performance (median CD and IoU) than Qwen0.5b. This can be attributed to the higher number of parameters as well as to the better ability of the model to produce valid python code before fine-tuning. Furthermore, increasing the size of the input point cloud demonstrates a similar pattern, with Qwen1.5b with an 256 input points appears to be the set of architecture parameters leading to the best performance.', 'section': 'D. Further Experimental Results', 'sec_num': None}, {'text': 'Note that the mean CD is a metric that is very sensitive to outlier predictions. While Qwen1.5b with 256 input points appears to result in the highest IR, it is negligibly low on all datasets (less 0.5%). This can also be explained by the fact that this setting produces more complex CAD sketchextrude sequences, making them more susceptible to errors. Note that a key idea of our method is to leverage pre-trained LLMs as decoder of Python code. In the absence of LLMbased CAD reverse engineering methods, we compare our approach to SOTA methods despite the difference in model sizes. For reference, CAD-SIGNet contains 6 M parameters.', 'section': 'Code Outputs:', 'sec_num': None}, {'text': \"Command & Parameter Accuracy: In order to evaluate the ability of CAD-Recode to predict numerical values and sequences that are consistent with the training set, we evaluate CAD-Recode trained on the DeepCAD dataset converted to CADQuery python codes with the Acc command and Acc parameter as introduced in [48] . The results on the DeepCAD testing set are presented in Table 7 . It can be observed that CAD-Recode achieves comparable performance to the state-of-the-art on the commnad type accuracy import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, -13, 0)) r = w0.workplane(offset=-87 / 2).moveTo(52.5, 10.5).box (57, 83, 87) .union(w0.workplane(offset=23 / 2).moveTo(-29, 0).cylinder (23, 30) )\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': '.union(w0.workplane(offset=113 / 2).moveTo(-29, 0).cylinder(113, 52))', 'section': 'Code Outputs:', 'sec_num': None}, {'text': \"import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, -30, 0)) r = w0.sketch().segment((-30, -27),(-18, -31)).segment((-19, -31)).segment((-19, -100))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': '.segment((38, -100)).segment((38, -31)).segment((10, -31)).segment((13, -23))', 'section': 'Code Outputs:', 'sec_num': None}, {'text': \".arc((30, -13), (23, 5) ).segment ((33, 33) ).segment ((16, 39) ).arc((-12, 99),(-9, 33)) .close().assemble().finalize().extrude (60) import cadquery as cq w0 = cq.Workplane('YZ', origin=(-14, 0, 0)) r = w0.workplane(offset=17 / 2).moveTo(4, -73.5).box(104, 53, 17) .union(w0.sketch().segment((-78, 23), (2, -55)).segment((40, -17))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': '.arc((42, -24),(48, -30)).segment((48, 5)).segment((61, 5))', 'section': 'Code Outputs:', 'sec_num': None}, {'text': \".segment ((78, 22) ).segment((-2, 100)).close().assemble() .push([(0, 22)]).circle(50, mode='s').finalize().extrude( 29))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': \"import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, 42)) w1 = cq.Workplane('YZ', origin=(-17, 0, 0)) r = w0.sketch().arc((-12, 6), (34, -29),(-1, 16)).segment((5, 4)).segment((-8, -2)) .close().assemble().finalize().extrude(56) .union(w0.sketch().arc((-42, 54), (-12, 71), (19, 54)).segment((19, 78))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': '.segment((-42, 78)).close().assemble().finalize().extrude(58)) .union(w1.sketch().segment((-44, -100), (51, -100)).segment((51, 5)).segment((27, 5))', 'section': 'Code Outputs:', 'sec_num': None}, {'text': \".arc((-58, 40),(-44, -51)).close().assemble().reset() .face(w1.sketch().arc((-54, -17), (-26, -34),(3, -17)).close() .assemble(), mode='s').reset().face(w1.sketch().segment((-54, 14), (3, 14))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': \".arc((-26, 31), (-54, 14)).assemble(), mode='s').finalize().extrude(-13))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': \"import cadquery as cq w0 = cq.Workplane('YZ', origin=(-22, 0, 0)) w1 = cq.Workplane('ZX', origin=(0, -19, 0)) r = w0.sketch().segment((-100, -83),(-67, -83)).segment((-80, -52)).segment((-75, -50))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': '.segment((-75, 62)).segment((17, 62)).segment((17, -62)).segment((-40, -62))', 'section': 'Code Outputs:', 'sec_num': None}, {'text': '.segment((-37, -71)).segment((-65, -83)).segment((43, -83))', 'section': 'Code Outputs:', 'sec_num': None}, {'text': \".segment((43,83)).segment((-100,83)).close().assemble().finalize().extrude(8) .union(w1.sketch().segment((-77, -53),(76, -53)).arc((76, -48),(77, -42)) .segment((77, 53)).segment((-77, 53)).close().assemble() .push([(38.5, 2.5)]).rect(9, 57, mode='s').finalize().extrude(119)) 5 10 15 20 25 30 35 40 Number of faces per model DeepCAD Our Dataset (a) Box-plot graph of the distribution of the number of faces per model. 0 20 40 60 80 100 Number of edges per model DeepCAD Our Dataset (b) Box-plot graph of the distribution of the number of edges per model. and significantly higher performance on the parameter accuracy. This demonstrates that CAD-Recode is able to predict numerical values accurately. Note that, those metrics were originally developed to evaluate autoencoding ability. However, there may exist many different possible valid CAD sequences to construct the same CAD model and these metrics do not take this into account. As a result, these metrics were omitted in recent works (CAD-SIGNet [21] and TransCAD [12] ).\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': 'The invalidity rate of CAD-Recode predictions is very low, below 1% on the DeepCAD [48] , Fusion360 [47] and real-world CC3D [35] dataset. Some examples of invalid code predictions are presented in Figure 14 . Invalid predictions happen when the CAD model contains features of dimension smaller than the resolution induced by quantization (Figure 14 Points Model DeepCAD Fusion360 CC3D Size Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 64 0.5 B 0.42 0.20 88.5 0.1 0.58 0.22 82.1 0.1 0.87 0.45 70.1 0. DeepCAD [48] 80.4 69.6 PrismCAD [25] 73.0 66.8 HNC-CAD [52] 82.7 74.6 CAD-Diffuser [34] 88.5 82.9 CAD-Recode 83.9 92.1', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': 'Table 7 . Command and parameter accuracy results [48] Point Cloud CAD-SIGNet CAD-Recode GT Figure 11. Qualitative results on the Fusion360 dataset. Point Cloud CAD-SIGNet CAD-Recode GT .segment((48, 100)).segment((-48, 100)).close().assemble().finalize().extrude(20) .union(w0.sketch().segment((-82, -100),(-27, -100)).segment((-27, 80)).segment ((27, 80) )', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.segment((27, -100)).segment((82, -100)).segment((82, -79)).segment((48, -79))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.segment((48, 100)).segment((-48, 100)).segment((-48, -79)).segment((-82, -79))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \".close().assemble().finalize().extrude (34) ) .circle(28, mode='s').finalize().extrude (32) import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, 40, 0)) w1 = cq.Workplane('XY', origin=(0, 0, -19)) r = w0.sketch().arc((-24, -47), (41, -99),(87, -32)).segment((88, -32)).segment((88, 100))\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': 'import', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.segment((82, 100)).segment((82, -52)).arc((34, -94), (-18, -52)).segment((-18, 100))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \".segment((-24, 100)).close().assemble().finalize().extrude(-80) .union(w1.workplane(offset=-69 / 2).moveTo (52, 0) .cylinder(69, 32)) import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, 31, 0)) r = w0.workplane(offset=-75 / 2).cylinder (75, 62) .union(w0.workplane(offset=-25 / 2).cylinder (25, 81) )\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.union(w0.workplane(offset=13 / 2).cylinder(13, 100))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \"import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, 69, 0)) w1 = cq.Workplane('ZX', origin=(0, -85, 0)) r = w0.workplane(offset=-150 / 2).cylinder (150, 15) .union(w0.workplane(offset=10 / 2).cylinder (10, 31) )\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.union(w0.workplane(offset=31 / 2).cylinder (31, 8) )', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \".union(w1.workplane(offset=-15/2).cylinder (15, 46) ) import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, 20, 0)) r = w0.sketch().circle(61).circle(25, mode='s').push([(34, 4)]) .circle(4, mode='s').finalize().extrude(-41) .union(w0.sketch().segment((-100, 19), (-88, 11) ).segment((-97, -34)).segment((-67, -41))\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.segment((-77, -66)).segment((-57, -74)).segment((-57, -72)).segment((-56, -72))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \". import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, 0)) w1 = cq.Workplane('YZ', origin=(0, 0, 0)) r = w0.workplane(offset=0 / 2).cylinder(0, 98) .union(w1.workplane(offset=0 / 2).cylinder(0, 100)) (a) The ground truth model contains three very thin cylinders with height smaller than 1. As a result, CAD-Recode is not able to predict heights with sufficient precision due to quantization and predicts cylinders with height 0, producing an invalid model. import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, 0)) r = w0.sketch().rect(200, 124).push([(-63.5, 25)]).rect(51, 60, mode='s') .push([(55, -25)]).rect(50, 60, mode='s').finalize().extrude(0) (b) As the ground-truth model has thickness less than 1, CAD-Recode predicts an extrusion distance of 0 as a quantized approximation (highlighted in yellow), resulting in an invalid CAD model. import cadquery as cq w0 = cq.Workplane('YZ', origin=(34, 0, 0)) w1 = cq.Workplane('XY', origin=(0, 0, 44)) r = w0.sketch().segment((-7, -35), (11, -36)).segment((11, -24)).arc((1, (6, -2)).segment((-1, 19)).segment((11, 23)).segment((11, 28))\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.segment ((11, 29) ).segment ((12, 29) ).segment ((12, 35) ) .segment((-4, 36)).close().assemble().finalize().extrude(-133) .union(w0.sketch().segment((5, -7), (14, -2)).segment ((8, 8) ).arc((7, 0),', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '(5, -7)).assemble().finalize().extrude( 63)) .union(w1.sketch().arc((-100, 12), (-85, 10), (-70, 5)).arc((-68, 6), (-66, 5)).arc((-59, 4), (-52, 2)).arc((-51, 3), (-50, 4)).arc((-72, 7), (-90, 12)).close().assemble().finalize().extrude(-88))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '(c) The ground-truth CAD model is created with B-spline primitives. Since CAD-Recode supports only arc, circle and line primitives, it tries to approximate the solution with multiple arcs, but fails to provide a valid CAD model. In particular, the prediction contains an arc constructed from three co-linear points (highlighted in yellow), which raises an error in CadQuery.', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \"import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, -79)) r = w0.sketch().segment((-100, -1), (-91, -1)).arc((0, -93),(91, -1))\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \".segment((100, -1)).segment((100, 1)).segment((91, 1)).arc((0, 99), (-91, 1)).segment((-100, 1)).close().assemble().push([(0, -2)]) .circle(90, mode='s').finalize().extrude(-2) .union(w0.workplane(offset=140 / 2).cylinder(140, 72)) .union(w0.sketch().segment((-51, 15), (-50, 15) ).arc((0, -53), (50, 15) )\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.segment ((51, 15) ).segment ((51, 27) ).segment ((48, 27) ).arc((0, -53), (-48, 27) ).segment((-51, 27)).close().assemble().finalize().extrude( 159))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '(d) The ground-truth CAD model is created with a revolution operation. Since CAD-Recode supports only extrusion operation, it tries to approximate the solution with multiple arcs. However, one of the sketch (highlighted in yellow) results in a self-intersecting loop, which is not a valid face. ', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': 'The ablation study in Section 5.1 of the main paper demonstrates the effectiveness of our test-time sampling strategy. This approach generates multiple plausible solutions by sampling different input point clouds. Figure 15 illustrates the qualitative results from different sampling instances. While CAD-Recode successfully captures the overall geometry across different samplings, fine-grained details may vary in reconstruction quality due to the relatively sparse point cloud input. However, this can be effectively addressed by leveraging multiple sampling iterations to capture different aspects of the input geometry.', 'section': 'E. Test-time Sampling', 'sec_num': None}, {'text': 'In this section, we provide further details on the CAD-QA experiments reported in Section 5.2 of the main paper. We start by providing more details on the SGP-Bench benchmark [38] . Then, we present results further results and examples of GPT-4o outputs.', 'section': 'F. Interpretability and CAD-QA', 'sec_num': None}, {'text': 'The goal of the SGP-Bench benchmark is to evaluate the spatial-semantic reasoning skills of LLMs from symbolic graphics programs [38] . One aspect of the benchmark is a set of 1000 multiple choice questions on 3D CAD models given their corresponding sketch-extrude sequence in the DeepCAD [48] format. An example is depicted in Figure 16 .', 'section': 'F.1. Representation and CAD-QA', 'sec_num': None}, {'text': 'To evaluate the interpretability of our code-based CAD representation, we translated the 1000 questions of SGP-Bench from the DeepCAD representation (Figure 16(a) ) to the CadQuery code format (Figure 16(b) ). Using the same protocol as in SGP-Bench [38] , and GPT-4o [36] , we found that the accuracy on the multiple choice question in Cad-Query format is 82.4%. This is about 4% higher than using the DeepCAD format with an interpretative hint. This suggests the proposed code representation provides a more structured and naturally LLM-interpretable representation of CAD models.', 'section': 'F.1. Representation and CAD-QA', 'sec_num': None}, {'text': 'In Table 6 of the main paper, the results for point cloud CAD-QA are presented. Figure 17 (a) depicts an example of point cloud and question that was used to obtain these results. In this particular question, the task is to deduce the number of holes present in the CAD model given the point cloud as input. Figure 17(b ), the answer provided by PointLLM is shown and it can be observed that PointLLM is unable to retrieve the correct answer. It is worth noting that PointLLM is a network trained to answer semantic questions about object given its point cloud representation, as result in most cases the network is unable to describe geometric CAD-specific questions. For both CAD-SIGNet and CAD-Recode, the point cloud CAD-QA is done in a two step process. First the sketch-extrude is sequence is predicted from each network, then the sequence along with the question is passed through GPT-4o. Note that for CAD-SIGNet an interpretative hint is provided to provide context on the structure of the sequence. A sample output for CAD-SIGNet and GPT-4o can be found in Figure 17 (c), and in Figure 17 (d) for CAD-Recode and GPT4-o. As the sequence was incorrectly predicted by CAD-SIGNet the answer to the question is wrong (1 hole), whereas the prediction from CAD-Recode captured better the geometry of the input point cloud leading to a correct answer. It is worth noting, that despite not being provided any information about CadQuery Python code in the prompt, GPT-4o is able to breakdown the predicted sequence into its primitive components and provide correct and accurate geometric descriptions. This can be explained by the fact that LLMs are exposed to large amounts of code data during training. As a result, the CadQuery Python representation of CAD models is appropriate for', 'section': 'F.2. Point Cloud and CAD-QA', 'sec_num': None}, {'text': \"We provide more details on the editing pipeline presented in Section 5.2 of the main paper. The goal of this pipeline is to integrate automated editability capabilities to CAD-Recode. To this end, we present a simple process using an off-the-shelf LLM, GPT-4o [36] . Starting from an output CAD Python code from CAD-Recode as shown in Figure 18a , we prepare a simple and generic prompt (Figure 18b ) for the LLM to generate a refactored version of the code such that when executed the user can change with the dimensions of each primitive. As seen in Figure 18c , the LLM is able to generate a code with comments that describe the different primitives semanticallly and include appropriate variables for the dimensions of each of the primitive, such as the height and the diameter of each cylinder. The code generated by the LLM, can be directly executed in a Jupyter notebook with the CadQuery and ipywidgets libraries. Figure 6 of the main paper shows the generated sliders and how can the shape be then edited. This demonstrates that the CAD representation as Python code within a reverse engineering scenario opens the door to new applications when combined with LLMs. Examine the following CAD code carefully to understand the 3D object it generates and answer the question based on your interpretation of the rendered image of that object. SOL; Line:(221,128); Line:(221,223) ;Line:(128,223); Line:(128,128); Ext: (128,128,128,32,110,128,98,167,128, Newbody, One-sided); EOS Hint: the CAD code has the following syntax: CAD code consists of a sequence of CAD commands that describe a 3D object. The commands fall into two categories: sketch and extrusion. Sketch commands are used to specify closed curves on a 2D plane in 3D space. Each closed curve is referred as a loop, and one or more loops form a closed region called a profile. A loop always starts with an indicator command <SOL> followed by a series of curve commands. All the curves on the loop are in counterclockwise order, beginning with the curve whose starting point is at the most bottom-left. In total, there are three possible curve commands: Line, Arc, and Circle. Line(x, y): a line, with x, y as line end-point. Arc(x, y, u, f): an arc, with x,y as arc end-point, u as sweep angle and f as whether it is counter-clockwise, f=0 means it is counter-clockwise, f=1 means it is not counter-clockwise. Circle(x, y, r): a circle, with x,y as the center point and r as the radius. The extrusion command has two purposes: 1) It extrudes a sketch profile from a 2D plane into a 3D body, and the extrusion type can be either one-sided, symmetric, or two-sided with respect to the profile's sketch plane. 2) The command also specifies (through the parameter b in Ext) how to merge the newly extruded 3D body with the previously created shape by one of the boolean operations: either creating a new body, or joining, cutting or intersecting with the existing body. Ext(x, y, z, o, p, q, s, e, f, b, u): extrude operation, with x, y, z as the sketch plane orientation, o, p, q as the sketch plane origin, s as the scale of the associated sketch profile, e, f as the extrude distances towards both sides, b as the type of merge operation (could be New-body operation, join operation, cut operation and intersect operation) and u as the extrude type (could be one-sided, symmetric or two-sided). <EOS> means the end of the code. Question: How many faces does the CAD object in the image have? (a) DeepCAD Representation Examine the following CAD code carefully to understand the 3D object it generates and answer the question based on your interpretation of the rendered image of that object.\", 'section': 'G. Editing Pipeline Details', 'sec_num': None}, {'text': \"import cadquery as cq def make shape(): plane0 = cq.Plane(origin = (-0.75,-0.1406,0.0),xDir = (1.0,0.0,0.0),normal = (0.0,0.0,1.0)) w0 = cq.Workplane(plane0) face0 = w0.sketch().face(w0.sketch().segment( (0.0, 0.0), (0.7495, 0.0)).segment((0.7495, 0.0), (0.7495, 0.7656)).segment((0.7495, 0.7656), (0.0, 0.7656)).segment((0.0, 0.7656), (0.0, 0.0)).assemble(), mode = 'a').finalize() shape0 = face0.extrude(0.3046875, both=False) return shape0\", 'section': 'G. Editing Pipeline Details', 'sec_num': None}, {'text': \"Question: How many faces does the CAD object in the image have? Question: How many holes does the CAD object in the image have? A) Two, B) Three, C) Four, D) Five Correct Answer: B (a) Point cloud and corresponding CAD-specific question The CAD object in the image has five holes. (b) PointLLM output from point cloud To determine the number of holes in the CAD object, let's break down the CAD code step by step: 1. Extrusion Command: Start;Ext:(128,130,128,128,130,128,128,128,NewBody,96); This command sets up an extrusion with specific parameters and indicates that a new body will be created. 2. First Loop: Line:(43,0);Arc:(213,0,255,43);Line:(213,85);Arc:(43,85,0,43);EOL; -Line:(43,0) -A line from the starting point to (43,0). -Arc:(213,0,255,43) -An arc with midpoint (213,0) and endpoint (255,43). -Line:(213,85) -A line from the previous endpoint to (213,85). -Arc:(43,85,0,43) -An arc with midpoint (43,85) and endpoint (0,43). -EOL -End of the loop. This forms a closed loop, which is a profile for extrusion. 3. Second Loop: Circle:(43,43,43,51);EOL; -Circle:(43,43,43,51) -A circle with the most left point at (43,43) and the most top point at (43,51). -EOL -End of the loop. This forms another closed loop, which is another profile for extrusion. 4. End of Sketch and Extrusion: EOF;EOS;End; -EOF -End of face.\", 'section': 'G. Editing Pipeline Details', 'sec_num': None}, {'text': '-EOS -End of sketch.', 'section': 'G. Editing Pipeline Details', 'sec_num': None}, {'text': '-End -End of the code. From the above analysis, we can see that the CAD object consists of:', 'section': 'G. Editing Pipeline Details', 'sec_num': None}, {'text': '-One main profile formed by the first loop.', 'section': 'G. Editing Pipeline Details', 'sec_num': None}, {'text': \"-One circular profile formed by the second loop. The circular profile represents a hole within the main profile. Since there is only one circular profile, the CAD object has one hole. Answer: A (c) GPT-4o output from CAD-SIGNet prediction Let's break down the CAD code step by step to understand the 3D object it generates and determine the number of holes. 1. Workplane Creation: w0 = cq.Workplane('XY', origin=(0,0,1)) This line creates a workplane on the XY plane with an origin at (0,0,1). 2. Sketching the Shape: r = w0.sketch() This initializes a sketch on the workplane. 3. Defining the Shape: .segment((-66,-34), (50,-34) ) .segment((50,-32)) .arc((100,0), (50, 32) ) .segment ((50,34) ) .segment((-66,34)) .segment((-66,32)) .arc((-100,0),(-66,-32)) .close() These lines define a closed shape with segments and arcs. The shape appears to be symmetrical along the Y-axis. 4. Adding Holes: .assemble() .push([(-66,0)]).circle(10, mode='s') .push([(0,0)]).circle(10, mode='s') .push([(66,0)]).circle(10, mode='s') .finalize() These lines add three circles (holes) to the shape at positions (-66,0), (0,0), and (66,0). 5. Extruding the Shape: .extrude(-4) This line extrudes the shape by -4 units, creating a 3D object with the defined shape and holes. From the code, we can see that three circles (holes) are added to the shape. Therefore, the CAD object has three holes. Answer: B (d) GPT-4o output from CAD-Recode prediction \", 'section': 'G. Editing Pipeline Details', 'sec_num': None}], 'back_matter': [{'text': 'import cadquery as cq w0 = cq.Workplane(\\'XY\\', origin=(0, 0, 0)) r = w0.workplane(offset=-100 / 2).cylinder (100, 100) .union(w0.workplane(offset=100 / 2).cylinder(100, 34))(a) CAD-Recode output as CadQuery Python code.Refactor the code, add functions and variables that can make the code easier to edit and more interpretable. Add in the code, sliders to edit the size of each primitive: import cadquery as cq w0=cq.Workplane(\\'XY\\',origin=(0,0,0)) r=w0.workplane(offset=-100/2).cylinder(100,100 \"\"\"Creates a cylinder on the specified workplane with a given diameter, height, and offset.\"\"\" return workplane.workplane(offset=offset).cylinder(height, diameter / 2) def build_model(base_diameter=default_base_diameter, base_height=default_base_height, top_diameter=default_top_diameter, top_height=default_top_height): \"\"\"Builds the model with adjustable base and top cylinder dimensions.\"\"\" # Initialize the main workplane w0 = cq.Workplane(\"XY\", origin=(0, 0, 0)) ', 'section': 'annex', 'sec_num': None}], 'ref_entries': {'FIGREF0': {'text': 'Figure 1. 3D CAD reverse engineering is a process of converting a point cloud into a CAD model (top). Existing methods are constrained by the use of method-specific CAD representations and limited hand-crafted training datasets (a). On the contrary, CAD-Recode employs a pre-trained LLM with a lightweight projector that translates point clouds into executable Python code and is trained on a procedurally generated dataset (b).', 'fig_num': '1', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF1': {'text': 'Figure 2. Sketch-extrude sequence (top) in DeepCAD representation (middle) and our CadQuery code (bottom).', 'fig_num': '1', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF2': {'text': \"Interpretability and LLM Compatibility: The proposed representation, based on Python and CadQuery syntax, presents an alternative to abstract numerical encodings with improved interpretability. Its code-based format facilitates model editing both programmatically and through CAD software. Importantly, this representation aligns with pretrained LLMs' demonstrated proficiency in Python code generation and manipulation. Indeed, state-of-the-art proprietary LLMs like GPT-4 [36] achieve over 90% accuracy on the Python code HumanEval benchmark [5], while even lightweight open-source models such as Qwen2-1.5B [55] show promising code generation capabilities. Hence, this code representation facilitates fine-tuning of pre-trained LLMs for the specific task of reverse engineering point clouds into CAD Python code and opens the doors for new capabilities with off-the-shelf LLMs.\", 'fig_num': '3', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF3': {'text': 'Figure 3. Examples of procedurally generated CAD models.', 'fig_num': '3', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF5': {'text': 'Figure 4. Overview of CAD-Recode. The pipeline comprises two parts: (1) a point cloud projector (marked blue) (2) a fine-tuned pretrained LLM (yellow). An input point cloud is processed using (1), and outputs are then passed to an LLM (2), which predicts a CAD sketch-extrude sequence in the form of executable Python code.', 'fig_num': '4', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF6': {'text': 'Figure 6. Interactive editing of a CAD model. Given the code output from CAD-Recode and a generic prompt, GPT-4o allows automated and interactive editing of the CAD model.', 'fig_num': '6', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF7': {'text': 'Figure 13 illustrates the predicted code sequences and their corresponding reconstructed shapes. The predicted codes have a syntax that is consistent with the procedurally generated training examples, showing that CAD-Recode successfully learns both the features and CAD design patterns established in the training set.', 'fig_num': '7', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF8': {'text': 'Figure 7. Examples from our procedurally generated training dataset. Each row contains CadQuery Python code and a corresponding CAD model. Examples contain not only basic line, circle, and arc primitives, but also higher-level abstractions such as rect, box, and cylinder.', 'fig_num': '7', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF9': {'text': 'Figure 8. Our 1 M procedurally generated training dataset displays distributions CAD models that are skewed towards models with larger edge and face count per model than the DeepCAD dataset (160 k models).', 'fig_num': '8', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF10': {'text': 'Figure 9. Example models from real-world CC3D dataset. The scans exhibits numerous artifacts such as surface noise, missing parts and smoothed edges. In the CC3D experiments reported in the main paper, the input point clouds are sampled from the scans. Zoom in for better details.', 'fig_num': '9', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF11': {'text': 'Figure 10. Qualitative results on the DeepCAD dataset.', 'fig_num': '101112', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF12': {'text': \"cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, -16)) r = w0.sketch().arc((-46, -23), (-95, -74), (-27, -56)).segment((30, -56)) .arc((96, -72), (44, -25)).segment((44, -12)).arc((31, 14), (30, 42)) .arc((1, 92), (-31, 44)).arc((-32, 43), (-33, 43)).arc((-31, 20),(-39, -2)) .segment((-39, -12)).segment((-43, -12)).arc((-45, -17),(-46, -23)).assemble() .push([(-64, -56)]).circle(28, mode='s').push([(0, 56)]).circle(28, mode='s') .push([(0, -19)]).circle(28, mode='s').push([(65, -56)])\", 'fig_num': '13', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF13': {'text': 'Figure 13. CAD-Recode predictions on DeepCAD (top 2 rows), Fusion360 (mid 3 rows), and CC3D (last row) datasets. Each row contains predicted CadQuery Python code and its result after execution in Python interpreter.', 'fig_num': '13', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF14': {'text': 'Figure 14. Examples of invalid predictions. Each row contains the ground-truth CAD model (left) and an invalid predicted CadQuery Python code (right). The CAD models in (a) and (b) are taken from the DeepCAD dataset and the CC3D dataset for (c) and (d). Invalid predictions mostly take place when the ground-truth contains features of very small dimension with respect to the size of the CAD model as in (a) and (b), or when the ground-truth model contains operations other than the ones supported as in (c) and (d).', 'fig_num': '14', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF15': {'text': 'Figure 15. CAD-Recode predictions from different point cloud sampling on DeepCAD, Fusion360, and real-world CC3D datasets. For each prediction, 256 points are sampled randomly from the input point cloud.', 'fig_num': '15', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF16': {'text': 'Figure 16. Example of a CAD question from SGP-Bench in the DeepCAD representation (b) and using the CadQuery representation (c).When asking the question in CadQuery format no hint is provided, while in DeepCAD format a long interpretative hint is required. The choice of answers are A) 6, B) 4, C) 8 and D) 5. The correct answer is A) 6.', 'fig_num': '16', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF17': {'text': 'Figure 17. Example of Point cloud CAD-QA (a) and answers provided by PointLLM (b), CADSIGNet and GPT-4o (c) and CAD-Recode and GPT-4o (d).', 'fig_num': '17', 'num': None, 'uris': None, 'type_str': 'figure'}, 'TABREF1': {'html': None, 'text': 'Comparison of CAD reverse engineering methods on DeepCAD and Fusion360 datasets. Our CAD-Recode trained on the 160 k DeepCAD dataset demonstrates an improvement over existing state-of-the-art methods both in terms of geometric fidelity and validity of the generated sketch-extrude sequences. Our procedurally generated dataset provides a significant boost in the prediction quality.', 'num': None, 'type_str': 'table', 'content': '<table><tr><td>Method</td><td colspan=\"10\">Train Dataset Name Size Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR \u2193 Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 DeepCAD Test Set Fusion360 Test Set</td></tr><tr><td>DeepCAD [48]</td><td colspan=\"2\">DeepCAD 160k</td><td>42.5</td><td>9.64</td><td>46.7</td><td>7.1</td><td>330</td><td>89.2</td><td colspan=\"2\">39.9 25.2</td></tr><tr><td>PrismCAD [25]</td><td colspan=\"2\">DeepCAD 127k</td><td>-</td><td>4.28</td><td colspan=\"2\">72.1 16.2</td><td>-</td><td>4.75</td><td colspan=\"2\">65.3 18.0</td></tr><tr><td>Point2Cyl [45]</td><td colspan=\"2\">DeepCAD 35k</td><td>-</td><td>4.27</td><td>73.8</td><td>3.9</td><td>-</td><td>4.18</td><td>67.5</td><td>3.2</td></tr><tr><td>HNC-CAD [52]</td><td colspan=\"2\">DeepCAD 125k</td><td>-</td><td>8.64</td><td>65.3</td><td>5.6</td><td>-</td><td>36.8</td><td>63.5</td><td>7.3</td></tr><tr><td>MultiCAD [33]</td><td colspan=\"2\">DeepCAD 160k</td><td>-</td><td>8.09</td><td>-</td><td>11.5</td><td>-</td><td>42.2</td><td>-</td><td>16.5</td></tr><tr><td>TransCAD [12]</td><td colspan=\"2\">DeepCAD 140k</td><td>32.3</td><td>4.51</td><td>65.5</td><td>1.1</td><td>78.6</td><td>33.4</td><td>60.2</td><td>2.4</td></tr><tr><td colspan=\"3\">CAD-Diffuser [34] DeepCAD 160k</td><td>-</td><td>3.02</td><td>74.3</td><td>1.5</td><td>-</td><td>3.85</td><td>63.2</td><td>1.7</td></tr><tr><td colspan=\"3\">CAD-SIGNet [21] DeepCAD 160k</td><td>3.43</td><td>0.28</td><td>77.6</td><td>0.9</td><td>7.37</td><td>0.48</td><td>65.6</td><td>1.6</td></tr><tr><td>CAD-Recode</td><td colspan=\"2\">DeepCAD 160k</td><td>1.98</td><td>0.27</td><td>80.7</td><td>0.0</td><td>3.37</td><td>0.52</td><td>67.6</td><td>0.1</td></tr><tr><td>CAD-Recode</td><td>Ours</td><td>1M</td><td>0.30</td><td>0.16</td><td colspan=\"2\">92.0 0.4</td><td>0.35</td><td>0.15</td><td colspan=\"2\">87.8 0.5</td></tr></table>'}, 'TABREF3': {'html': None, 'text': \"is a benchmark of 1000 CAD-specific Question Answering (CAD-QA) tasks that test LLMs' understanding of CAD model geometry from sketch-extrude se-Ablation of training data and test-time sampling. The results demonstrate the advantage of training on our procedurally generated data, while the test-time sampling helps reducing the invalidity ratio. CD stands for mean Chamfer distance.\", 'num': None, 'type_str': 'table', 'content': '<table><tr><td>Method</td><td/><td colspan=\"7\">Train Dataset Name Size Sampling CD\u2193 IoU\u2191 IR\u2193 CD\u2193 IoU\u2191 IR\u2193 CD\u2193 IoU\u2191 IR\u2193 Test-time DeepCAD Fusion360 Real-World CC3D</td></tr><tr><td colspan=\"4\">Previous best [21] DeepCAD 160 k</td><td>\u2713</td><td colspan=\"3\">3.43 77.6 0.9 7.37 65.6 1.6 14.80 42.6</td><td>4.4</td></tr><tr><td colspan=\"2\">CAD-Recode</td><td colspan=\"2\">DeepCAD 160 k</td><td>\u2713</td><td>1.98 80.7 0.0 3.37 67.6 0.1</td><td>3.79</td><td>56.4</td><td>0.0</td></tr><tr><td colspan=\"2\">CAD-Recode</td><td>Ours</td><td>160 k</td><td>\u2713</td><td>0.54 88.3 0.3 0.66 82.0 0.1</td><td>1.27</td><td>69.0</td><td>0.2</td></tr><tr><td colspan=\"2\">CAD-Recode</td><td>Ours</td><td>1 M</td><td>\u2713</td><td colspan=\"4\">0.30 92.0 0.4 0.35 87.8 0.5 0.76 74.2 0.3</td></tr><tr><td colspan=\"4\">Previous best [21] DeepCAD 160 k</td><td>\u2717</td><td colspan=\"4\">6.81 77.3 4.4 14.5 58.4 9.3 32.59 39.1 15.5</td></tr><tr><td colspan=\"2\">CAD-Recode</td><td>Ours</td><td>1 M</td><td>\u2717</td><td colspan=\"4\">0.75 89.3 4.9 0.89 84.2 8.7 3.05 65.6 16.8</td></tr><tr><td>Points</td><td>Model Size</td><td colspan=\"4\">DeepCAD CD\u2193 IoU\u2191 CD\u2193 IoU\u2191 CD\u2193 IoU\u2191 Fusion360 CC3D</td><td/><td/></tr><tr><td>128</td><td>0.5 B</td><td colspan=\"4\">0.18 89.9 0.18 84.3 0.38 71.9</td><td/><td/></tr><tr><td>256</td><td>0.5 B</td><td/><td/><td/><td/><td/><td/></tr></table>'}, 'TABREF5': {'html': None, 'text': 'Ablation of architecture details.', 'num': None, 'type_str': 'table', 'content': '<table><tr><td>1</td></tr></table>'}}}}\n\n-----\n\n## Overview of the plan\nBelow is a comprehensive roadmap to reproduce the CAD\u2010Recode method. This plan is divided into major phases\u2014from generating the training data to building the model and designing experiments\u2014while highlighting all key details mentioned in the paper. Some points may require clarifications or additional choices during implementation.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n1. OVERVIEW  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n\u2022 Objective: Reverse engineer CAD models by predicting executable Python code (using the CadQuery library) from 3D point clouds.  \n\u2022 Core idea: Combine a lightweight point cloud processing \u201cprojector\u201d with a pre\u2010trained, auto-regressive LLM (Qwen2-1.5B) fine-tuned on a large-scale, procedurally generated CAD dataset.  \n\u2022 End goals:  \n\u2003 \u2013 Generate CAD \u201csketch-extrude\u201d sequences in Python code that reconstruct models.  \n\u2003 \u2013 Ensure the output code is valid (syntactically and geometrically) and can be further interpreted by off-the-shelf LLMs for editing or CAD-QA.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n2. DATASET GENERATION  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nA. Procedural Data Generation Pipeline  \n\u2003\u2022 Implement two algorithms (as per Algorithms 1 and 2 in the paper\u2019s supplementary):  \n\u2003\u2003\u2013 Algorithm 1: 2D Sketch Generation  \n\u2003\u2003\u2003\u25e6 Randomly choose between ~3\u20138 primitives (e.g., circles, rotated rectangles).  \n\u2003\u2003\u2003\u25e6 Apply Boolean operations (union, cut) to combine them.  \n\u2003\u2003\u2003\u25e6 Extract boundary loops and decompose them into a sequence of edges (lines, arcs, circles).  \n\u2003\u2003\u2003\u25e6 Apply topological validation (non-intersecting loops, minimum primitive lengths).  \n\u2003\u2003\u2013 Algorithm 2: CAD Model Generation  \n\u2003\u2003\u2003\u25e6 Select one of the three canonical planes (translated by a random offset) as the sketch plane.  \n\u2003\u2003\u2003\u25e6 Extrude the validated sketch using CadQuery operations.  \n\u2003\u2003\u2003\u25e6 Merge volumes via Boolean union.  \n\u2003\u2003\u2003\u25e6 Normalize the final model to fit in a unit bounding box and quantize parameters (coordinates in [\u2013100, 100] with minimum resolution 1).  \n\u2003\u2003\u2003\u25e6 Use a simplified \u201cabstraction\u201d step (e.g., replacing a 2D sketch-extrude sequence with a high-level primitive like box or cylinder) where applicable.  \n\u2003\u2022 Validate each generated CAD code:  \n\u2003\u2003\u2013 Run the generated Python code (using a standard interpreter with the CadQuery library).  \n\u2003\u2003\u2013 Check syntactic correctness (\u03d5_syn) and CAD-specific validity (\u03d5_cad) using a tool like PythonOCC\u2019s BRepCheck analyzer.  \n\u2003\u2003\u2013 Use a duplicate detection protocol (e.g., hash-based) to ensure that every sample is unique.  \n\u2003\u2022 Produce 1 million samples.  \n\u2003\u2003\u2013 Additionally, for ablation/comparisons, generate a 160k-sample dataset (i.e. converted from DeepCAD) following the same format.\n\nB. Point Cloud Extraction  \n\u2003\u2022 For each CAD model, sample points from its surface or the underlying mesh:  \n\u2003\u2003\u2013 For training, generate dense point clouds and then downsample to the required number (see next section).  \n\u2003\u2022 For evaluation, use the available datasets:  \n\u2003\u2003\u2013 DeepCAD (8046 models)  \n\u2003\u2003\u2013 Fusion360 (1725 models)  \n\u2003\u2003\u2013 CC3D (2973 models \u2013 including real-scanned artifacts such as noise, missing parts, smooth edges)  \n\u2003\u2022 Document any assumptions about sampling (e.g., uniform sampling, number of points, noise injection).\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n3. MODEL ARCHITECTURE  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nA. Point Cloud Projection Module  \n\u2003\u2022 Input: Dense point cloud P \u2208 \u211d^(n\u00d73).  \n\u2003\u2022 Processing steps:  \n\u2003\u2003\u2013 Apply furthest point sampling to downsample P to n_p = 256 points.  \n\u2003\u2003\u2013 Encode each point with Fourier positional encoding (refer to [62] for details).  \n\u2003\u2003\u2013 Use a linear layer to project the encoded points into a fixed embedding space of dimension d_q = 1536, resulting in query tokens Q_p \u2208 \u211d^(n_p\u00d7d_q).  \n\u2003\u2022 Note: The exact details for Fourier encoding (e.g., frequency scales) may need to be finalized based on common practices or further clarification in the supplementary material.\n\nB. CAD Code Decoder (LLM) Module  \n\u2003\u2022 Backbone: Pre-trained Qwen2-1.5B (primary); also note ablation with Qwen2-0.5B.  \n\u2003\u2022 Adaptation:  \n\u2003\u2003\u2013 Fine-tune the LLM to generate CAD code tokens via autoregressive next-token prediction.  \n\u2003\u2003\u2013 The code is in the form of Python scripts using the CadQuery library.  \n\u2003\u2003\u2013 Use a tokenized vocabulary that includes alphanumeric characters and operators (use the HuggingFace tokenizer associated with Qwen2, if available).  \n\u2003\u2022 Input to the decoder:  \n\u2003\u2003\u2013 Concatenate point cloud tokens Q_p with initial code tokens Q_t (starting with <s>).  \n\u2003\u2003\u2013 Full sequence [Q_p; Q_t] \u2208 \u211d^((n_p + n_t)\u00d7d_q).  \n\u2003\u2022 Training objective: Minimize the Negative Log-Likelihood (NLL) over the CAD code sequence.  \n\u2003\u2003\u2013 Use special tokens <s> and <e> to mark the boundaries of code generation.\n\nC. Integration & End-to-End Training  \n\u2003\u2022 The point cloud projector and the LLM decoder are trained jointly.  \n\u2003\u2022 Apply Gaussian noise (mean = 0, std = 0.01) to the input point cloud coordinates with a probability of 0.5 per sample to improve robustness.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n4. TRAINING SETUP & HYPERPARAMETERS  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nA. Hyperparameters  \n\u2003\u2022 Query token embedding dimension: 1536.  \n\u2003\u2022 Downsampled point cloud size: 256 points.  \n\u2003\u2022 Optimizer: AdamW with learning rate = 0.0002 and weight decay = 0.01.  \n\u2003\u2022 Learning rate schedule: Cosine scheduler with an initial warmup period of 1k iterations.  \n\u2003\u2022 Total iterations: 100k  \n\u2003\u2022 Batch size: 18  \n\u2003\u2022 Hardware: Single NVIDIA H100 GPU (training expected in ~12 hours based on these settings).\n\nB. Training Details  \n\u2003\u2022 Fine-tune pre-trained Qwen2-1.5B (ensure proper initialization from a HuggingFace checkpoint if available).  \n\u2003\u2022 Both modules (point cloud projector and decoder) learn end-to-end; the projector learns from scratch while the LLM is fine-tuned for CAD code generation.  \n\u2003\u2022 Loss: Use the standard NLL loss computed over the predicted token sequence.\n\nC. Ablation Studies  \n\u2003\u2022 Compare training on 160k DeepCAD samples versus 1M procedurally generated samples.  \n\u2003\u2022 Vary the input point cloud size (e.g., testing with 128 vs. 256 points).  \n\u2003\u2022 Compare different LLM model sizes (Qwen2-1.5B vs. Qwen2-0.5B).  \n\u2003\u2022 Evaluate the effect of test-time sampling (see next section).\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n5. INFERENCE & TEST-TIME SAMPLING  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nA. Inference Pipeline  \n\u2003\u2022 Given a new input point cloud:  \n\u2003\u2003\u2013 Downsample using furthest point sampling to 256 points.  \n\u2003\u2003\u2013 Apply Fourier positional encoding and linear projection to produce Q_p.  \n\u2003\u2003\u2013 Feed Q_p along with the start token (<s>) to the LLM decoder.  \n\u2003\u2003\u2013 Autoregressively generate tokens until the end token (<e>) is produced.  \n\u2003\u2022 Post-process the generated token sequence to obtain a Python CAD script.\n\nB. Test-Time Sampling  \n\u2003\u2022 To reduce the possibility of invalid outputs, adopt a sampling strategy:  \n\u2003\u2003\u2013 Generate 10 candidates per input, each using a different sampling instance (e.g., different random seeds for furthest point sampling).  \n\u2003\u2003\u2013 For each candidate:  \n\u2003\u2003\u2003\u2013 Validate the CAD code syntactically and using the CAD validation routine (\u03d5_syn and \u03d5_cad).  \n\u2003\u2003\u2013 Choose the best candidate (e.g., the one that is valid and closest to the ground truth based on evaluation metrics).\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n6. EXPERIMENTS & EVALUATION  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nA. Datasets for Evaluation  \n\u2003\u2022 DeepCAD: 8046 test models; if needed, convert existing DeepCAD CAD representations to CadQuery Python code.  \n\u2003\u2022 Fusion360: 1725 test models; sample point clouds from available CAD meshes.  \n\u2003\u2022 CC3D (real-world): 2973 models; note these include noise, missing parts, and smoothed edges.\n\nB. Evaluation Metrics  \n\u2003\u2022 Chamfer Distance (CD):  \n\u2003\u2003\u2013 Compute mean and median CD using 8192 points sampled from the surfaces.  \n\u2003\u2003\u2013 CD values should be scaled (multiplied by 10\u00b3 as in the paper).  \n\u2003\u2022 Intersection over Union (IoU):  \n\u2003\u2003\u2013 Compute IoU between the reconstructed CAD model\u2019s mesh and the ground truth mesh, expressed as a percentage.  \n\u2003\u2022 Invalidity Ratio (IR):  \n\u2003\u2003\u2013 Percentage of generated CAD code sequences that do not produce a valid CAD model when executed.  \n\u2003\u2022 (Optionally) Command and Parameter Accuracy:  \n\u2003\u2003\u2013 Evaluate the ability to reproduce specific CAD commands and numerical parameters as done in [48].\n\nC. Additional Experiments  \n\u2003\u2022 CAD-QA Pipeline:  \n\u2003\u2003\u2013 Use the generated CAD Python code as input for an off-the-shelf LLM (e.g., GPT-4o) to answer CAD-specific questions.  \n\u2003\u2003\u2013 Compare accuracy with baseline methods (e.g., CAD-SIGNet and PointLLM).  \n\u2003\u2022 Editing Pipeline:  \n\u2003\u2003\u2013 Use a refactoring prompt (as demonstrated in the paper) to have GPT-4o generate code that integrates interactive editability (e.g., using ipywidgets for sliders).  \n\u2003\u2003\u2013 Test the usability of the output in an interactive environment like a Jupyter Notebook.\n\nD. Ablation Studies Recap  \n\u2003\u2022 Compare performance (CD, IoU, IR) for:  \n\u2003\u2003\u2013 Different training dataset sizes (DeepCAD 160k vs. generated 1M samples).  \n\u2003\u2003\u2013 With and without test-time sampling.  \n\u2003\u2003\u2013 Varying number of input points and different LLM sizes.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n7. IMPLEMENTATION CONSIDERATIONS & UNCERTAINTIES  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nA. Key Implementation Points  \n\u2003\u2022 Use PyTorch (or an equivalent deep learning framework) to integrate the projection module and to fine-tune the LLM.  \n\u2003\u2022 Leverage HuggingFace libraries for model loading and tokenization (ensure that Qwen2 models are available or consider alternatives if not).  \n\u2003\u2022 Interface with CadQuery for both code generation and code execution (to verify validity).  \n\u2003\u2022 Use PythonOCC\u2019s BRepCheck (or similar CAD validation libraries) to assess geometric validity of the reconstructed models.\n\nB. Unclear/Missing Details to Clarify  \n\u2003\u2022 Specific configuration details of the Fourier positional encoding (frequency values, number of components) may require a design decision or further clarification from the supplementary materials.  \n\u2003\u2022 The exact procedure for duplicate detection in the generated dataset is mentioned briefly; decide on a reproducible method (e.g., using hash checks on code strings).  \n\u2003\u2022 Details around integrating point cloud tokens with text tokens in the LLM (e.g., handling different modalities) might require experimentation.  \n\u2003\u2022 Handling code tokenization for Python code: ensure that the vocabulary covers all necessary symbols and that the tokenizer is compatible with the chosen LLM.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n8. ROADMAP SUMMARY  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nStep 1. Data Generation  \n\u2003\u2022 Implement and test Algorithms 1 and 2 to generate valid, diverse CAD Python code samples paired with corresponding CAD models and point clouds.  \n\u2003\u2022 Validate each sample (syntax, CAD geometry, duplicates).\n\nStep 2. Model Construction  \n\u2003\u2022 Build the point cloud projector using furthest point sampling, Fourier encoding, and a linear projection layer.  \n\u2003\u2022 Load and prepare the pre-trained Qwen2-1.5B LLM; adapt its input pipeline to accept both point cloud tokens and code tokens.\n\nStep 3. Training  \n\u2003\u2022 Integrate both sub-modules and set up an end-to-end training loop with NLL loss.  \n\u2003\u2022 Work with the specified hyperparameters (AdamW, learning rate, batch size, iterations, etc.).  \n\u2003\u2022 Augment point clouds with Gaussian noise as specified.\n\nStep 4. Inference Pipeline  \n\u2003\u2022 Develop a generation function to produce CAD Python code from new point clouds using autoregressive decoding.  \n\u2003\u2022 Implement test-time sampling to generate and validate multiple output candidates.\n\nStep 5. Experiments & Evaluation  \n\u2003\u2022 Evaluate on DeepCAD, Fusion360, and CC3D datasets using CD, IoU, and IR metrics.  \n\u2003\u2022 Run CAD-QA and editing experiments using GPT-4o to assess interpretability and interactive editing.\n\nStep 6. Ablations and Benchmarking  \n\u2003\u2022 Conduct controlled ablation experiments varying training data, input point cloud size, and LLM capacity.  \n\u2003\u2022 Compare against baselines reported in the paper.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nCONCLUSION  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nThis roadmap outlines a detailed plan that covers the full reproduction pipeline\u2014from dataset generation and model design to training, inference, and evaluation. Although some implementation details (e.g., Fourier encoding specifics and duplicate detection methods) require further clarification or design choices, this plan should serve as a robust foundation once you proceed to write the final code.\n\n-----\n\n## Design\n[CONTENT]\n{\n    \"Implementation approach\": \"We will build a modular system using open-source libraries: PyTorch for deep learning, HuggingFace Transformers for loading and fine-tuning the pre-trained Qwen2 LLM, NumPy for numerical operations, and CadQuery for CAD code generation and validation. The system will consist of a procedural dataset generator for creating CAD models as Python CadQuery code combined with corresponding point clouds, a point cloud processor that applies furthest point sampling and Fourier positional encoding, a model module that integrates the point cloud projector with a fine-tuned LLM for CAD code generation, and trainer/evaluation modules for end-to-end training and metric computation (Chamfer Distance, IoU, and Invalidity Ratio). The overall architecture is kept simple with a single entry point, modular component classes, and clear interfaces.\",\n    \"File list\": [\n        \"main.py\",\n        \"dataset_loader.py\",\n        \"model.py\",\n        \"trainer.py\",\n        \"evaluation.py\",\n        \"utils.py\"\n    ],\n    \"Data structures and interfaces\": \"classDiagram\\n    class Main {\\n        +__init__(config: dict)\\n        +run_experiment() -> None\\n    }\\n    class DatasetLoader {\\n        +__init__(config: dict)\\n        +generate_procedural_dataset(num_samples: int) -> list\\n        +load_existing_dataset(dataset_name: str) -> list\\n    }\\n    class PointCloudProcessor {\\n        +__init__(num_points: int)\\n        +furthest_point_sampling(point_cloud: np.ndarray) -> np.ndarray\\n        +fourier_encode(points: np.ndarray) -> np.ndarray\\n    }\\n    class Model {\\n        +__init__(params: dict)\\n        +forward(point_cloud: torch.Tensor) -> torch.Tensor\\n    }\\n    class Trainer {\\n        +__init__(model: Model, dataset: list, config: dict)\\n        +train() -> None\\n        +save_checkpoint(filepath: str) -> None\\n        +load_checkpoint(filepath: str) -> None\\n    }\\n    class Evaluation {\\n        +__init__(model: Model, dataset: list)\\n        +evaluate() -> dict\\n        +compute_chamfer_distance(pred: torch.Tensor, target: torch.Tensor) -> float\\n        +compute_iou(pred: torch.Tensor, target: torch.Tensor) -> float\\n        +compute_invalidity_ratio(outputs: list) -> float\\n    }\\n    %% Relationships\\n    Main --> DatasetLoader : uses\\n    Main --> Trainer : creates\\n    Main --> Evaluation : creates\\n    Trainer --> Model : updates\\n    Evaluation --> Model : queries\\n    Model --> PointCloudProcessor : integrates\\n\",\n    \"Program call flow\": \"sequenceDiagram\\n    participant M as Main\\n    participant DL as DatasetLoader\\n    participant PCP as PointCloudProcessor\\n    participant MD as Model\\n    participant TR as Trainer\\n    participant EV as Evaluation\\n\\n    M->>DL: load_existing_dataset(dataset_name) OR generate_procedural_dataset(num_samples)\\n    DL-->>M: return dataset\\n    M->>PCP: initialize(num_points)\\n    M->>MD: initialize(model_params)\\n    MD->>PCP: setup point cloud processing\\n    M->>TR: initialize(model, dataset, config)\\n    TR->>MD: forward(point_cloud) [for each batch]\\n    MD-->>TR: return predicted CAD code tokens\\n    TR->>TR: compute NLL loss, backpropagate, update model weights\\n    TR-->>M: signal training complete\\n    M->>EV: initialize(model, dataset)\\n    EV->>MD: forward(point_cloud) [for evaluation]\\n    MD-->>EV: return predictions\\n    EV->>EV: compute metrics (Chamfer, IoU, Invalidity Ratio)\\n    EV-->>M: return evaluation metrics\\n\",\n    \"Anything UNCLEAR\": \"The exact configuration details for the Fourier positional encoding (e.g., frequency ranges) and tokenization for Python CAD code generation are not fully specified. Also, further clarification is needed on the dataset file formats, point sampling strategy (beyond furthest point sampling), and the integration of point cloud tokens with textual code tokens into the LLM input pipeline.\"\n}\n[/CONTENT]\n\n-----\n\n## Task\n[CONTENT]\n{\n    \"Required packages\": [\n        \"numpy==1.21.0\",\n        \"torch==1.9.0\",\n        \"transformers\",\n        \"cadquery\",\n        \"pythonocc-core\",\n        \"tqdm\"\n    ],\n    \"Required Other language third-party packages\": [\n        \"No third-party dependencies required\"\n    ],\n    \"Logic Analysis\": [\n        [\n            \"dataset_loader.py\",\n            \"DatasetLoader class: Implements methods for generating a procedural CAD dataset using defined algorithms for 2D sketch and CAD model generation. Also handles loading of existing datasets (e.g., DeepCAD, Fusion360, CC3D). Depends on utility functions from utils.py (e.g., duplicate detection, configuration parsing) and uses CadQuery for validating generated CAD code.\"\n        ],\n        [\n            \"utils.py\",\n            \"Provides common utility functions such as furthest point sampling, Fourier positional encoding, CAD code validation (syntax and geometric), logging, and configuration parsing. These utilities are shared across dataset_loader.py, model.py, and trainer.py.\"\n        ],\n        [\n            \"model.py\",\n            \"Defines the Model class which integrates two main components: the PointCloudProcessor and the FineTunedLLM decoder. The PointCloudProcessor performs furthest point sampling and Fourier encoding on input point clouds. The FineTunedLLM is implemented using the transformers library (based on Qwen2) and is responsible for generating CAD code tokens. This module imports helper functions from utils.py.\"\n        ],\n        [\n            \"trainer.py\",\n            \"Trainer class: Orchestrates the end-to-end training process. It loads data from DatasetLoader, passes input batches through the Model, computes the Negative Log-Likelihood (NLL) loss, and updates model weights using AdamW with a cosine learning rate scheduler. It also provides checkpoint saving/loading functionality.\"\n        ],\n        [\n            \"evaluation.py\",\n            \"Evaluation class: Implements evaluation metrics including Chamfer Distance (CD), Intersection over Union (IoU), and Invalidity Ratio (IR). It uses the trained Model to predict CAD code from point clouds, post-processes predictions with CadQuery to verify validity, and computes the metrics against the ground truth.\"\n        ],\n        [\n            \"main.py\",\n            \"Entry point of the system: Parses configuration, uses DatasetLoader to obtain the dataset, instantiates the Model, Trainer, and Evaluation classes, and coordinates the training and evaluation pipelines. Optionally handles test-time sampling and integration of CAD-QA experiments.\"\n        ]\n    ],\n    \"Task list\": [\n        \"dataset_loader.py\",\n        \"utils.py\",\n        \"model.py\",\n        \"trainer.py\",\n        \"evaluation.py\",\n        \"main.py\"\n    ],\n    \"Full API spec\": \"\",\n    \"Shared Knowledge\": \"Shared configuration parameters (e.g., number of points, learning rate, batch size, total iterations) should be defined as global constants or in a separate config file. Utility functions (for furthest point sampling, Fourier encoding, code validation) in utils.py are reused across multiple modules. Standard libraries such as numpy and torch are used consistently across the system to manage arrays, tensors, and numerical computations.\",\n    \"Anything UNCLEAR\": \"Clarification is needed on the exact parameters for Fourier positional encoding and the tokenization approach for CAD code generation. Additionally, details regarding the dataset file formats and point cloud sampling strategies (beyond furthest point sampling) require further specification.\"\n}\n[/CONTENT]\n\n-----\n\n## Configuration file\n```yaml\n## config.yaml\ntraining:\n  learning_rate: 0.0002\n  weight_decay: 0.01\n  total_iterations: 100000\n  warmup_iterations: 1000\n  batch_size: 18\n  optimizer: \"AdamW\"\n  lr_scheduler: \"Cosine\"\n  gpu: \"NVIDIA H100\"\n  training_time: \"12 hours\"\nmodel:\n  point_cloud:\n    num_points: 256\n    noise:\n      probability: 0.5\n      std: 0.01\n    embedding_dimension: 1536\n  llm:\n    model_name: \"Qwen2-1.5B\"\n  decoder: \"Auto-regressive Python code generator\"\ndataset:\n  procedurally_generated_samples: 1000000\n  alternative_dataset: \"DeepCAD 160k\"\n  cad_library: \"CadQuery\"\nlogging:\n  log_interval: 100\n```\n-----\n\n## Instruction\nConduct a Logic Analysis to assist in writing the code, based on the paper, the plan, the design, the task and the previously specified configuration file (config.yaml). \nYou DON'T need to provide the actual code yet; focus on a thorough, clear analysis.\n\nWrite the logic analysis in 'evaluation.py', which is intended for 'Evaluation class: Implements evaluation metrics including Chamfer Distance (CD), Intersection over Union (IoU), and Invalidity Ratio (IR). It uses the trained Model to predict CAD code from point clouds, post-processes predictions with CadQuery to verify validity, and computes the metrics against the ground truth.'.\n\n-----\n\n## Logic Analysis: evaluation.py"}, {"role": "assistant", "content": "Below is a detailed logic analysis for the Evaluation module (evaluation.py). This analysis outlines how the Evaluation class should function, the step\u2010by\u2010step process for processing test samples, and how to compute the required metrics. Note that this analysis relies on configuration parameters (e.g., number of points, noise probability, etc.) from config.yaml, and it must use utility functions (such as code validation, point sampling, and Fourier encoding) defined in utils.py, as well as the Model\u2019s forward method defined in model.py.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nOverview of Evaluation Module  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n\u2022 The Evaluation class is responsible for taking a trained Model and a given dataset (each sample containing an input point cloud and its corresponding ground-truth CAD model).  \n\u2022 For each sample, the model predicts CAD code (in the form of a CadQuery Python script), which is then post-processed and validated using the CadQuery library.  \n\u2022 After obtaining a valid CAD model from the generated code, the evaluation functions will compute:\n\u2003\u2003\u2013 Chamfer Distance (CD): by sampling 8192 points from both the predicted and ground-truth CAD models.\n\u2003\u2003\u2013 Intersection over Union (IoU): computed on the resulting meshes (or voxelizations) of the CAD models.\n\u2003\u2003\u2013 Invalidity Ratio (IR): as the percentage of samples for which no valid CAD model is produced by the generated code.\n\u2022 Additionally, the evaluation process uses test-time sampling by generating 10 candidate predictions per input. This helps to pick the best candidate (or, if none are valid, flag the sample as invalid).\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nMain Steps in the Evaluation Process  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n\n1. Initialization  \n\u2003\u2022 The Evaluation class\u2019s constructor (__init__) accepts:\n\u2003\u2003\u2013 the trained Model instance (which already integrates the PointCloudProcessor and the fine-tuned LLM decoder),\n\u2003\u2003\u2013 the dataset (a list or iterable of samples, where each sample contains at least a point cloud and its ground-truth CAD model),\n\u2003\u2003\u2013 possible configuration information (e.g., logging interval, and number of test-time candidates).\n\n2. Iterating Over the Dataset (evaluate())  \n\u2003\u2022 For each sample in the dataset, perform the following:\n\u2003\u2003a. Extract the input point cloud and the corresponding ground-truth CAD model.\n\u2003\u2003b. Implement test-time sampling by generating 10 candidate predictions:  \n\u2003\u2003\u2003\u2013 For each candidate, apply (or reapply) the point cloud pre-processing (using furthest point sampling and potentially adding Gaussian noise using the specified probability of 0.5 and std 0.01 as in the config).  \n\u2003\u2003\u2003\u2013 Feed the processed point cloud to the model via its forward() method to obtain a sequence of predicted tokens.\n\u2003\u2003\u2003\u2013 Decode the predicted tokens into a Python code string that should reconstruct a CAD model using CadQuery.\n\u2003\u2003\u2003\u2013 Attempt to execute the CAD code (using a helper from utils.py that wraps CadQuery functions) to obtain a CAD model object.  \n\u2003\u2003\u2003\u2013 If the code execution fails (due to syntax error or producing an invalid geometry as checked by a function equivalent to \u03d5_syn and \u03d5_cad), mark that candidate as invalid.  \n\u2003\u2003c. From the candidates:\n\u2003\u2003\u2003\u2013 If one or more candidates produce a valid CAD model, select the \u201cbest\u201d candidate (for instance, the one with the lowest Chamfer Distance relative to the ground truth).  \n\u2003\u2003\u2003\u2013 If none of the candidates yield a valid CAD model, mark this sample as invalid.\n\u2003\u2003d. For the chosen candidate (if valid):\n\u2003\u2003\u2003\u2013 Sample 8192 points from the predicted CAD model\u2019s surface and from the ground-truth model (this sampling may be implemented via a utility function in utils.py).\n\u2003\u2003\u2003\u2013 Compute the Chamfer Distance (CD) between these two point sets using the compute_chamfer_distance() method.\n\u2003\u2003\u2003\u2013 Compute the Intersection over Union (IoU) by voxelizing or comparing the meshes of both models via compute_iou() method.\n\u2003\u2003e. Record the obtained CD and IoU for the sample.\n\u2003\u2003f. Also maintain a count of samples for which no valid candidate was generated (to later compute the Invalidity Ratio, IR).\n\n3. Metrics Aggregation  \n\u2003\u2022 After processing all samples:\n\u2003\u2003\u2013 Calculate the overall mean and median Chamfer Distances over all valid samples.\n\u2003\u2003\u2013 Compute the average IoU percentage.\n\u2003\u2003\u2013 Compute the Invalidity Ratio as (number of samples with no valid prediction) divided by (total number of samples).\n\u2003\u2022 Package these aggregated metrics into a dictionary (e.g., {\"mean_CD\": \u2026, \"median_CD\": \u2026, \"IoU\": \u2026, \"IR\": \u2026}) to return from the evaluate() method.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nSupporting Functions and Methods  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n\n\u2022 compute_chamfer_distance(pred_points: np.ndarray, target_points: np.ndarray) -> float  \n\u2003\u2013 This method takes two point clouds (each shaped [N\u00d73]) and computes the Chamfer Distance.  \n\u2003\u2013 One possibility is to compute, for every point in the predicted cloud, the nearest neighbor in the target cloud (and vice versa), and average these distances.  \n\u2003\u2013 An efficient implementation may use KD-tree based searches; however, the focus here is on clarity rather than optimization.\n\n\u2022 compute_iou(pred_model, target_model) -> float  \n\u2003\u2013 This function will compare the volume (or voxelized representations) of the predicted CAD model and the ground-truth model.  \n\u2003\u2013 A voxel grid is generated for each model (ideally normalized to fit within the same bounding box), and IoU is computed as (intersection volume)/(union volume).  \n\u2003\u2013 The result should be expressed as a percentage.\n\n\u2022 compute_invalidity_ratio(total_samples: int, invalid_samples: int) -> float  \n\u2003\u2013 This helper simply computes the ratio: invalid_samples / total_samples.\n\n\u2022 Utility & Exception Handling for CAD Code Execution  \n\u2003\u2013 Use helper functions (possibly defined in utils.py) to execute a given CAD code string.  \n\u2003\u2013 Wrap this in a try/except block to catch execution errors (or validation failures as per \u03d5_syn and \u03d5_cad).  \n\u2003\u2013 The function should return a flag indicating whether the CAD model is valid and, if valid, the CAD model itself which can then be used for sampling.\n\n\u2022 Logging and Progress Reporting  \n\u2003\u2013 Use tqdm to iterate over samples for progress visualization.  \n\u2003\u2013 Log progress at intervals defined by config.logging.log_interval.\n\u2003\u2013 Report individual sample metrics during evaluation (if needed) for debugging purposes.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nIntegration with the Overall Pipeline  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \n\u2022 The Evaluation class will be instantiated in main.py once the Model has been trained.  \n\u2022 It queries the Model by passing in a point cloud (already processed by the PointCloudProcessor from model.py).  \n\u2022 All configuration parameters (such as number of points, default batch size for evaluation if any, number of test-time candidates, etc.) are taken directly from the config.yaml.\n\u2022 The final evaluation output (a dictionary of metrics) will be used to compare against reported values (e.g., mean CD, median CD, IoU, IR) as described in the paper\u2019s experimental results sections.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nSummary  \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \nThe Evaluation module (evaluation.py) will:\n\u20031. Loop over each sample in the provided dataset.\n\u20032. For each sample, generate 10 candidate CAD code outputs by running the Model (with slight randomness via test-time sampling).\n\u20033. Execute each candidate\u2019s CAD code (using CadQuery) and validate it.\n\u20034. For valid predictions, sample points from the predicted CAD model and compute Chamfer Distance and IoU against the ground truth.\n\u20035. Select the best candidate per sample (or mark the sample invalid if no candidate is valid).\n\u20036. Aggregate metrics across the entire dataset to compute mean and median CD, average IoU percentage, and the Invalidity Ratio.\n\u20037. Return the metrics as a dictionary for reporting and further analysis.\n\nThis detailed logic analysis should guide the development of evaluation.py to ensure consistency with the paper\u2019s methodology, the planned design, and the configuration specified in config.yaml."}]