{
    "paper_id": "cadrecode",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2025-05-19T21:25:37.129230Z"
    },
    "title": "CAD-Recode: Reverse Engineering CAD Code from Point Clouds",
    "authors": [
        {
            "first": "Danila",
            "middle": [],
            "last": "Rukhovich",
            "suffix": "",
            "affiliation": {
                "laboratory": "SnT",
                "institution": "University of Luxembourg",
                "location": {}
            },
            "email": "danila.rukhovich@uni.lu"
        },
        {
            "first": "Elona",
            "middle": [],
            "last": "Dupont",
            "suffix": "",
            "affiliation": {
                "laboratory": "SnT",
                "institution": "University of Luxembourg",
                "location": {}
            },
            "email": "elona.dupont@uni.lu"
        },
        {
            "first": "Dimitrios",
            "middle": [],
            "last": "Mallis",
            "suffix": "",
            "affiliation": {
                "laboratory": "SnT",
                "institution": "University of Luxembourg",
                "location": {}
            },
            "email": "dimitrios.mallis@uni.lu"
        },
        {
            "first": "Kseniya",
            "middle": [],
            "last": "Cherenkova",
            "suffix": "",
            "affiliation": {},
            "email": "kseniya.cherenkova@uni.lu"
        },
        {
            "first": "Anis",
            "middle": [],
            "last": "Kacem",
            "suffix": "",
            "affiliation": {
                "laboratory": "SnT",
                "institution": "University of Luxembourg",
                "location": {}
            },
            "email": "anis.kacem@uni.lu"
        },
        {
            "first": "Djamila",
            "middle": [],
            "last": "Aouada",
            "suffix": "",
            "affiliation": {
                "laboratory": "SnT",
                "institution": "University of Luxembourg",
                "location": {}
            },
            "email": "djamila.aouada@uni.lu"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Computer-Aided Design (CAD) models are typically constructed by sequentially drawing parametric sketches and applying CAD operations to obtain a 3D model. The problem of 3D CAD reverse engineering consists of reconstructing the sketch and CAD operation sequences from 3D representations such as point clouds. In this paper, we address this challenge through novel contributions across three levels: CAD sequence representation, network design, and training dataset. In particular, we represent CAD sketch-extrude sequences as Python code. The proposed CAD-Recode translates a point cloud into Python code that, when executed, reconstructs the CAD model. Taking advantage of the exposure of pre-trained Large Language Models (LLMs) to Python code, we leverage a relatively small LLM as a decoder for CAD-Recode and combine it with a lightweight point cloud projector. CAD-Recode is trained on a procedurally generated dataset of one million CAD sequences. CAD-Recode significantly outperforms existing methods across the DeepCAD, Fusion360 and realworld CC3D datasets. Furthermore, we show that our CAD Python code output is interpretable by off-the-shelf LLMs, enabling CAD editing and CAD-specific question answering from point clouds.",
    "pdf_parse": {
        "paper_id": "cadrecode",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Computer-Aided Design (CAD) models are typically constructed by sequentially drawing parametric sketches and applying CAD operations to obtain a 3D model. The problem of 3D CAD reverse engineering consists of reconstructing the sketch and CAD operation sequences from 3D representations such as point clouds. In this paper, we address this challenge through novel contributions across three levels: CAD sequence representation, network design, and training dataset. In particular, we represent CAD sketch-extrude sequences as Python code. The proposed CAD-Recode translates a point cloud into Python code that, when executed, reconstructs the CAD model. Taking advantage of the exposure of pre-trained Large Language Models (LLMs) to Python code, we leverage a relatively small LLM as a decoder for CAD-Recode and combine it with a lightweight point cloud projector. CAD-Recode is trained on a procedurally generated dataset of one million CAD sequences. CAD-Recode significantly outperforms existing methods across the DeepCAD, Fusion360 and realworld CC3D datasets. Furthermore, we show that our CAD Python code output is interpretable by off-the-shelf LLMs, enabling CAD editing and CAD-specific question answering from point clouds.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Computer-Aided Design (CAD) modeling is the standard approach for designing manufactured objects, ranging from furniture to mechanical components [3, 30] . However, creating a 3D CAD model is a time-consuming task that demands specialized expertise, as the model must not only capture the object's shape but also maintain its functional requirements-commonly referred to as the design intent [4, 27] . To streamline this process, 3D CAD reverse engineering aims at generating CAD models directly from 3D scanned objects, offering a faster and more accessible pathway to CAD creation [17] . Automated 3D CAD reverse engineering has a long history in the fields of computer vision and graphics [13, 43] , with goals evolving alongside advancements in the field. These objectives have progressed from identifying CAD parts in 3D point clouds [43] to predicting the sequence of steps a designer may take to recreate a 3D scanned object in CAD software [21, 34] . This latter goal is particularly appealing, as it aims not only to produce a final CAD parametric model but also to capture the design steps behind it, enabling further editing within CAD software [21, 45] . In CAD software, designers typically construct their CAD model as feature-based design sequences, where a sequence of 2D sketches is transformed into 3D objects via opera-tions such as extrusion and revolution [47, 50] . Following the release of large CAD datasets [7, 22, 47] , recent works have focused on learning feature-based CAD sequences from input point clouds, specifically as sketchextrude sequences [12, 21, 28, 33, 39, 45, 48] . As depicted in Figure 1 (a), although varying in methodology, these approaches share a common pipeline: (1) crafting a CAD sketch-extrude sequence representation, (2) converting raw CAD data [22, 47] into this format, and (3) training dedicated neural networks to output these representations from input point clouds.",
                "cite_spans": [
                    {
                        "start": 146,
                        "end": 149,
                        "text": "[3,",
                        "ref_id": null
                    },
                    {
                        "start": 150,
                        "end": 153,
                        "text": "30]",
                        "ref_id": null
                    },
                    {
                        "start": 392,
                        "end": 395,
                        "text": "[4,",
                        "ref_id": null
                    },
                    {
                        "start": 396,
                        "end": 399,
                        "text": "27]",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 583,
                        "end": 587,
                        "text": "[17]",
                        "ref_id": null
                    },
                    {
                        "start": 692,
                        "end": 696,
                        "text": "[13,",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 697,
                        "end": 700,
                        "text": "43]",
                        "ref_id": null
                    },
                    {
                        "start": 839,
                        "end": 843,
                        "text": "[43]",
                        "ref_id": null
                    },
                    {
                        "start": 948,
                        "end": 952,
                        "text": "[21,",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 953,
                        "end": 956,
                        "text": "34]",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 1156,
                        "end": 1160,
                        "text": "[21,",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 1161,
                        "end": 1164,
                        "text": "45]",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 1377,
                        "end": 1381,
                        "text": "[47,",
                        "ref_id": null
                    },
                    {
                        "start": 1382,
                        "end": 1385,
                        "text": "50]",
                        "ref_id": "BIBREF49"
                    },
                    {
                        "start": 1436,
                        "end": 1439,
                        "text": "22,",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 1440,
                        "end": 1443,
                        "text": "47]",
                        "ref_id": null
                    },
                    {
                        "start": 1577,
                        "end": 1581,
                        "text": "[12,",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 1582,
                        "end": 1585,
                        "text": "21,",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 1586,
                        "end": 1589,
                        "text": "28,",
                        "ref_id": null
                    },
                    {
                        "start": 1590,
                        "end": 1593,
                        "text": "33,",
                        "ref_id": null
                    },
                    {
                        "start": 1594,
                        "end": 1597,
                        "text": "39,",
                        "ref_id": null
                    },
                    {
                        "start": 1598,
                        "end": 1601,
                        "text": "45,",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 1602,
                        "end": 1605,
                        "text": "48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 1799,
                        "end": 1803,
                        "text": "[22,",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 1804,
                        "end": 1807,
                        "text": "47]",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 1630,
                        "end": 1631,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1."
            },
            {
                "text": "Despite recent advances in feature-based CAD reverse engineering, key limitations constrain the broader applicability of existing approaches. Firstly, existing methods often use customized CAD representations, such as custom CAD languages [12, 21, 34, 48] or simplified extrusion shapes [28, 39, 45] , to facilitate model training. These representations are difficult to interpret, require postprocessing to be compatible with CAD tools, and restrict design capabilities to basic operations. Secondly, these approaches typically rely on designing networks that output language-like CAD representations [12, 21] and training them from scratch. This requires the networks to learn not only the geometry of the point clouds, but also the syntax of the CAD sequence representation.",
                "cite_spans": [
                    {
                        "start": 239,
                        "end": 243,
                        "text": "[12,",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 244,
                        "end": 247,
                        "text": "21,",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 248,
                        "end": 251,
                        "text": "34,",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 252,
                        "end": 255,
                        "text": "48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 287,
                        "end": 291,
                        "text": "[28,",
                        "ref_id": null
                    },
                    {
                        "start": 292,
                        "end": 295,
                        "text": "39,",
                        "ref_id": null
                    },
                    {
                        "start": 296,
                        "end": 299,
                        "text": "45]",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 602,
                        "end": 606,
                        "text": "[12,",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 607,
                        "end": 610,
                        "text": "21]",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1."
            },
            {
                "text": "In this paper, we pose the following question: In view of the recent breakthrough performance of Large Language Models (LLMs), how can their advanced language understanding be leveraged for CAD reverse engineering?",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1."
            },
            {
                "text": "To address this question, we base our approach on three key observations: (1) LLMs can generate valid Python code [36, 55] , (2) modern CAD software increasingly supports modeling through Python scripting [10] , and (3) recent efforts have shown that LLMs can be fine-tuned to process point clouds [49, 61] . As shown in Figure 1 (b), we propose CAD-Recode, a solution for CAD reverse engineering by fine-tuning an LLM to map input point clouds into CAD sketch-extrude sequences represented as Python code. In particular, instead of crafting a CAD representation, we base our representation on the existing Python CadQuery library [10] . This code-based representation is not only interpretable but also inherently allows for incorporating modular CAD features and design practices such as reusing design elements and abstracting low-level design steps (e.g. 3D box to represent a four-line sketch of a square and its extrusion). To learn the mapping between point clouds and CAD Python code, we fine-tune a pre-trained LLM, Qwen2-1.5B [55], augmented with a lightweight, trainable point cloud projector. To train CAD-Recode, a potential approach could be using existing sketch-extrude datasets [47, 48] and converting them to Python CadQuery code. However, these datasets are limited in size and design features included due to the efforts required to con-vert their original proprietary representation into one that is suitable for learning. As a solution, we propose a procedurally generated training dataset composed of one million CAD sketch-extrude sequences as Python CadQuery code. This dataset consists of CadQuery Python scripts generated following predefined heuristics with randomized parameter selection. The execution of each generated script results in a parametric CAD model. Unlike existing CAD datasets, this procedurally generated dataset provides an alternative for learning the mapping between point clouds and CAD sketch-extrude sequences in Python code, with full control over the design features, patterns and dataset size included during training. Our contributions can be summarized to: \u2022 A CAD sketch-extrude sequence representation in Python code using CadQuery [10] for CAD reverse engineering.",
                "cite_spans": [
                    {
                        "start": 74,
                        "end": 77,
                        "text": "(1)",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 114,
                        "end": 118,
                        "text": "[36,",
                        "ref_id": null
                    },
                    {
                        "start": 119,
                        "end": 122,
                        "text": "55]",
                        "ref_id": null
                    },
                    {
                        "start": 205,
                        "end": 209,
                        "text": "[10]",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 298,
                        "end": 302,
                        "text": "[49,",
                        "ref_id": "BIBREF48"
                    },
                    {
                        "start": 303,
                        "end": 306,
                        "text": "61]",
                        "ref_id": null
                    },
                    {
                        "start": 631,
                        "end": 635,
                        "text": "[10]",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 1195,
                        "end": 1199,
                        "text": "[47,",
                        "ref_id": null
                    },
                    {
                        "start": 1200,
                        "end": 1203,
                        "text": "48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 2190,
                        "end": 2194,
                        "text": "[10]",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 328,
                        "end": 329,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1."
            },
            {
                "text": "\u2022 CAD-Recode, the first LLM-based CAD reverse engineering model designed to predict CAD Python code from point clouds. The model, consisting of a pre-trained LLM and a point cloud projector is trained end-to-end to generate code that reconstructs the input geometry. \u2022 A one million procedurally generated training dataset of CAD sketch-extrude sequences as CadQuery Python code. This provides precise control over dataset size, features, and design patterns included during training, re-",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1."
            },
            {
                "text": "sulting in significant performance improvement. We will make this dataset publicly accessible. \u2022 Extensive experiments on three publicly available datasets show that CAD-Recode achieves substantial improvements over state-of-the-art methods in CAD reverse engineering. Moreover, we show that CAD-Recode, when operating on point clouds and generating CAD code, can be integrated with an off-the-shelf LLM to perform CAD Question Answering (CAD-QA) and CAD editing from point clouds. Paper Organization: The rest of the paper is organized as follows. Section 2 reviews related works. Section 3 introduces the CAD code representation and the proposed synthetic dataset. CAD-Recode is formulated and described in Section 4. Experiments are presented in Section 5. Finally, conclusions and future works are given in Section 6.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1."
            },
            {
                "text": "LLM, Point Cloud and CAD: Recent works have explored integrating point clouds with LLMs for various tasks, including 3D generation [56, 62] , captioning [16, 18, 49] , and question answering [6, 19] . These approaches typically employ complex point cloud encoders, either aligning with CLIP embeddings [31, 53, 54, 61, 64] or directly with LLM feature spaces [49] . Such methods require two-stage training: first pre-training the point cloud encoder, then finetuning with the LLM through instruction-based prompts.",
                "cite_spans": [
                    {
                        "start": 131,
                        "end": 135,
                        "text": "[56,",
                        "ref_id": "BIBREF55"
                    },
                    {
                        "start": 136,
                        "end": 139,
                        "text": "62]",
                        "ref_id": "BIBREF61"
                    },
                    {
                        "start": 153,
                        "end": 157,
                        "text": "[16,",
                        "ref_id": null
                    },
                    {
                        "start": 158,
                        "end": 161,
                        "text": "18,",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 162,
                        "end": 165,
                        "text": "49]",
                        "ref_id": "BIBREF48"
                    },
                    {
                        "start": 191,
                        "end": 194,
                        "text": "[6,",
                        "ref_id": null
                    },
                    {
                        "start": 195,
                        "end": 198,
                        "text": "19]",
                        "ref_id": null
                    },
                    {
                        "start": 302,
                        "end": 306,
                        "text": "[31,",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 307,
                        "end": 310,
                        "text": "53,",
                        "ref_id": "BIBREF52"
                    },
                    {
                        "start": 311,
                        "end": 314,
                        "text": "54,",
                        "ref_id": null
                    },
                    {
                        "start": 315,
                        "end": 318,
                        "text": "61,",
                        "ref_id": null
                    },
                    {
                        "start": 319,
                        "end": 322,
                        "text": "64]",
                        "ref_id": "BIBREF63"
                    },
                    {
                        "start": 359,
                        "end": 363,
                        "text": "[49]",
                        "ref_id": "BIBREF48"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Works",
                "sec_num": "2."
            },
            {
                "text": "In parallel, recent works have started exploring LLMs' capabilities in a range of CAD-related tasks. Reparam-CAD [23] infers shape variations from parametric models and text descriptions, while CADTalk [60] generates semantic descriptions of CAD parts. The works in [1, 2] focus on the generation of CAD models from text using LLMs, and SGP-Benchmark [38] evaluates LLMs' understanding of CAD sketch-extrude sequences using CADspecific question answering. While Img2CAD [57] attempts CAD reverse engineering from images using GPT-4V [36] , it still requires a separate transformer for parameter inference. In contrast, CAD-Recode introduces the first approach for point cloud to CAD reconstruction combining point clouds with the sequence modeling capabilities of pre-trained LLMs.",
                "cite_spans": [
                    {
                        "start": 113,
                        "end": 117,
                        "text": "[23]",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 202,
                        "end": 206,
                        "text": "[60]",
                        "ref_id": "BIBREF59"
                    },
                    {
                        "start": 266,
                        "end": 269,
                        "text": "[1,",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 270,
                        "end": 272,
                        "text": "2]",
                        "ref_id": null
                    },
                    {
                        "start": 351,
                        "end": 355,
                        "text": "[38]",
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 470,
                        "end": 474,
                        "text": "[57]",
                        "ref_id": "BIBREF56"
                    },
                    {
                        "start": 533,
                        "end": 537,
                        "text": "[36]",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Works",
                "sec_num": "2."
            },
            {
                "text": "CAD Reverse Engineering from Point Cloud: CAD reverse engineering aims to reconstruct parametric CAD models from 3D shapes (e.g., meshes or point clouds) in a compatible representation with CAD software. A key challenge lies in the choice of this representation. A line of works attempts to address sub-problems of the CAD reverse engineering task by focusing on parameter estimation for edges and surface primitives [8, 9, 15, 26, 32, 42, 46, 63] or reconstructing B-Rep construction history [11, 24, 47, 50] .",
                "cite_spans": [
                    {
                        "start": 417,
                        "end": 420,
                        "text": "[8,",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 421,
                        "end": 423,
                        "text": "9,",
                        "ref_id": null
                    },
                    {
                        "start": 424,
                        "end": 427,
                        "text": "15,",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 428,
                        "end": 431,
                        "text": "26,",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 432,
                        "end": 435,
                        "text": "32,",
                        "ref_id": null
                    },
                    {
                        "start": 436,
                        "end": 439,
                        "text": "42,",
                        "ref_id": "BIBREF41"
                    },
                    {
                        "start": 440,
                        "end": 443,
                        "text": "46,",
                        "ref_id": null
                    },
                    {
                        "start": 444,
                        "end": 447,
                        "text": "63]",
                        "ref_id": "BIBREF62"
                    },
                    {
                        "start": 493,
                        "end": 497,
                        "text": "[11,",
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 498,
                        "end": 501,
                        "text": "24,",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 502,
                        "end": 505,
                        "text": "47,",
                        "ref_id": null
                    },
                    {
                        "start": 506,
                        "end": 509,
                        "text": "50]",
                        "ref_id": "BIBREF49"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Works",
                "sec_num": "2."
            },
            {
                "text": "In order to obtain a representation that is closer to CAD modelling, several methods [14, 20, 29, 58, 59 ] use Constructive Solid Geometry (CSG), representing models as compositions of 3D primitives and Boolean operations. While this enables reconstruction, the CSG representation diverges from modern CAD workflows [50] .",
                "cite_spans": [
                    {
                        "start": 85,
                        "end": 89,
                        "text": "[14,",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 90,
                        "end": 93,
                        "text": "20,",
                        "ref_id": null
                    },
                    {
                        "start": 94,
                        "end": 97,
                        "text": "29,",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 98,
                        "end": 101,
                        "text": "58,",
                        "ref_id": null
                    },
                    {
                        "start": 102,
                        "end": 104,
                        "text": "59",
                        "ref_id": null
                    },
                    {
                        "start": 316,
                        "end": 320,
                        "text": "[50]",
                        "ref_id": "BIBREF49"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Works",
                "sec_num": "2."
            },
            {
                "text": "Recent works have adopted the more CAD-aligned sketch-extrude representation, introduced by Deep-CAD [48] for CAD generation [51, 52] or predicting extrusion cylinder [39, 45] . Considering the sequential nature of sketch-extrude operations, methods have explored a template-based approach [25] given a rounded voxel input representation. Furthermore, transformer architectures have been investigated for both autoregressive [21] and non-autoregressive [12, 48] prediction of sketch-extrude sequences from point clouds. The work in [34] combines a lightweight pre-trained language model [40] with a point cloud encoder using a diffusion-based approach. Alternative methods using self-supervised [28] or unsupervised [29] learning still face integration challenges due to their non-standard sketch representations (e.g., signed distance functions). In contrast to these approaches that require full parameter learning of specialized networks for both CAD geometry and representation syntax, we leverage pre-trained LLMs that have been exposed to programming patterns through large-scale training on code repositories. Our method outputs Python code using the CadQuery library [10] that is directly executable and can easily be interpreted. Additionally, we address the data limitation through automated generation of a large-scale training dataset, enabling full control over design features included during training. Modern feature-based CAD modeling relies on sequences of 2D sketches and operations to create 3D models. Designers first draw geometric primitives (lines, arcs, circles) on a selected plane, then apply operations like extrusion or revolution to generate 3D geometry [50] . As depicted in Figure 2 (a), we focus on sketch-extrusion sequences, a fundamental CAD modeling pattern widely adopted in previous works [21, 48, 51] . Below, we present our CAD representation, highlighting its advantages over existing language-like encodings, and describe our procedurally generated training data.",
                "cite_spans": [
                    {
                        "start": 101,
                        "end": 105,
                        "text": "[48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 125,
                        "end": 129,
                        "text": "[51,",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 130,
                        "end": 133,
                        "text": "52]",
                        "ref_id": "BIBREF51"
                    },
                    {
                        "start": 167,
                        "end": 171,
                        "text": "[39,",
                        "ref_id": null
                    },
                    {
                        "start": 172,
                        "end": 175,
                        "text": "45]",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 290,
                        "end": 294,
                        "text": "[25]",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 425,
                        "end": 429,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 453,
                        "end": 457,
                        "text": "[12,",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 458,
                        "end": 461,
                        "text": "48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 532,
                        "end": 536,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 587,
                        "end": 591,
                        "text": "[40]",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 716,
                        "end": 720,
                        "text": "[29]",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 1175,
                        "end": 1179,
                        "text": "[10]",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 1683,
                        "end": 1687,
                        "text": "[50]",
                        "ref_id": "BIBREF49"
                    },
                    {
                        "start": 1827,
                        "end": 1831,
                        "text": "[21,",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 1832,
                        "end": 1835,
                        "text": "48,",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 1836,
                        "end": 1839,
                        "text": "51]",
                        "ref_id": "BIBREF50"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 1712,
                        "end": 1713,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Related Works",
                "sec_num": "2."
            },
            {
                "text": "Recent approaches in CAD language modeling [12, 21, 33, 48, 51] encode sketch-extrude sequences as numerical vectors representing features and their parameters as shown in Figure 2(b) . However, this representation constrains the modeling to specific CAD practices, lacks interpretability, and requires post-processing for CAD kernel compatibility. We propose using CadQuery [10] Python code to represent sketch-extrude sequences for CAD reverse engineering, offering the following advantages:",
                "cite_spans": [
                    {
                        "start": 43,
                        "end": 47,
                        "text": "[12,",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 48,
                        "end": 51,
                        "text": "21,",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 52,
                        "end": 55,
                        "text": "33,",
                        "ref_id": null
                    },
                    {
                        "start": 56,
                        "end": 59,
                        "text": "48,",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 60,
                        "end": 63,
                        "text": "51]",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 375,
                        "end": 379,
                        "text": "[10]",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 179,
                        "end": 183,
                        "text": "2(b)",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "CadQuery Code",
                "sec_num": "3.1."
            },
            {
                "text": "Modularity of CAD Features and Design Practices: Existing language-based CAD reverse engineering methods rely on custom representations of low-level geometric features (lines, arcs, circles) for sketch construction [41, 48] . This approach inherently limits the range of implementable features and design practices. In contrast, CadQuery provides comprehensive built-in CAD functionality, encom-passing both low-level features and higher-level geometries like cylinders and boxes as shown in Figure 2(c ). Furthermore, its programmatic nature enables variable reuse and code modularity. This allows reusing common design features or practices across models, as illustrated by the shared center coordinates across two circles in Figure 2 (c) . This representation naturally accommodates diverse CAD features and design practices without requiring complex custom encodings or post-processing steps. The training of current CAD sketch-extrude reverse engineering methods [12, 21, 33, 34, 48] predominantly rely on datasets collected from CAD model repositories [7, 22, 47] . Considerable efforts are required to parse the CAD models from their original proprietary representations to a suitable one for deep learning [47, 48] . As a result, existing datasets are restricted not only in scale, but also in control over the design features and patterns included in training.",
                "cite_spans": [
                    {
                        "start": 215,
                        "end": 219,
                        "text": "[41,",
                        "ref_id": null
                    },
                    {
                        "start": 220,
                        "end": 223,
                        "text": "48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 968,
                        "end": 972,
                        "text": "[12,",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 973,
                        "end": 976,
                        "text": "21,",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 977,
                        "end": 980,
                        "text": "33,",
                        "ref_id": null
                    },
                    {
                        "start": 981,
                        "end": 984,
                        "text": "34,",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 985,
                        "end": 988,
                        "text": "48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 1062,
                        "end": 1065,
                        "text": "22,",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 1066,
                        "end": 1069,
                        "text": "47]",
                        "ref_id": null
                    },
                    {
                        "start": 1214,
                        "end": 1218,
                        "text": "[47,",
                        "ref_id": null
                    },
                    {
                        "start": 1219,
                        "end": 1222,
                        "text": "48]",
                        "ref_id": "BIBREF47"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 499,
                        "end": 502,
                        "text": "2(c",
                        "ref_id": null
                    },
                    {
                        "start": 735,
                        "end": 740,
                        "text": "2 (c)",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "CadQuery Code",
                "sec_num": "3.1."
            },
            {
                "text": "To address these limitations, we propose to procedurally generate a training dataset of one million CAD models in the form of sketch-extrude sequences written in Python CadQuery [10] code. Our proposed pipeline randomly generates sketch and CAD operation parameters guided by topological and geometrical heuristics to ensure control over the amount of generated models and the features in the generated codes. The algorithm outlining the steps of this generation pipeline is provided in the supplementary materials along with further statistical analysis of the generated dataset. The modularity of CAD features is incorporated by utilizing both low-level primitives (i.e. circles, lines, and arcs) and their abstractions (i.e. boxes, cylinders, and rectangles) as well as reusing design elements within the generated sequences. In this work, we focus on some aspects of modularity (i.e., reusing point coordinates, extrusion planes, and abstracting basic shapes such as boxes and cylinders). Further modularity features (e.g., reusing functions corresponding to arbitrary CAD parts, additional CAD operations) can also be integrated in the future. Note that although our generated dataset does not include sequences from human-designed CAD models, it offers significant control over the features and design patterns to which the network is exposed during training. Examples of generated CAD models are shown in Figure 3 .",
                "cite_spans": [
                    {
                        "start": 178,
                        "end": 182,
                        "text": "[10]",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 1419,
                        "end": 1420,
                        "text": "3",
                        "ref_id": "FIGREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Procedurally Generated Training Dataset",
                "sec_num": "3.2."
            },
            {
                "text": "Building on the introduced CAD code representation and generated training dataset outlined in the previous section, this section introduces CAD-Recode, our proposed model for predicting CAD sketch-extrude sequences as code from input 3D point clouds. We formalize the problem of CAD code prediction, describe the architecture of CAD-Recode, and detail its training and inference processes.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "CAD-Recode",
                "sec_num": "4."
            },
            {
                "text": "Let us denote the set of all possible code strings as \u03a3 * , where each code string is composed of elements from the finite set of alphanumeric characters and operators in the programming language \u03a3. Let \u03d5 syn : \u03a3 * \u2192 {True, False} represent the syntactic validation function for Python programming rules (e.g., variable declarations, expression syntax, and statement structure), and \u03d5 cad : \u03a3 * \u2192 {True, False} denote the validation function for CAD-specific rules. The latter includes the syntactic validity of the code w.r.t. to the CAD library, i.e. CadQuery [10] , and the geometric validity of the reconstructed model from the code (e.g., an extrusion can only be applied on a closed loop of 2D primitives, a circle radius cannot be negative). An executable valid CAD code can be formally described by a code string C \u2208 C, where",
                "cite_spans": [
                    {
                        "start": 562,
                        "end": 566,
                        "text": "[10]",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem Statement",
                "sec_num": "4.1."
            },
            {
                "text": "C = {w \u2208 \u03a3 * | \u03d5 syn (w) \u2227 \u03d5 cad (w)} ,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem Statement",
                "sec_num": "4.1."
            },
            {
                "text": "represents the set of all valid CAD codes. This formulation ensures that any code string w in C satisfies both the syntactic requirements of Python (\u03d5 syn ) and the CAD code validation rules (\u03d5 cad ). Let P = {p i } n i=1 \u2208 R n\u00d73 denote an input point cloud, where each point p i \u2208 R 3 represents 3D Cartesian coordinates. The objective of CAD-Recode is to learn a mapping",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem Statement",
                "sec_num": "4.1."
            },
            {
                "text": "... Point Cloud CAD model <s> import cadquery ... extrude(15) Large Language Model import ... Python interpreter Tokenizer ... ... Linear Layer finalize().extrude(15)<e> \u03a8 : R n\u00d73 \u2192 C, C = \u03a8(P) , that maps the input point cloud to a valid CAD code C \u2208 C such that the code, when executed, produces a CAD model geometrically approximating the input point cloud P. Note that the CAD code execution results in a Boundary-Representation (B-Rep) [24]. Unlike meshes or point clouds, B-Rep is a parametric representation of the CAD model's geometry, enabling seamless integration into modern CAD software and allowing for further modifications. The goal of CAD-Recode is to infer the CAD code describing the design steps of the CAD model, that when executed results in a B-Rep.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Problem Statement",
                "sec_num": "4.1."
            },
            {
                "text": "CAD-Recode builds on pre-trained LLMs and their prior exposure to Python code, augmenting these with point cloud processing capabilities and CAD-specific Python code knowledge. As shown in Figure 4 , its architecture consists of two components: (1) a point cloud projector mapping the 3D point cloud into learnable tokens, and (2) a pretrained LLM-based auto-regressive CAD code decoder.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 196,
                        "end": 197,
                        "text": "4",
                        "ref_id": "FIGREF5"
                    }
                ],
                "eq_spans": [],
                "section": "Proposed Model Architecture",
                "sec_num": "4.2."
            },
            {
                "text": "Point Cloud Projection Module: CAD-Recode introduces a lightweight projection module \u03a8 p that directly maps a dense point cloud P \u2208 R n\u00d7dp , where d p = 3 corresponds to the dimension of point coordinates, into a sequence of n p \u226a n query tokens",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Model Architecture",
                "sec_num": "4.2."
            },
            {
                "text": "Q p = [q 1 p , . . . , q np p ] \u2208 R np\u00d7dq , of embedding dimension d q .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Model Architecture",
                "sec_num": "4.2."
            },
            {
                "text": "The point cloud projector, trained in an end-to-end manner with the CAD code decoder module, consists of three simple components:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Model Architecture",
                "sec_num": "4.2."
            },
            {
                "text": "(1) furthest point sampling to downsample the input point clouds to n p points, (2) Fourier positional encoding [62] of coordinates, and (3) a linear layer projecting the encoded coordinatesinto Q p .",
                "cite_spans": [
                    {
                        "start": 112,
                        "end": 116,
                        "text": "[62]",
                        "ref_id": "BIBREF61"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Model Architecture",
                "sec_num": "4.2."
            },
            {
                "text": "LLM as CAD Code Decoder: Our CAD code decoder, denoted as \u03a8 LLM , adapts a pre-trained LLM for the specific task of CAD code generation. We leverage the Qwen2-1.5B model [55] as our LLM backbone, chosen for its balanced trade-off between model capacity and computational re-quirements. The decoder's input consists of point query tokens Q p from the point cloud projector, augmented with n t code tokens Q t \u2208 R nt\u00d7dq obtained by tokenizing the input code as in [55]. The complete input sequence is denoted as",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Model Architecture",
                "sec_num": "4.2."
            },
            {
                "text": "[Q p ; Q t ] \u2208 R (np+nt)\u00d7dq",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Model Architecture",
                "sec_num": "4.2."
            },
            {
                "text": ", where semicolon indicates concatenation along the sequence dimension. The LLM decoder generates the CAD code sequence through next-token prediction. As in [55], each predicted token is mapped to a symbol from the vocabulary \u03a3, which includes alphanumeric characters and operators.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Model Architecture",
                "sec_num": "4.2."
            },
            {
                "text": "Overall, CAD-Recode repurposes the LLM's sequence modeling capabilities for the specialized task of translating geometric point clouds into executable CAD code.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Proposed Model Architecture",
                "sec_num": "4.2."
            },
            {
                "text": "Training Strategy: Our training process consists of a single stage. The model operates on query tokens of dimension d q = 1536 and processes input point clouds downsampled to n p = 256 points. Gaussian noise with mean zero and standard deviation of 0.01 is added to the coordinates of the input points with a probability of 0.5 per model. The network is trained on the procedurally generated CAD codes, hence exposed to the CAD features and design practices that were included in the algorithm. The training objective minimizes the Negative Log-Likelihood (NLL) of the target CAD code sequence, using special tokens (<s> and <e>) to demarcate sequence boundaries. The point cloud projector \u03a8 p learns geometric features from scratch, while the pre-trained decoder \u03a8 LLM is fine-tuned for CAD code generation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Training and Inference Details",
                "sec_num": "4.3."
            },
            {
                "text": "Inference Strategy: At inference time, the point cloud projector \u03a8 p processes the input point cloud P to generate query tokens Q p , which are then fed to the decoder along with the start token <s>. The model autoregressively generates CAD code tokens until producing a complete code sequence C ending with token <e>. Following [21] , we employ a test-time sampling approach where we generate ten distinct CAD code candidates, each from a different sampling of the input point cloud. For each candidate, we sam- ",
                "cite_spans": [
                    {
                        "start": 329,
                        "end": 333,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Training and Inference Details",
                "sec_num": "4.3."
            },
            {
                "text": "In order to validate the effectiveness of CAD-Recode, we conduct a series of experiments across two different scenarios. The first scenario focuses on the reverse engineering task, where the goal is to reconstruct a CAD sketch-extrude sequence in Python code from a given input point cloud.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "5."
            },
            {
                "text": "The second assesses the interpretability and editibility of the generated CAD code with a proprietary LLM [36] .",
                "cite_spans": [
                    {
                        "start": 106,
                        "end": 110,
                        "text": "[36]",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "5."
            },
            {
                "text": "Experimental Setup: CAD-Recode is evaluated on three test datasets: DeepCAD [48] (8046 models), Fu-sion360 [47] (1725 models), and the real-world CC3D [35] (2973 models). The point clouds are obtained by sampling points on the meshes for DeepCAD and Fusion360. The CC3D dataset provides a real-world scenario with input point clouds sampled from actual 3D scans of CAD models containing surface noise, smoothed edges and missing parts (see supplementary materials for more details). Implementation details are provided in the supplementary.",
                "cite_spans": [
                    {
                        "start": 76,
                        "end": 80,
                        "text": "[48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 151,
                        "end": 155,
                        "text": "[35]",
                        "ref_id": "BIBREF34"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Reverse Engineering",
                "sec_num": "5.1."
            },
            {
                "text": "To evaluate the quality of the predicted CAD sketch-extrude sequences, we use three metrics: Chamfer Distance (CD) [21] , Intersection over Union (IoU) [34] , and Invalidity Ratio (IR) [48] . We report both mean and median CD values computed using 8192 points to assess geometric accuracy. Reported CD values have been multiplied by 10 3 . The IoU is computed from the resulting CAD model meshes and expressed as a percentage. The IR indicates the percentage of generated sequences that fail to produce a valid CAD model.",
                "cite_spans": [
                    {
                        "start": 115,
                        "end": 119,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 152,
                        "end": 156,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 185,
                        "end": 189,
                        "text": "[48]",
                        "ref_id": "BIBREF47"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Metrics:",
                "sec_num": null
            },
            {
                "text": "Results & Analysis: Table 1 presents results on the test sets of DeepCAD and Fusion360 datasets, where CAD-Recode establishes new state-of-the-art performance across all metrics. Note that the results of stateof-the-art methods in Table 1 are borrowed from [34] , except for CAD-SIGNet [21] , MultiCAD [33] , Tran-sCAD [12] , and DeepCAD [48] which were taken from [21] and [12] . First, we convert the DeepCAD dataset (160 k models) to CadQuery Python code and use it to train CAD-Recode (results are in row before last of Table 1 ). When trained on DeepCAD dataset as existing methods, CAD-Recode outperforms them in almost all metrics. These results showcase the effectiveness of CAD-Recode and the proposed CAD code representation.",
                "cite_spans": [
                    {
                        "start": 257,
                        "end": 261,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 286,
                        "end": 290,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 302,
                        "end": 306,
                        "text": "[33]",
                        "ref_id": null
                    },
                    {
                        "start": 319,
                        "end": 323,
                        "text": "[12]",
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 338,
                        "end": 342,
                        "text": "[48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 365,
                        "end": 369,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 374,
                        "end": 378,
                        "text": "[12]",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 26,
                        "end": 27,
                        "text": "1",
                        "ref_id": "TABREF1"
                    },
                    {
                        "start": 237,
                        "end": 238,
                        "text": "1",
                        "ref_id": "TABREF1"
                    },
                    {
                        "start": 530,
                        "end": 531,
                        "text": "1",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Metrics:",
                "sec_num": null
            },
            {
                "text": "Training on 1 M generated samples results in substantial improvements in CD and IoU metrics while maintaining a negligibly low invalidity ratio (last row of Table 1 ), reflecting significantly better geometric fidelity in the predicted CAD models. CAD-Recode demonstrates a ten-fold improvement in mean CD and an increase of IoU by over 10% on both DeepCAD and Fusion360 datasets compared to the existing best methods. These results confirm that our largescale procedurally generated training dataset provides substantial benefits.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 163,
                        "end": 164,
                        "text": "1",
                        "ref_id": "TABREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Metrics:",
                "sec_num": null
            },
            {
                "text": "As illustrated in Figure 5 , this translates to consistent reconstruction quality, where CAD-Recode reliably produces CAD models that accurately capture the geometry from the input point cloud. In contrast, CAD-SIGNet [21] can generate shapes that deviate significantly from the target geometry, further highlighting the advantages of our approach.",
                "cite_spans": [
                    {
                        "start": 218,
                        "end": 222,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 25,
                        "end": 26,
                        "text": "5",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Metrics:",
                "sec_num": null
            },
            {
                "text": "In Table 2 , we evaluate DeepCAD Dataset Fusion360 Dataset Real-world CC3D Dataset Point Cloud CAD-SIGNet CAD-Recode GT Figure 5. Qualitative results on the DeepCAD, Fusion360, and CC3D datasets. For each input point cloud (first row), we compare CAD models produced by CAD-SIGNet (second) and our CAD-Recode trained on our dataset (third) with a ground truth CAD model (bottom row). While CAD-SIGNet often fails to restore the general shape, CAD-Recode outputs only slightly deviate from ground truth in most cases. Method Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 DeepCAD [48] -263 -12.7 CAD-SIGNet [21] 14.82 2.90 42.6 2.5 CAD-Recode 0.76 0.31 74.2 0.3 Table 2. Results on the CC3D dataset, where input point clouds are sampled from real 3D scans. CAD-Recode significantly outperforms DeepCAD, and CAD-SIGNet.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 9,
                        "end": 10,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Real-world Scenario:",
                "sec_num": null
            },
            {
                "text": "CAD-Recode on the real-world CC3D dataset, where input point clouds are sampled from 3D scans and contain artifacts such as surface noise, smooth edges, and missing parts. Even under these challenging conditions, our method achieves significant improvements over CAD-SIGNet [21] , with a 89% lower median CD and a 30% higher IoU, while maintaining a low IR. From the CC3D qualitative results in Figure 5 , CAD-Recode is able to recover geometries that are much closer to the ground truth than current state-of-the-art. However, it can be observed that CAD-Recode still lacks the expressiveness to model complex shapes that contain operations beyond the extrusion operation such as revolution and fillet. This can be attributed to the choice of features and design practices in the procedurally generated training dataset. Nevertheless, we believe that this can be addressed in future works by incorporating further features in the dataset generation procedure. Our results on CC3D are compared with methods previously reported for this dataset [21] , namely CAD-SIGNet and DeepCAD.",
                "cite_spans": [
                    {
                        "start": 274,
                        "end": 278,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 1044,
                        "end": 1048,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 402,
                        "end": 403,
                        "text": "5",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Real-world Scenario:",
                "sec_num": null
            },
            {
                "text": "Ablation Study: To evaluate the different components of CAD-Recode, we conduct a comprehensive ablation study on the amount of training data, test-time sampling, and the number of input points and model parameters.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Real-world Scenario:",
                "sec_num": null
            },
            {
                "text": "Training CAD-Recode on 160 k procedurally generated samples using the method described in Section 3.2 leads to significant improvements in geometric fidelity of the predicted samples over training on the DeepCAD dataset with the same amount of data (see row 2 and 3 of Table 3 ). Furthermore, scaling our training dataset to 1 M samples provides further improvements across all datasets (row 4 of Table 3 ). As compared to DeepCAD training dataset, our procedural dataset generation provides a better way of learning the mapping between point clouds and CAD codes which can be further improved by scaling up the dataset size.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 275,
                        "end": 276,
                        "text": "3",
                        "ref_id": "TABREF3"
                    },
                    {
                        "start": 403,
                        "end": 404,
                        "text": "3",
                        "ref_id": "TABREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Real-world Scenario:",
                "sec_num": null
            },
            {
                "text": "We investigate the effectiveness of the test-time sampling approach that generates multiple CAD code predictions through different point cloud samplings, as described in Section 4.3. As shown in the third and last row of Table 3 , the test-time sampling approach mainly helps reducing the ratio of invalid predicted CAD codes (IR). For comparison, CAD-SIGNet [21] employs a probability-based sampling. Yet, even without test-time sampling our method still performs better on the reconstruction metrics than CAD-SIGNet [21] .",
                "cite_spans": [
                    {
                        "start": 359,
                        "end": 363,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 518,
                        "end": 522,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 227,
                        "end": 228,
                        "text": "3",
                        "ref_id": "TABREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Real-world Scenario:",
                "sec_num": null
            },
            {
                "text": "Results in Table 4 show an ablation of the input point cloud size and the number of parameters of the LLM backbone. It can be observed that using an input point cloud of 256 points and Qwen1.5b results in the highest IoU. This setting with a relatively small input point cloud and lightweight LLM backbone provides the best balance between prediction accuracy and memory requirements. Results on all metrics are included in the supplementary materials.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 17,
                        "end": 18,
                        "text": "4",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Real-world Scenario:",
                "sec_num": null
            },
            {
                "text": "CAD-QA and LLM Interpretability: CAD SGP-Bench [38] quences encoded as in DeepCAD [48] . These questions require analyzing various geometric aspects, such as relative sizes and 3D primitive types. We extend this benchmark to evaluate CAD reverse engineering methods by using point clouds as input instead of CAD sequences. Our evaluation follows a two-stage process: first predicting sketch-extrude sequences from point clouds as CadQuery code with CAD-Recode, then using GPT-4o [36] to answer CAD-specific questions. Without requiring additional interpretation hints, our approach achieves 76.5% accuracy on this CAD-QA task (Table 5 ). For comparison, we evaluate two baseline approaches: CAD-SIGNet [21] and PointLLM [49] . When using CAD-SIGNet's output with GPT-4o, even with provided interpretation hints explaining the sequence format, the accuracy reaches only 63.2%.",
                "cite_spans": [
                    {
                        "start": 47,
                        "end": 51,
                        "text": "[38]",
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 82,
                        "end": 86,
                        "text": "[48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 479,
                        "end": 483,
                        "text": "[36]",
                        "ref_id": null
                    },
                    {
                        "start": 702,
                        "end": 706,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 720,
                        "end": 724,
                        "text": "[49]",
                        "ref_id": "BIBREF48"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 633,
                        "end": 634,
                        "text": "5",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "CAD-QA and Editability",
                "sec_num": "5.2."
            },
            {
                "text": "PointLLM, which directly processes point clouds for language tasks, achieves 42.3% accuracy when prompted with the CAD-specific questions. These results demonstrate that CAD-Recode effectively captures CAD geometric information while generating an output in a format that proprietary LLMs can naturally interpret and process.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "CAD-QA and Editability",
                "sec_num": "5.2."
            },
            {
                "text": "Editing Pipeline: Leveraging the interpretable nature of our code-based output, we present an automated editing pipeline using GPT-4o [36] . Through a simple prompt, the system refactors the generated code to expose geometric parameters via interactive sliders, enabling direct manipulation of the reconstructed model. As shown in Figure 6 , the resulting code can be directly executed in a Python environment to provide an interactive editing interface. Implementation details are provided in the supplementary materials. ",
                "cite_spans": [
                    {
                        "start": 134,
                        "end": 138,
                        "text": "[36]",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 338,
                        "end": 339,
                        "text": "6",
                        "ref_id": "FIGREF6"
                    }
                ],
                "eq_spans": [],
                "section": "CAD-QA and Editability",
                "sec_num": "5.2."
            },
            {
                "text": "This work rethinks the problem of feature-based CAD reverse engineering by approaching it through pre-trained LLMs taking advantage of CAD Python-based representation. Our key contributions include a new CAD code representation for reverse engineering sketch-extrude sequences, very large-scale procedurally generated training dataset in the form of CAD programs, and a point cloud-to-CAD code model. We demonstrate that CAD-Recode outperforms existing methods by a large margin on three datasets, including the real-world CC3D dataset. We also showcase that combining pre-trained LLMs with geometric understanding enables powerful new workflows, where designers can reconstruct CAD models from point clouds and modify them through natural language. We believe that this work will open new perspectives for CAD reverse engineering.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "6."
            },
            {
                "text": "We identify the following interesting future works: (1) further exploiting the modularity of the proposed CAD code representation, (2) scaling up the LLM and the dataset to enable reverse engineering of more complex CAD models.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "6."
            },
            {
                "text": "Acknowledgement: The present project is supported by the National Research Fund, Luxembourg under the BRIDGES2021/IS/16849599/FREE-3D and IF/17052459/CASCADES projects, and by Artec 3D.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "6."
            },
            {
                "text": "The CAD-Recode implementation uses Qwen2-1.5B as the LLM decoder. The training configuration employs the AdamW optimizer with a learning rate of 0.0002 and weight decay of 0.01, while maintaining other parameters at their default values from the HuggingFace implementation [44] , including the cosine learning rate scheduler. The training process is conducted for 100 k iterations, incorporating an initial warmup period of 1 k iterations. Using a single NVIDIA H100 GPU with a batch size of 18, the complete training process takes approximately 12 hours. For ablation study examining decoder size impact (Section 5.1 of the main paper), we utilize Qwen2-0.5B.",
                "cite_spans": [
                    {
                        "start": 273,
                        "end": 277,
                        "text": "[44]",
                        "ref_id": "BIBREF43"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Appendix A. Training Details",
                "sec_num": null
            },
            {
                "text": "In Section 3.2, the procedurally generated training dataset is presented. The main advantage of generating data over using the existing DeepCAD dataset for training is that the algorithm allows full control over the amount of data as well as the features and design patterns that the network is exposed to during training. We generate one million valid Python CadQuery code snippets, through an automated pipeline leveraging PythonOCC [37] and CadQuery [10] .",
                "cite_spans": [
                    {
                        "start": 435,
                        "end": 439,
                        "text": "[37]",
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 453,
                        "end": 457,
                        "text": "[10]",
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "B. Training Dataset Generation Algorithm",
                "sec_num": null
            },
            {
                "text": "The generation process consists of two primary components: (1) a sketch profile generator (Algorithm 1) that creates valid 2D sketches, and (2) a CAD model generator (Algorithm 2) that produces 3D CAD models from these sketches.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "B. Training Dataset Generation Algorithm",
                "sec_num": null
            },
            {
                "text": "The sketch generation process combines primitive shapes (circles and rectangles) through boolean operations (union and cut). From each generated sketch, we extract the primitives (lines, arcs, and circles) from both inner and outer loops. The validity of the generated sketch is ensured through multiple verification steps, including verifying that loops do not intersect, and each primitive has a length greater than zero. Finally, we ensure that the randomly generated CAD code has not previously been generated using the duplicate detection protocol outlined in [51] . This ensures that each sample in the dataset is unique.",
                "cite_spans": [
                    {
                        "start": 565,
                        "end": 569,
                        "text": "[51]",
                        "ref_id": "BIBREF50"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "B. Training Dataset Generation Algorithm",
                "sec_num": null
            },
            {
                "text": "The CAD model generation procedure extrudes the validated sketches and combines them through union operations. The planes on which the sketches lie are randomly generated by choosing one of the three canonical planes translated by a random amount. Each resulting model undergoes normalization to fit within a unit bounding box centered at the origin. The parameters are quantized so that the coordinates of any point on the CAD surface are within the range -100 to 100 with a minimum resolution of 1 unit. We then simplify the sequence using higher level abstractions (rectangle, box, and cylinder) by considering the sequence parameters. Our validation framework verifies that a generated code w executes without errors (\u03d5 syn ). Furthermore, we check that the executed code produces a geometric valid CAD model (\u03d5 cad ) using the BRepCheck Analyzer function from PythonOCC as in [48] . Invalid models are excluded from the dataset.",
                "cite_spans": [
                    {
                        "start": 881,
                        "end": 885,
                        "text": "[48]",
                        "ref_id": "BIBREF47"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "B. Training Dataset Generation Algorithm",
                "sec_num": null
            },
            {
                "text": "Figure 7 presents examples of CAD models alongside their corresponding CadQuery Python code from our procedurally generated dataset. It is worth noting that the generated codes are fairly compact, this was designed to facilitate training. All code examples are directly executable using a standard Python interpreter with the CadQuery library. The codes follow a consistent three-part structure:",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "7",
                        "ref_id": "FIGREF8"
                    }
                ],
                "eq_spans": [],
                "section": "B. Training Dataset Generation Algorithm",
                "sec_num": null
            },
            {
                "text": "(1) necessary library import, (2) definition of sketch planes, and (3) sketch-extrude operations combined through union.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "B. Training Dataset Generation Algorithm",
                "sec_num": null
            },
            {
                "text": "The training dataset generation procedure provides full control over the features included. In Figure 8 , it can be observed that the distribution of our CAD models is skewed towards models with larger face and edge count per model with interquartile ranges. As a result, our procedurally generated dataset provides a larger variety of models.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 102,
                        "end": 103,
                        "text": "8",
                        "ref_id": "FIGREF9"
                    }
                ],
                "eq_spans": [],
                "section": "B. Training Dataset Generation Algorithm",
                "sec_num": null
            },
            {
                "text": "Results on the real-world CC3D [7, 35] dataset are presented in Table 3 of the main paper. This scenario provides an experimental evaluation in a realistic setting, as the input point clouds are sampled from actual 3D scans of CAD models. Sample models are depicted in Figure 9 , where artifacts such as surface noise, smoothed edges, and missing parts can be observed. Furthermore, several models from the CC3D dataset are constructed using a range of operations beyond simple extrusion, including revolution, chamfer, and fillet. Consequently, the real-world CC3D dataset provides a challenging set of inputs that enables robust inthe-wild evaluation of our proposed method.",
                "cite_spans": [
                    {
                        "start": 31,
                        "end": 34,
                        "text": "[7,",
                        "ref_id": null
                    },
                    {
                        "start": 35,
                        "end": 38,
                        "text": "35]",
                        "ref_id": "BIBREF34"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 70,
                        "end": 71,
                        "text": "3",
                        "ref_id": "TABREF3"
                    },
                    {
                        "start": 276,
                        "end": 277,
                        "text": "9",
                        "ref_id": "FIGREF10"
                    }
                ],
                "eq_spans": [],
                "section": "C. Real-World CC3D Dataset",
                "sec_num": null
            },
            {
                "text": "Qualitative Results: Additional qualitative results for the reverse engineering of CAD models from point clouds are presented for DeepCAD (Figure 10 ), Fusion360 (Figure 11 ), and real-world CC3D (Figure 12 ) datasets. As de-",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 146,
                        "end": 148,
                        "text": "10",
                        "ref_id": "FIGREF1"
                    },
                    {
                        "start": 170,
                        "end": 172,
                        "text": "11",
                        "ref_id": "FIGREF1"
                    },
                    {
                        "start": 204,
                        "end": 206,
                        "text": "12",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "D. Further Experimental Results",
                "sec_num": null
            },
            {
                "text": "Algorithm 1 Generate2DSketch 1: function GENERATE2DSKETCH 2: numP rimitives \u2190 RandInt(3, 8) \u25b7 Choose random number of shape primitives 3: compositeShape \u2190 \u2205 \u25b7 Initialize empty shape 4: for i \u2190 1 to numP rimitives do \u25b7 Build shape by combining primitives 5: primitive \u2190 random from {Circle, RotatedRectangle} 6: booleanOperation \u2190 random from {Union, Cut} \u25b7 Union adds, Cut subtracts 7: compositeShape \u2190 ApplyOperation(compositeShape, primitive, booleanOperation) 8: end for 9: boundaryLoops \u2190 ExtractBoundaryLoops(compositeShape) \u25b7 Extract shape boundaries 10: boundaryComponents \u2190 \u2205 11: for loop \u2208 boundaryLoops do \u25b7 Process each boundary loop 12: (edgeSequence, isOuter) \u2190 AnalyzeBoundary(loop) \u25b7 List of parametric curves (lines, arcs, circles) 13: boundaryComponents.Append((edgeSequence, isOuter)) 14: end for 15: boundaryComponents \u2190 V alidateShapeT opology(boundaryComponents) \u25b7 Ensure valid shape topology 16: return boundaryComponents \u25b7 Returns list of (edges, boolean) tuples 17: end function Algorithm 2 GenerateCAD 1: function GENERATECAD 2: cadM odel \u2190 \u2205 \u25b7 Initialize empty CAD model 3: planes \u2190 GenerateRandomP lanes() \u25b7 Create set of reference planes 4: sketches \u2190 Generate2DSketch() \u25b7 Get sketches from Algorithm 1 5: for sketch \u2208 sketches do \u25b7 Create 3D volumes from sketches 6: plane \u2190 RandomSelect(planes) \u25b7 Select random reference plane 7: volume \u2190 ExtrudeSketch(sketch, plane) \u25b7 Create 3D volume by extrusion 8: cadM odel \u2190 BooleanU nion(cadM odel, volume) \u25b7 Add volume to model 9: end for 10: cadM odel \u2190 N ormalizeM odel(cadM odel) \u25b7 Ensure the model fits within a unit box 11: cadM odel \u2190 QuantizeP arameters(cadM odel) \u25b7 Discretize model parameters 12: cadM odel \u2190 Simplif yCADM odel(cadM odel) \u25b7 Identify high-level abstractions (rectangle, box, and cylinder) 13: cadM odel \u2190 V alidateCADM odel(cadM odel) \u25b7 Ensure validity of CadQuery code and CAD model geometry 14: cadM odel \u2190 CheckDuplicate(cadM odel) \u25b7 Ensure that the sequence has not previously been generated. 15:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "D. Further Experimental Results",
                "sec_num": null
            },
            {
                "text": "return cadM odel 16: end function tailed in Section 5.1 of the main paper, CAD-Recode consistently generates shapes that closely approximate the input point cloud geometry, whereas CAD-SIGNet [21] can generate predictions that greatly differ from the input. Ablation Results: Table 6 shows the architecture ablation results on all metrics, complementing Table 4 of the main paper. Results show that for the same size of input point clouds Qwen1.5b always produces better geometric performance (median CD and IoU) than Qwen0.5b. This can be attributed to the higher number of parameters as well as to the better ability of the model to produce valid python code before fine-tuning. Furthermore, increasing the size of the input point cloud demonstrates a similar pattern, with Qwen1.5b with an 256 input points appears to be the set of architecture parameters leading to the best performance.",
                "cite_spans": [
                    {
                        "start": 192,
                        "end": 196,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 282,
                        "end": 283,
                        "text": "6",
                        "ref_id": "TABREF5"
                    },
                    {
                        "start": 360,
                        "end": 361,
                        "text": "4",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "D. Further Experimental Results",
                "sec_num": null
            },
            {
                "text": "Note that the mean CD is a metric that is very sensitive to outlier predictions. While Qwen1.5b with 256 input points appears to result in the highest IR, it is negligibly low on all datasets (less 0.5%). This can also be explained by the fact that this setting produces more complex CAD sketchextrude sequences, making them more susceptible to errors. Note that a key idea of our method is to leverage pre-trained LLMs as decoder of Python code. In the absence of LLMbased CAD reverse engineering methods, we compare our approach to SOTA methods despite the difference in model sizes. For reference, CAD-SIGNet contains 6 M parameters.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": "Command & Parameter Accuracy: In order to evaluate the ability of CAD-Recode to predict numerical values and sequences that are consistent with the training set, we evaluate CAD-Recode trained on the DeepCAD dataset converted to CADQuery python codes with the Acc command and Acc parameter as introduced in [48] . The results on the DeepCAD testing set are presented in Table 7 . It can be observed that CAD-Recode achieves comparable performance to the state-of-the-art on the commnad type accuracy import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, -13, 0)) r = w0.workplane(offset=-87 / 2).moveTo(52.5, 10.5).box (57, 83, 87) .union(w0.workplane(offset=23 / 2).moveTo(-29, 0).cylinder (23, 30) )",
                "cite_spans": [
                    {
                        "start": 307,
                        "end": 311,
                        "text": "[48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 622,
                        "end": 626,
                        "text": "(57,",
                        "ref_id": "BIBREF56"
                    },
                    {
                        "start": 627,
                        "end": 630,
                        "text": "83,",
                        "ref_id": null
                    },
                    {
                        "start": 631,
                        "end": 634,
                        "text": "87)",
                        "ref_id": null
                    },
                    {
                        "start": 694,
                        "end": 698,
                        "text": "(23,",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 699,
                        "end": 702,
                        "text": "30)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 376,
                        "end": 377,
                        "text": "7",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": ".union(w0.workplane(offset=113 / 2).moveTo(-29, 0).cylinder(113, 52))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": "import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, -30, 0)) r = w0.sketch().segment((-30, -27),(-18, -31)).segment((-19, -31)).segment((-19, -100))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": ".segment((38, -100)).segment((38, -31)).segment((10, -31)).segment((13, -23))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": ".arc((30, -13), (23, 5) ).segment ((33, 33) ).segment ((16, 39) ).arc((-12, 99),(-9, 33)) .close().assemble().finalize().extrude (60) import cadquery as cq w0 = cq.Workplane('YZ', origin=(-14, 0, 0)) r = w0.workplane(offset=17 / 2).moveTo(4, -73.5).box(104, 53, 17) .union(w0.sketch().segment((-78, 23), (2, -55)).segment((40, -17))",
                "cite_spans": [
                    {
                        "start": 16,
                        "end": 20,
                        "text": "(23,",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 21,
                        "end": 23,
                        "text": "5)",
                        "ref_id": null
                    },
                    {
                        "start": 34,
                        "end": 43,
                        "text": "((33, 33)",
                        "ref_id": null
                    },
                    {
                        "start": 54,
                        "end": 63,
                        "text": "((16, 39)",
                        "ref_id": null
                    },
                    {
                        "start": 129,
                        "end": 133,
                        "text": "(60)",
                        "ref_id": "BIBREF59"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": ".arc((42, -24),(48, -30)).segment((48, 5)).segment((61, 5))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": ".segment ((78, 22) ).segment((-2, 100)).close().assemble() .push([(0, 22)]).circle(50, mode='s').finalize().extrude( 29))",
                "cite_spans": [
                    {
                        "start": 9,
                        "end": 18,
                        "text": "((78, 22)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": "import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, 42)) w1 = cq.Workplane('YZ', origin=(-17, 0, 0)) r = w0.sketch().arc((-12, 6), (34, -29),(-1, 16)).segment((5, 4)).segment((-8, -2)) .close().assemble().finalize().extrude(56) .union(w0.sketch().arc((-42, 54), (-12, 71), (19, 54)).segment((19, 78))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": ".segment((-42, 78)).close().assemble().finalize().extrude(58)) .union(w1.sketch().segment((-44, -100), (51, -100)).segment((51, 5)).segment((27, 5))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": ".arc((-58, 40),(-44, -51)).close().assemble().reset() .face(w1.sketch().arc((-54, -17), (-26, -34),(3, -17)).close() .assemble(), mode='s').reset().face(w1.sketch().segment((-54, 14), (3, 14))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": ".arc((-26, 31), (-54, 14)).assemble(), mode='s').finalize().extrude(-13))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": "import cadquery as cq w0 = cq.Workplane('YZ', origin=(-22, 0, 0)) w1 = cq.Workplane('ZX', origin=(0, -19, 0)) r = w0.sketch().segment((-100, -83),(-67, -83)).segment((-80, -52)).segment((-75, -50))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": ".segment((-75, 62)).segment((17, 62)).segment((17, -62)).segment((-40, -62))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": ".segment((-37, -71)).segment((-65, -83)).segment((43, -83))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": ".segment((43,83)).segment((-100,83)).close().assemble().finalize().extrude(8) .union(w1.sketch().segment((-77, -53),(76, -53)).arc((76, -48),(77, -42)) .segment((77, 53)).segment((-77, 53)).close().assemble() .push([(38.5, 2.5)]).rect(9, 57, mode='s').finalize().extrude(119)) 5 10 15 20 25 30 35 40 Number of faces per model DeepCAD Our Dataset (a) Box-plot graph of the distribution of the number of faces per model. 0 20 40 60 80 100 Number of edges per model DeepCAD Our Dataset (b) Box-plot graph of the distribution of the number of edges per model. and significantly higher performance on the parameter accuracy. This demonstrates that CAD-Recode is able to predict numerical values accurately. Note that, those metrics were originally developed to evaluate autoencoding ability. However, there may exist many different possible valid CAD sequences to construct the same CAD model and these metrics do not take this into account. As a result, these metrics were omitted in recent works (CAD-SIGNet [21] and TransCAD [12] ).",
                "cite_spans": [
                    {
                        "start": 1005,
                        "end": 1009,
                        "text": "[21]",
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 1023,
                        "end": 1027,
                        "text": "[12]",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Code Outputs:",
                "sec_num": null
            },
            {
                "text": "The invalidity rate of CAD-Recode predictions is very low, below 1% on the DeepCAD [48] , Fusion360 [47] and real-world CC3D [35] dataset. Some examples of invalid code predictions are presented in Figure 14 . Invalid predictions happen when the CAD model contains features of dimension smaller than the resolution induced by quantization (Figure 14 Points Model DeepCAD Fusion360 CC3D Size Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 64 0.5 B 0.42 0.20 88.5 0.1 0.58 0.22 82.1 0.1 0.87 0.45 70.1 0. DeepCAD [48] 80.4 69.6 PrismCAD [25] 73.0 66.8 HNC-CAD [52] 82.7 74.6 CAD-Diffuser [34] 88.5 82.9 CAD-Recode 83.9 92.1",
                "cite_spans": [
                    {
                        "start": 83,
                        "end": 87,
                        "text": "[48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 125,
                        "end": 129,
                        "text": "[35]",
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 545,
                        "end": 549,
                        "text": "[48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 569,
                        "end": 573,
                        "text": "[25]",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 592,
                        "end": 596,
                        "text": "[52]",
                        "ref_id": "BIBREF51"
                    },
                    {
                        "start": 620,
                        "end": 624,
                        "text": "[34]",
                        "ref_id": "BIBREF33"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 205,
                        "end": 207,
                        "text": "14",
                        "ref_id": "FIGREF14"
                    },
                    {
                        "start": 347,
                        "end": 349,
                        "text": "14",
                        "ref_id": "FIGREF14"
                    }
                ],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": "Table 7 . Command and parameter accuracy results [48] Point Cloud CAD-SIGNet CAD-Recode GT Figure 11. Qualitative results on the Fusion360 dataset. Point Cloud CAD-SIGNet CAD-Recode GT .segment((48, 100)).segment((-48, 100)).close().assemble().finalize().extrude(20) .union(w0.sketch().segment((-82, -100),(-27, -100)).segment((-27, 80)).segment ((27, 80) )",
                "cite_spans": [
                    {
                        "start": 49,
                        "end": 53,
                        "text": "[48]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 346,
                        "end": 355,
                        "text": "((27, 80)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "7",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ".segment((27, -100)).segment((82, -100)).segment((82, -79)).segment((48, -79))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ".segment((48, 100)).segment((-48, 100)).segment((-48, -79)).segment((-82, -79))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ".close().assemble().finalize().extrude (34) ) .circle(28, mode='s').finalize().extrude (32) import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, 40, 0)) w1 = cq.Workplane('XY', origin=(0, 0, -19)) r = w0.sketch().arc((-24, -47), (41, -99),(87, -32)).segment((88, -32)).segment((88, 100))",
                "cite_spans": [
                    {
                        "start": 39,
                        "end": 43,
                        "text": "(34)",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 87,
                        "end": 91,
                        "text": "(32)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": "import",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ".segment((82, 100)).segment((82, -52)).arc((34, -94), (-18, -52)).segment((-18, 100))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ".segment((-24, 100)).close().assemble().finalize().extrude(-80) .union(w1.workplane(offset=-69 / 2).moveTo (52, 0) .cylinder(69, 32)) import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, 31, 0)) r = w0.workplane(offset=-75 / 2).cylinder (75, 62) .union(w0.workplane(offset=-25 / 2).cylinder (25, 81) )",
                "cite_spans": [
                    {
                        "start": 107,
                        "end": 111,
                        "text": "(52,",
                        "ref_id": "BIBREF51"
                    },
                    {
                        "start": 112,
                        "end": 114,
                        "text": "0)",
                        "ref_id": null
                    },
                    {
                        "start": 241,
                        "end": 245,
                        "text": "(75,",
                        "ref_id": null
                    },
                    {
                        "start": 246,
                        "end": 249,
                        "text": "62)",
                        "ref_id": "BIBREF61"
                    },
                    {
                        "start": 295,
                        "end": 299,
                        "text": "(25,",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 300,
                        "end": 303,
                        "text": "81)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ".union(w0.workplane(offset=13 / 2).cylinder(13, 100))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": "import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, 69, 0)) w1 = cq.Workplane('ZX', origin=(0, -85, 0)) r = w0.workplane(offset=-150 / 2).cylinder (150, 15) .union(w0.workplane(offset=10 / 2).cylinder (10, 31) )",
                "cite_spans": [
                    {
                        "start": 152,
                        "end": 157,
                        "text": "(150,",
                        "ref_id": null
                    },
                    {
                        "start": 158,
                        "end": 161,
                        "text": "15)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 206,
                        "end": 210,
                        "text": "(10,",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 211,
                        "end": 214,
                        "text": "31)",
                        "ref_id": "BIBREF30"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ".union(w0.workplane(offset=31 / 2).cylinder (31, 8) )",
                "cite_spans": [
                    {
                        "start": 44,
                        "end": 48,
                        "text": "(31,",
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 49,
                        "end": 51,
                        "text": "8)",
                        "ref_id": "BIBREF7"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ".union(w1.workplane(offset=-15/2).cylinder (15, 46) ) import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, 20, 0)) r = w0.sketch().circle(61).circle(25, mode='s').push([(34, 4)]) .circle(4, mode='s').finalize().extrude(-41) .union(w0.sketch().segment((-100, 19), (-88, 11) ).segment((-97, -34)).segment((-67, -41))",
                "cite_spans": [
                    {
                        "start": 43,
                        "end": 47,
                        "text": "(15,",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 48,
                        "end": 51,
                        "text": "46)",
                        "ref_id": null
                    },
                    {
                        "start": 267,
                        "end": 276,
                        "text": "(-88, 11)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ".segment((-77, -66)).segment((-57, -74)).segment((-57, -72)).segment((-56, -72))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ". import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, 0)) w1 = cq.Workplane('YZ', origin=(0, 0, 0)) r = w0.workplane(offset=0 / 2).cylinder(0, 98) .union(w1.workplane(offset=0 / 2).cylinder(0, 100)) (a) The ground truth model contains three very thin cylinders with height smaller than 1. As a result, CAD-Recode is not able to predict heights with sufficient precision due to quantization and predicts cylinders with height 0, producing an invalid model. import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, 0)) r = w0.sketch().rect(200, 124).push([(-63.5, 25)]).rect(51, 60, mode='s') .push([(55, -25)]).rect(50, 60, mode='s').finalize().extrude(0) (b) As the ground-truth model has thickness less than 1, CAD-Recode predicts an extrusion distance of 0 as a quantized approximation (highlighted in yellow), resulting in an invalid CAD model. import cadquery as cq w0 = cq.Workplane('YZ', origin=(34, 0, 0)) w1 = cq.Workplane('XY', origin=(0, 0, 44)) r = w0.sketch().segment((-7, -35), (11, -36)).segment((11, -24)).arc((1, (6, -2)).segment((-1, 19)).segment((11, 23)).segment((11, 28))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ".segment ((11, 29) ).segment ((12, 29) ).segment ((12, 35) ) .segment((-4, 36)).close().assemble().finalize().extrude(-133) .union(w0.sketch().segment((5, -7), (14, -2)).segment ((8, 8) ).arc((7, 0),",
                "cite_spans": [
                    {
                        "start": 9,
                        "end": 18,
                        "text": "((11, 29)",
                        "ref_id": null
                    },
                    {
                        "start": 29,
                        "end": 38,
                        "text": "((12, 29)",
                        "ref_id": null
                    },
                    {
                        "start": 49,
                        "end": 58,
                        "text": "((12, 35)",
                        "ref_id": null
                    },
                    {
                        "start": 178,
                        "end": 185,
                        "text": "((8, 8)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": "(5, -7)).assemble().finalize().extrude( 63)) .union(w1.sketch().arc((-100, 12), (-85, 10), (-70, 5)).arc((-68, 6), (-66, 5)).arc((-59, 4), (-52, 2)).arc((-51, 3), (-50, 4)).arc((-72, 7), (-90, 12)).close().assemble().finalize().extrude(-88))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": "(c) The ground-truth CAD model is created with B-spline primitives. Since CAD-Recode supports only arc, circle and line primitives, it tries to approximate the solution with multiple arcs, but fails to provide a valid CAD model. In particular, the prediction contains an arc constructed from three co-linear points (highlighted in yellow), which raises an error in CadQuery.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": "import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, -79)) r = w0.sketch().segment((-100, -1), (-91, -1)).arc((0, -93),(91, -1))",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ".segment((100, -1)).segment((100, 1)).segment((91, 1)).arc((0, 99), (-91, 1)).segment((-100, 1)).close().assemble().push([(0, -2)]) .circle(90, mode='s').finalize().extrude(-2) .union(w0.workplane(offset=140 / 2).cylinder(140, 72)) .union(w0.sketch().segment((-51, 15), (-50, 15) ).arc((0, -53), (50, 15) )",
                "cite_spans": [
                    {
                        "start": 270,
                        "end": 279,
                        "text": "(-50, 15)",
                        "ref_id": null
                    },
                    {
                        "start": 296,
                        "end": 300,
                        "text": "(50,",
                        "ref_id": "BIBREF49"
                    },
                    {
                        "start": 301,
                        "end": 304,
                        "text": "15)",
                        "ref_id": "BIBREF4"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": ".segment ((51, 15) ).segment ((51, 27) ).segment ((48, 27) ).arc((0, -53), (-48, 27) ).segment((-51, 27)).close().assemble().finalize().extrude( 159))",
                "cite_spans": [
                    {
                        "start": 9,
                        "end": 18,
                        "text": "((51, 15)",
                        "ref_id": null
                    },
                    {
                        "start": 29,
                        "end": 38,
                        "text": "((51, 27)",
                        "ref_id": null
                    },
                    {
                        "start": 49,
                        "end": 58,
                        "text": "((48, 27)",
                        "ref_id": null
                    },
                    {
                        "start": 75,
                        "end": 84,
                        "text": "(-48, 27)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": "(d) The ground-truth CAD model is created with a revolution operation. Since CAD-Recode supports only extrusion operation, it tries to approximate the solution with multiple arcs. However, one of the sketch (highlighted in yellow) results in a self-intersecting loop, which is not a valid face. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Invalid Predictions:",
                "sec_num": null
            },
            {
                "text": "The ablation study in Section 5.1 of the main paper demonstrates the effectiveness of our test-time sampling strategy. This approach generates multiple plausible solutions by sampling different input point clouds. Figure 15 illustrates the qualitative results from different sampling instances. While CAD-Recode successfully captures the overall geometry across different samplings, fine-grained details may vary in reconstruction quality due to the relatively sparse point cloud input. However, this can be effectively addressed by leveraging multiple sampling iterations to capture different aspects of the input geometry.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 221,
                        "end": 223,
                        "text": "15",
                        "ref_id": "FIGREF15"
                    }
                ],
                "eq_spans": [],
                "section": "E. Test-time Sampling",
                "sec_num": null
            },
            {
                "text": "In this section, we provide further details on the CAD-QA experiments reported in Section 5.2 of the main paper. We start by providing more details on the SGP-Bench benchmark [38] . Then, we present results further results and examples of GPT-4o outputs.",
                "cite_spans": [
                    {
                        "start": 175,
                        "end": 179,
                        "text": "[38]",
                        "ref_id": "BIBREF37"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "F. Interpretability and CAD-QA",
                "sec_num": null
            },
            {
                "text": "The goal of the SGP-Bench benchmark is to evaluate the spatial-semantic reasoning skills of LLMs from symbolic graphics programs [38] . One aspect of the benchmark is a set of 1000 multiple choice questions on 3D CAD models given their corresponding sketch-extrude sequence in the DeepCAD [48] format. An example is depicted in Figure 16 .",
                "cite_spans": [
                    {
                        "start": 129,
                        "end": 133,
                        "text": "[38]",
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 289,
                        "end": 293,
                        "text": "[48]",
                        "ref_id": "BIBREF47"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 335,
                        "end": 337,
                        "text": "16",
                        "ref_id": "FIGREF16"
                    }
                ],
                "eq_spans": [],
                "section": "F.1. Representation and CAD-QA",
                "sec_num": null
            },
            {
                "text": "To evaluate the interpretability of our code-based CAD representation, we translated the 1000 questions of SGP-Bench from the DeepCAD representation (Figure 16(a) ) to the CadQuery code format (Figure 16(b) ). Using the same protocol as in SGP-Bench [38] , and GPT-4o [36] , we found that the accuracy on the multiple choice question in Cad-Query format is 82.4%. This is about 4% higher than using the DeepCAD format with an interpretative hint. This suggests the proposed code representation provides a more structured and naturally LLM-interpretable representation of CAD models.",
                "cite_spans": [
                    {
                        "start": 250,
                        "end": 254,
                        "text": "[38]",
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 268,
                        "end": 272,
                        "text": "[36]",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 157,
                        "end": 162,
                        "text": "16(a)",
                        "ref_id": "FIGREF16"
                    },
                    {
                        "start": 201,
                        "end": 206,
                        "text": "16(b)",
                        "ref_id": "FIGREF16"
                    }
                ],
                "eq_spans": [],
                "section": "F.1. Representation and CAD-QA",
                "sec_num": null
            },
            {
                "text": "In Table 6 of the main paper, the results for point cloud CAD-QA are presented. Figure 17 (a) depicts an example of point cloud and question that was used to obtain these results. In this particular question, the task is to deduce the number of holes present in the CAD model given the point cloud as input. Figure 17(b ), the answer provided by PointLLM is shown and it can be observed that PointLLM is unable to retrieve the correct answer. It is worth noting that PointLLM is a network trained to answer semantic questions about object given its point cloud representation, as result in most cases the network is unable to describe geometric CAD-specific questions. For both CAD-SIGNet and CAD-Recode, the point cloud CAD-QA is done in a two step process. First the sketch-extrude is sequence is predicted from each network, then the sequence along with the question is passed through GPT-4o. Note that for CAD-SIGNet an interpretative hint is provided to provide context on the structure of the sequence. A sample output for CAD-SIGNet and GPT-4o can be found in Figure 17 (c), and in Figure 17 (d) for CAD-Recode and GPT4-o. As the sequence was incorrectly predicted by CAD-SIGNet the answer to the question is wrong (1 hole), whereas the prediction from CAD-Recode captured better the geometry of the input point cloud leading to a correct answer. It is worth noting, that despite not being provided any information about CadQuery Python code in the prompt, GPT-4o is able to breakdown the predicted sequence into its primitive components and provide correct and accurate geometric descriptions. This can be explained by the fact that LLMs are exposed to large amounts of code data during training. As a result, the CadQuery Python representation of CAD models is appropriate for",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 9,
                        "end": 10,
                        "text": "6",
                        "ref_id": "TABREF5"
                    },
                    {
                        "start": 87,
                        "end": 89,
                        "text": "17",
                        "ref_id": "FIGREF17"
                    },
                    {
                        "start": 315,
                        "end": 319,
                        "text": "17(b",
                        "ref_id": "FIGREF17"
                    },
                    {
                        "start": 1074,
                        "end": 1076,
                        "text": "17",
                        "ref_id": "FIGREF17"
                    },
                    {
                        "start": 1096,
                        "end": 1098,
                        "text": "17",
                        "ref_id": "FIGREF17"
                    }
                ],
                "eq_spans": [],
                "section": "F.2. Point Cloud and CAD-QA",
                "sec_num": null
            },
            {
                "text": "We provide more details on the editing pipeline presented in Section 5.2 of the main paper. The goal of this pipeline is to integrate automated editability capabilities to CAD-Recode. To this end, we present a simple process using an off-the-shelf LLM, GPT-4o [36] . Starting from an output CAD Python code from CAD-Recode as shown in Figure 18a , we prepare a simple and generic prompt (Figure 18b ) for the LLM to generate a refactored version of the code such that when executed the user can change with the dimensions of each primitive. As seen in Figure 18c , the LLM is able to generate a code with comments that describe the different primitives semanticallly and include appropriate variables for the dimensions of each of the primitive, such as the height and the diameter of each cylinder. The code generated by the LLM, can be directly executed in a Jupyter notebook with the CadQuery and ipywidgets libraries. Figure 6 of the main paper shows the generated sliders and how can the shape be then edited. This demonstrates that the CAD representation as Python code within a reverse engineering scenario opens the door to new applications when combined with LLMs. Examine the following CAD code carefully to understand the 3D object it generates and answer the question based on your interpretation of the rendered image of that object. SOL; Line:(221,128); Line:(221,223) ;Line:(128,223); Line:(128,128); Ext: (128,128,128,32,110,128,98,167,128, Newbody, One-sided); EOS Hint: the CAD code has the following syntax: CAD code consists of a sequence of CAD commands that describe a 3D object. The commands fall into two categories: sketch and extrusion. Sketch commands are used to specify closed curves on a 2D plane in 3D space. Each closed curve is referred as a loop, and one or more loops form a closed region called a profile. A loop always starts with an indicator command <SOL> followed by a series of curve commands. All the curves on the loop are in counterclockwise order, beginning with the curve whose starting point is at the most bottom-left. In total, there are three possible curve commands: Line, Arc, and Circle. Line(x, y): a line, with x, y as line end-point. Arc(x, y, u, f): an arc, with x,y as arc end-point, u as sweep angle and f as whether it is counter-clockwise, f=0 means it is counter-clockwise, f=1 means it is not counter-clockwise. Circle(x, y, r): a circle, with x,y as the center point and r as the radius. The extrusion command has two purposes: 1) It extrudes a sketch profile from a 2D plane into a 3D body, and the extrusion type can be either one-sided, symmetric, or two-sided with respect to the profile's sketch plane. 2) The command also specifies (through the parameter b in Ext) how to merge the newly extruded 3D body with the previously created shape by one of the boolean operations: either creating a new body, or joining, cutting or intersecting with the existing body. Ext(x, y, z, o, p, q, s, e, f, b, u): extrude operation, with x, y, z as the sketch plane orientation, o, p, q as the sketch plane origin, s as the scale of the associated sketch profile, e, f as the extrude distances towards both sides, b as the type of merge operation (could be New-body operation, join operation, cut operation and intersect operation) and u as the extrude type (could be one-sided, symmetric or two-sided). <EOS> means the end of the code. Question: How many faces does the CAD object in the image have? (a) DeepCAD Representation Examine the following CAD code carefully to understand the 3D object it generates and answer the question based on your interpretation of the rendered image of that object.",
                "cite_spans": [
                    {
                        "start": 260,
                        "end": 264,
                        "text": "[36]",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 342,
                        "end": 345,
                        "text": "18a",
                        "ref_id": "FIGREF9"
                    },
                    {
                        "start": 395,
                        "end": 398,
                        "text": "18b",
                        "ref_id": "FIGREF9"
                    },
                    {
                        "start": 559,
                        "end": 562,
                        "text": "18c",
                        "ref_id": "FIGREF9"
                    },
                    {
                        "start": 929,
                        "end": 930,
                        "text": "6",
                        "ref_id": "FIGREF6"
                    }
                ],
                "eq_spans": [],
                "section": "G. Editing Pipeline Details",
                "sec_num": null
            },
            {
                "text": "import cadquery as cq def make shape(): plane0 = cq.Plane(origin = (-0.75,-0.1406,0.0),xDir = (1.0,0.0,0.0),normal = (0.0,0.0,1.0)) w0 = cq.Workplane(plane0) face0 = w0.sketch().face(w0.sketch().segment( (0.0, 0.0), (0.7495, 0.0)).segment((0.7495, 0.0), (0.7495, 0.7656)).segment((0.7495, 0.7656), (0.0, 0.7656)).segment((0.0, 0.7656), (0.0, 0.0)).assemble(), mode = 'a').finalize() shape0 = face0.extrude(0.3046875, both=False) return shape0",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "G. Editing Pipeline Details",
                "sec_num": null
            },
            {
                "text": "Question: How many faces does the CAD object in the image have? Question: How many holes does the CAD object in the image have? A) Two, B) Three, C) Four, D) Five Correct Answer: B (a) Point cloud and corresponding CAD-specific question The CAD object in the image has five holes. (b) PointLLM output from point cloud To determine the number of holes in the CAD object, let's break down the CAD code step by step: 1. Extrusion Command: Start;Ext:(128,130,128,128,130,128,128,128,NewBody,96); This command sets up an extrusion with specific parameters and indicates that a new body will be created. 2. First Loop: Line:(43,0);Arc:(213,0,255,43);Line:(213,85);Arc:(43,85,0,43);EOL; -Line:(43,0) -A line from the starting point to (43,0). -Arc:(213,0,255,43) -An arc with midpoint (213,0) and endpoint (255,43). -Line:(213,85) -A line from the previous endpoint to (213,85). -Arc:(43,85,0,43) -An arc with midpoint (43,85) and endpoint (0,43). -EOL -End of the loop. This forms a closed loop, which is a profile for extrusion. 3. Second Loop: Circle:(43,43,43,51);EOL; -Circle:(43,43,43,51) -A circle with the most left point at (43,43) and the most top point at (43,51). -EOL -End of the loop. This forms another closed loop, which is another profile for extrusion. 4. End of Sketch and Extrusion: EOF;EOS;End; -EOF -End of face.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "G. Editing Pipeline Details",
                "sec_num": null
            },
            {
                "text": "-EOS -End of sketch.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "G. Editing Pipeline Details",
                "sec_num": null
            },
            {
                "text": "-End -End of the code. From the above analysis, we can see that the CAD object consists of:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "G. Editing Pipeline Details",
                "sec_num": null
            },
            {
                "text": "-One main profile formed by the first loop.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "G. Editing Pipeline Details",
                "sec_num": null
            },
            {
                "text": "-One circular profile formed by the second loop. The circular profile represents a hole within the main profile. Since there is only one circular profile, the CAD object has one hole. Answer: A (c) GPT-4o output from CAD-SIGNet prediction Let's break down the CAD code step by step to understand the 3D object it generates and determine the number of holes. 1. Workplane Creation: w0 = cq.Workplane('XY', origin=(0,0,1)) This line creates a workplane on the XY plane with an origin at (0,0,1). 2. Sketching the Shape: r = w0.sketch() This initializes a sketch on the workplane. 3. Defining the Shape: .segment((-66,-34), (50,-34) ) .segment((50,-32)) .arc((100,0), (50, 32) ) .segment ((50,34) ) .segment((-66,34)) .segment((-66,32)) .arc((-100,0),(-66,-32)) .close() These lines define a closed shape with segments and arcs. The shape appears to be symmetrical along the Y-axis. 4. Adding Holes: .assemble() .push([(-66,0)]).circle(10, mode='s') .push([(0,0)]).circle(10, mode='s') .push([(66,0)]).circle(10, mode='s') .finalize() These lines add three circles (holes) to the shape at positions (-66,0), (0,0), and (66,0). 5. Extruding the Shape: .extrude(-4) This line extrudes the shape by -4 units, creating a 3D object with the defined shape and holes. From the code, we can see that three circles (holes) are added to the shape. Therefore, the CAD object has three holes. Answer: B (d) GPT-4o output from CAD-Recode prediction ",
                "cite_spans": [
                    {
                        "start": 621,
                        "end": 629,
                        "text": "(50,-34)",
                        "ref_id": null
                    },
                    {
                        "start": 665,
                        "end": 669,
                        "text": "(50,",
                        "ref_id": "BIBREF49"
                    },
                    {
                        "start": 670,
                        "end": 673,
                        "text": "32)",
                        "ref_id": null
                    },
                    {
                        "start": 685,
                        "end": 693,
                        "text": "((50,34)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "G. Editing Pipeline Details",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": "import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, 0)) r = w0.workplane(offset=-100 / 2).cylinder (100, 100) .union(w0.workplane(offset=100 / 2).cylinder(100, 34))(a) CAD-Recode output as CadQuery Python code.Refactor the code, add functions and variables that can make the code easier to edit and more interpretable. Add in the code, sliders to edit the size of each primitive: import cadquery as cq w0=cq.Workplane('XY',origin=(0,0,0)) r=w0.workplane(offset=-100/2).cylinder(100,100 \"\"\"Creates a cylinder on the specified workplane with a given diameter, height, and offset.\"\"\" return workplane.workplane(offset=offset).cylinder(height, diameter / 2) def build_model(base_diameter=default_base_diameter, base_height=default_base_height, top_diameter=default_top_diameter, top_height=default_top_height): \"\"\"Builds the model with adjustable base and top cylinder dimensions.\"\"\" # Initialize the main workplane w0 = cq.Workplane(\"XY\", origin=(0, 0, 0)) ",
                "cite_spans": [
                    {
                        "start": 107,
                        "end": 112,
                        "text": "(100,",
                        "ref_id": null
                    },
                    {
                        "start": 113,
                        "end": 117,
                        "text": "100)",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "annex",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Generating CAD code with vision-language models for 3d designs",
                "authors": [
                    {
                        "first": "Pradyumna",
                        "middle": [],
                        "last": "Kamel Alrashedy",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Tambwekar",
                        "suffix": ""
                    },
                    {
                        "first": "Haider",
                        "middle": [],
                        "last": "Zulfiqar",
                        "suffix": ""
                    },
                    {
                        "first": "Megan",
                        "middle": [],
                        "last": "Zaidi",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Langwasser",
                        "suffix": ""
                    },
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Gombolay",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kamel Alrashedy, Pradyumna Tambwekar, Zulfiqar Haider Zaidi, Megan Langwasser, Wei Xu, and Matthew Gombolay. Generating CAD code with vision-language models for 3d designs. In ICLR, 2025.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Query2cad: Generating cad models using natural language queries",
                "authors": [
                    {
                        "first": "Akshay",
                        "middle": [],
                        "last": "Badagabettu",
                        "suffix": ""
                    },
                    {
                        "first": "Sai",
                        "middle": [],
                        "last": "Sravan Yarlagadda",
                        "suffix": ""
                    },
                    {
                        "first": "Amir",
                        "middle": [],
                        "last": "Barati",
                        "suffix": ""
                    },
                    {
                        "first": "Farimani",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2406.00144"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Akshay Badagabettu, Sai Sravan Yarlagadda, and Amir Barati Farimani. Query2cad: Generating cad models using natural language queries. arXiv preprint arXiv:2406.00144, 2024.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Comparing 3d cad models: uses, methods, tools and perspectives",
                "authors": [
                    {
                        "first": "Antoine",
                        "middle": [],
                        "last": "Bri\u00e8re-C\u00f4t\u00e9",
                        "suffix": ""
                    },
                    {
                        "first": "Louis",
                        "middle": [],
                        "last": "Rivest",
                        "suffix": ""
                    },
                    {
                        "first": "Roland",
                        "middle": [],
                        "last": "Maranzana",
                        "suffix": ""
                    }
                ],
                "year": 2012,
                "venue": "Computer-Aided Design and Applications",
                "volume": "9",
                "issue": "6",
                "pages": "771--794",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Antoine Bri\u00e8re-C\u00f4t\u00e9, Louis Rivest, and Roland Maranzana. Comparing 3d cad models: uses, methods, tools and per- spectives. Computer-Aided Design and Applications, 9(6): 771-794, 2012.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Parametric cad modeling: An analysis of strategies for design reusability",
                "authors": [
                    {
                        "first": "Jorge",
                        "middle": [
                            "D"
                        ],
                        "last": "Camba",
                        "suffix": ""
                    },
                    {
                        "first": "Manuel",
                        "middle": [],
                        "last": "Contero",
                        "suffix": ""
                    },
                    {
                        "first": "Pedro",
                        "middle": [],
                        "last": "Company",
                        "suffix": ""
                    }
                ],
                "year": 2016,
                "venue": "Computer-Aided Design",
                "volume": "74",
                "issue": "",
                "pages": "18--31",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jorge D Camba, Manuel Contero, and Pedro Company. Para- metric cad modeling: An analysis of strategies for design reusability. Computer-Aided Design, 74:18-31, 2016.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Evaluating large language models trained code",
                "authors": [
                    {
                        "first": "Mark",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Jerry",
                        "middle": [],
                        "last": "Tworek",
                        "suffix": ""
                    },
                    {
                        "first": "Heewoo",
                        "middle": [],
                        "last": "Jun",
                        "suffix": ""
                    },
                    {
                        "first": "Qiming",
                        "middle": [],
                        "last": "Yuan",
                        "suffix": ""
                    },
                    {
                        "first": "Henrique",
                        "middle": [],
                        "last": "Ponde De Oliveira Pinto",
                        "suffix": ""
                    },
                    {
                        "first": "Jared",
                        "middle": [],
                        "last": "Kaplan",
                        "suffix": ""
                    },
                    {
                        "first": "Harri",
                        "middle": [],
                        "last": "Edwards",
                        "suffix": ""
                    },
                    {
                        "first": "Yuri",
                        "middle": [],
                        "last": "Burda",
                        "suffix": ""
                    },
                    {
                        "first": "Greg",
                        "middle": [],
                        "last": "Joseph",
                        "suffix": ""
                    },
                    {
                        "first": "Alex",
                        "middle": [],
                        "last": "Brockman",
                        "suffix": ""
                    },
                    {
                        "first": "Raul",
                        "middle": [],
                        "last": "Ray",
                        "suffix": ""
                    },
                    {
                        "first": "Gretchen",
                        "middle": [],
                        "last": "Puri",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Krueger",
                        "suffix": ""
                    },
                    {
                        "first": "Heidy",
                        "middle": [],
                        "last": "Petrov",
                        "suffix": ""
                    },
                    {
                        "first": "Girish",
                        "middle": [],
                        "last": "Khlaaf",
                        "suffix": ""
                    },
                    {
                        "first": "Pamela",
                        "middle": [],
                        "last": "Sastry",
                        "suffix": ""
                    },
                    {
                        "first": "Brooke",
                        "middle": [],
                        "last": "Mishkin",
                        "suffix": ""
                    },
                    {
                        "first": "Scott",
                        "middle": [],
                        "last": "Chan",
                        "suffix": ""
                    },
                    {
                        "first": "Nick",
                        "middle": [],
                        "last": "Gray",
                        "suffix": ""
                    },
                    {
                        "first": "Mikhail",
                        "middle": [],
                        "last": "Ryder",
                        "suffix": ""
                    },
                    {
                        "first": "Alethea",
                        "middle": [],
                        "last": "Pavlov",
                        "suffix": ""
                    },
                    {
                        "first": "Lukasz",
                        "middle": [],
                        "last": "Power",
                        "suffix": ""
                    },
                    {
                        "first": "Mohammad",
                        "middle": [],
                        "last": "Kaiser",
                        "suffix": ""
                    },
                    {
                        "first": "Clemens",
                        "middle": [],
                        "last": "Bavarian",
                        "suffix": ""
                    },
                    {
                        "first": "Philippe",
                        "middle": [],
                        "last": "Winter",
                        "suffix": ""
                    },
                    {
                        "first": "Felipe",
                        "middle": [
                            "Petroski"
                        ],
                        "last": "Tillet",
                        "suffix": ""
                    },
                    {
                        "first": "Dave",
                        "middle": [],
                        "last": "Such",
                        "suffix": ""
                    },
                    {
                        "first": "Matthias",
                        "middle": [],
                        "last": "Cummings",
                        "suffix": ""
                    },
                    {
                        "first": "Fotios",
                        "middle": [],
                        "last": "Plappert",
                        "suffix": ""
                    },
                    {
                        "first": "Elizabeth",
                        "middle": [],
                        "last": "Chantzis",
                        "suffix": ""
                    },
                    {
                        "first": "Ariel",
                        "middle": [],
                        "last": "Barnes",
                        "suffix": ""
                    },
                    {
                        "first": "William",
                        "middle": [],
                        "last": "Herbert-Voss",
                        "suffix": ""
                    },
                    {
                        "first": "Alex",
                        "middle": [],
                        "last": "Hebgen Guss",
                        "suffix": ""
                    },
                    {
                        "first": "Alex",
                        "middle": [],
                        "last": "Nichol",
                        "suffix": ""
                    },
                    {
                        "first": "Nikolas",
                        "middle": [],
                        "last": "Paino",
                        "suffix": ""
                    },
                    {
                        "first": "Jie",
                        "middle": [],
                        "last": "Tezak",
                        "suffix": ""
                    },
                    {
                        "first": "Igor",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "Suchir",
                        "middle": [],
                        "last": "Babuschkin",
                        "suffix": ""
                    },
                    {
                        "first": "Shantanu",
                        "middle": [],
                        "last": "Balaji",
                        "suffix": ""
                    },
                    {
                        "first": "William",
                        "middle": [],
                        "last": "Jain",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [],
                        "last": "Saunders",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [
                            "N"
                        ],
                        "last": "Hesse",
                        "suffix": ""
                    },
                    {
                        "first": "Jan",
                        "middle": [],
                        "last": "Carr",
                        "suffix": ""
                    },
                    {
                        "first": "Josh",
                        "middle": [],
                        "last": "Leike",
                        "suffix": ""
                    },
                    {
                        "first": "Vedant",
                        "middle": [],
                        "last": "Achiam",
                        "suffix": ""
                    },
                    {
                        "first": "Evan",
                        "middle": [],
                        "last": "Misra",
                        "suffix": ""
                    },
                    {
                        "first": "Alec",
                        "middle": [],
                        "last": "Morikawa",
                        "suffix": ""
                    },
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Radford",
                        "suffix": ""
                    },
                    {
                        "first": "Miles",
                        "middle": [],
                        "last": "Knight",
                        "suffix": ""
                    },
                    {
                        "first": "Mira",
                        "middle": [],
                        "last": "Brundage",
                        "suffix": ""
                    },
                    {
                        "first": "Katie",
                        "middle": [],
                        "last": "Murati",
                        "suffix": ""
                    },
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Mayer",
                        "suffix": ""
                    },
                    {
                        "first": "Bob",
                        "middle": [],
                        "last": "Welinder",
                        "suffix": ""
                    },
                    {
                        "first": "Dario",
                        "middle": [],
                        "last": "Mcgrew",
                        "suffix": ""
                    },
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Amodei",
                        "suffix": ""
                    },
                    {
                        "first": "Ilya",
                        "middle": [],
                        "last": "Mccandlish",
                        "suffix": ""
                    },
                    {
                        "first": "Wojciech",
                        "middle": [],
                        "last": "Sutskever",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Zaremba",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Hen- rique Ponde de Oliveira Pinto, Jared Kaplan, Harri Ed- wards, Yuri Burda, Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plap- pert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Mu- rati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained code, 2021.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Ll3da: Visual interactive instruction tuning for omni-3d understanding reasoning and planning",
                "authors": [
                    {
                        "first": "Sijin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Xin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Chi",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Mingsheng",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Gang",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Hao",
                        "middle": [],
                        "last": "Fei",
                        "suffix": ""
                    },
                    {
                        "first": "Hongyuan",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Jiayuan",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    },
                    {
                        "first": "Tao",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": "",
                "issue": "",
                "pages": "26428--26438",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sijin Chen, Xin Chen, Chi Zhang, Mingsheng Li, Gang Yu, Hao Fei, Hongyuan Zhu, Jiayuan Fan, and Tao Chen. Ll3da: Visual interactive instruction tuning for omni-3d understand- ing reasoning and planning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 26428-26438, 2024.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "Pvdeconv: Point-voxel deconvolution for autoencoding cad construction in 3d",
                "authors": [
                    {
                        "first": "Kseniya",
                        "middle": [],
                        "last": "Cherenkova",
                        "suffix": ""
                    },
                    {
                        "first": "Djamila",
                        "middle": [],
                        "last": "Aouada",
                        "suffix": ""
                    },
                    {
                        "first": "Gleb",
                        "middle": [],
                        "last": "Gusev",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "ICIP",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kseniya Cherenkova, Djamila Aouada, and Gleb Gusev. Pvdeconv: Point-voxel deconvolution for autoencoding cad construction in 3d. In ICIP, pages 2741-2745, 2020. 2, 4, 9",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Sepicnet: Sharp edges recovery by parametric inference of curves in 3d shapes",
                "authors": [
                    {
                        "first": "Kseniya",
                        "middle": [],
                        "last": "Cherenkova",
                        "suffix": ""
                    },
                    {
                        "first": "Elona",
                        "middle": [],
                        "last": "Dupont",
                        "suffix": ""
                    },
                    {
                        "first": "Anis",
                        "middle": [],
                        "last": "Kacem",
                        "suffix": ""
                    },
                    {
                        "first": "Ilya",
                        "middle": [],
                        "last": "Arzhannikov",
                        "suffix": ""
                    },
                    {
                        "first": "Gleb",
                        "middle": [],
                        "last": "Gusev",
                        "suffix": ""
                    },
                    {
                        "first": "Djamila",
                        "middle": [],
                        "last": "Aouada",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "CVPRW",
                "volume": "",
                "issue": "",
                "pages": "2726--2734",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kseniya Cherenkova, Elona Dupont, Anis Kacem, Ilya Arzhannikov, Gleb Gusev, and Djamila Aouada. Sepicnet: Sharp edges recovery by parametric inference of curves in 3d shapes. In CVPRW, pages 2726-2734, 2023.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Spelsnet: Surface primitive elements segmentation by b-rep graph structure supervision",
                "authors": [
                    {
                        "first": "Kseniya",
                        "middle": [],
                        "last": "Cherenkova",
                        "suffix": ""
                    },
                    {
                        "first": "Elona",
                        "middle": [],
                        "last": "Dupont",
                        "suffix": ""
                    },
                    {
                        "first": "Anis",
                        "middle": [],
                        "last": "Kacem",
                        "suffix": ""
                    },
                    {
                        "first": "Gleb",
                        "middle": [],
                        "last": "Gusev",
                        "suffix": ""
                    },
                    {
                        "first": "Djamila",
                        "middle": [],
                        "last": "Aouada",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "NeurIPS",
                "volume": "3",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kseniya Cherenkova, Elona Dupont, Anis Kacem, Gleb Gu- sev, and Djamila Aouada. Spelsnet: Surface primitive el- ements segmentation by b-rep graph structure supervision. NeurIPS, 2024. 3",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Cadquery: A python parametric cad scripting framework",
                "authors": [
                    {
                        "first": "Cadquery",
                        "middle": [],
                        "last": "Developers",
                        "suffix": ""
                    }
                ],
                "year": 2009,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "CADQuery Developers. Cadquery: A python paramet- ric cad scripting framework. https : / / cadquery . readthedocs.io/, 2024. Accessed: 2024-10-22. 2, 3, 4, 9",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Cadops-net: Jointly learning cad operation types and steps from boundary-representations",
                "authors": [
                    {
                        "first": "Elona",
                        "middle": [],
                        "last": "Dupont",
                        "suffix": ""
                    },
                    {
                        "first": "Kseniya",
                        "middle": [],
                        "last": "Cherenkova",
                        "suffix": ""
                    },
                    {
                        "first": "Anis",
                        "middle": [],
                        "last": "Kacem",
                        "suffix": ""
                    },
                    {
                        "first": "Aziz",
                        "middle": [],
                        "last": "Sk",
                        "suffix": ""
                    },
                    {
                        "first": "Ilya",
                        "middle": [],
                        "last": "Ali",
                        "suffix": ""
                    },
                    {
                        "first": "Gleb",
                        "middle": [],
                        "last": "Aryhannikov",
                        "suffix": ""
                    },
                    {
                        "first": "Djamila",
                        "middle": [],
                        "last": "Gusev",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Aouada",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "",
                "volume": "3",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Elona Dupont, Kseniya Cherenkova, Anis Kacem, Sk Aziz Ali, Ilya Aryhannikov, Gleb Gusev, and Djamila Aouada. Cadops-net: Jointly learning cad operation types and steps from boundary-representations. 3DV, 2022. 3",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Transcad: A hierarchical transformer for cad sequence inference from point clouds",
                "authors": [
                    {
                        "first": "Elona",
                        "middle": [],
                        "last": "Dupont",
                        "suffix": ""
                    },
                    {
                        "first": "Kseniya",
                        "middle": [],
                        "last": "Cherenkova",
                        "suffix": ""
                    },
                    {
                        "first": "Dimitrios",
                        "middle": [],
                        "last": "Mallis",
                        "suffix": ""
                    },
                    {
                        "first": "Gleb",
                        "middle": [],
                        "last": "Gusev",
                        "suffix": ""
                    },
                    {
                        "first": "Anis",
                        "middle": [],
                        "last": "Kacem",
                        "suffix": ""
                    },
                    {
                        "first": "Djamila",
                        "middle": [],
                        "last": "Aouada",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Eur. Conf. Comput. Vis",
                "volume": "2",
                "issue": "3",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Elona Dupont, Kseniya Cherenkova, Dimitrios Mallis, Gleb Gusev, Anis Kacem, and Djamila Aouada. Transcad: A hi- erarchical transformer for cad sequence inference from point clouds. In Eur. Conf. Comput. Vis., 2024. 2, 3, 4, 6, 11",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Simultaneous registration of multiple range views for use in reverse engineering of cad models",
                "authors": [
                    {
                        "first": "Andrew",
                        "middle": [
                            "W"
                        ],
                        "last": "David W Eggert",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [
                            "B"
                        ],
                        "last": "Fitzgibbon",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Fisher",
                        "suffix": ""
                    }
                ],
                "year": 1998,
                "venue": "Computer Vision and Image Understanding",
                "volume": "69",
                "issue": "3",
                "pages": "253--272",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "David W Eggert, Andrew W Fitzgibbon, and Robert B Fisher. Simultaneous registration of multiple range views for use in reverse engineering of cad models. Computer Vision and Image Understanding, 69(3):253-272, 1998.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Optimizing evolutionary csg tree extraction",
                "authors": [
                    {
                        "first": "Markus",
                        "middle": [],
                        "last": "Friedrich",
                        "suffix": ""
                    },
                    {
                        "first": "Pierre-Alain",
                        "middle": [],
                        "last": "Fayolle",
                        "suffix": ""
                    },
                    {
                        "first": "Thomas",
                        "middle": [],
                        "last": "Gabor",
                        "suffix": ""
                    },
                    {
                        "first": "Claudia",
                        "middle": [],
                        "last": "Linnhoff-Popien",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the Genetic and Evolutionary Computation Conference",
                "volume": "",
                "issue": "",
                "pages": "1183--1191",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Markus Friedrich, Pierre-Alain Fayolle, Thomas Gabor, and Claudia Linnhoff-Popien. Optimizing evolutionary csg tree extraction. In Proceedings of the Genetic and Evolutionary Computation Conference, pages 1183-1191, 2019.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Complexgen: Cad reconstruction by b-rep chain complex generation",
                "authors": [
                    {
                        "first": "Haoxiang",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Shilin",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Hao",
                        "middle": [],
                        "last": "Pan",
                        "suffix": ""
                    },
                    {
                        "first": "Yang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Xin",
                        "middle": [],
                        "last": "Tong",
                        "suffix": ""
                    },
                    {
                        "first": "Baining",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "ACM TOG",
                "volume": "41",
                "issue": "4",
                "pages": "1--18",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Haoxiang Guo, Shilin Liu, Hao Pan, Yang Liu, Xin Tong, and Baining Guo. Complexgen: Cad reconstruction by b-rep chain complex generation. ACM TOG, 41(4):1-18, 2022.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "Onellm: One framework to align all modalities with language",
                "authors": [
                    {
                        "first": "Jiaming",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    },
                    {
                        "first": "Kaixiong",
                        "middle": [],
                        "last": "Gong",
                        "suffix": ""
                    },
                    {
                        "first": "Yiyuan",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Jiaqi",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Kaipeng",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Dahua",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Yu",
                        "middle": [],
                        "last": "Qiao",
                        "suffix": ""
                    },
                    {
                        "first": "Peng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Xiangyu",
                        "middle": [],
                        "last": "Yue",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": "",
                "issue": "",
                "pages": "26584--26595",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jiaming Han, Kaixiong Gong, Yiyuan Zhang, Jiaqi Wang, Kaipeng Zhang, Dahua Lin, Yu Qiao, Peng Gao, and Xi- angyu Yue. Onellm: One framework to align all modalities with language. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 26584- 26595, 2024.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "A case study on use of 3d scanning for reverse engineering and quality control",
                "authors": [
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Robin",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Helle",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Hirpa",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Lemu",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Materials Today: Proceedings",
                "volume": "45",
                "issue": "1",
                "pages": "5255--5262",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Robin H Helle and Hirpa G Lemu. A case study on use of 3d scanning for reverse engineering and quality control. Materials Today: Proceedings, 45:5255-5262, 2021. 1",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "3d-llm: Injecting the 3d world into large language models",
                "authors": [
                    {
                        "first": "Yining",
                        "middle": [],
                        "last": "Hong",
                        "suffix": ""
                    },
                    {
                        "first": "Haoyu",
                        "middle": [],
                        "last": "Zhen",
                        "suffix": ""
                    },
                    {
                        "first": "Peihao",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Shuhong",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    },
                    {
                        "first": "Yilun",
                        "middle": [],
                        "last": "Du",
                        "suffix": ""
                    },
                    {
                        "first": "Zhenfang",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Chuang",
                        "middle": [],
                        "last": "Gan",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "NeurIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yining Hong, Haoyu Zhen, Peihao Chen, Shuhong Zheng, Yilun Du, Zhenfang Chen, and Chuang Gan. 3d-llm: Inject- ing the 3d world into large language models. NeurIPS, 2023.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "3d-llm: Injecting the 3d world into large language models",
                "authors": [
                    {
                        "first": "Yining",
                        "middle": [],
                        "last": "Hong",
                        "suffix": ""
                    },
                    {
                        "first": "Haoyu",
                        "middle": [],
                        "last": "Zhen",
                        "suffix": ""
                    },
                    {
                        "first": "Peihao",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Shuhong",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    },
                    {
                        "first": "Yilun",
                        "middle": [],
                        "last": "Du",
                        "suffix": ""
                    },
                    {
                        "first": "Zhenfang",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Chuang",
                        "middle": [],
                        "last": "Gan",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "36",
                "issue": "",
                "pages": "20482--20494",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yining Hong, Haoyu Zhen, Peihao Chen, Shuhong Zheng, Yilun Du, Zhenfang Chen, and Chuang Gan. 3d-llm: In- jecting the 3d world into large language models. Advances in Neural Information Processing Systems, 36:20482-20494, 2023.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Ucsg-net-unsupervised discovering of constructive solid geometry tree",
                "authors": [
                    {
                        "first": "Kacper",
                        "middle": [],
                        "last": "Kania",
                        "suffix": ""
                    },
                    {
                        "first": "Maciej",
                        "middle": [],
                        "last": "Zieba",
                        "suffix": ""
                    },
                    {
                        "first": "Tomasz",
                        "middle": [],
                        "last": "Kajdanowicz",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Adv. Neural Inform. Process. Syst",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kacper Kania, Maciej Zieba, and Tomasz Kajdanowicz. Ucsg-net-unsupervised discovering of constructive solid ge- ometry tree. Adv. Neural Inform. Process. Syst., 2020. 3",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Cad-signet: Cad language inference from point clouds using layer-wise sketch instance guided attention",
                "authors": [
                    {
                        "first": "Mohammad",
                        "middle": [],
                        "last": "Sadil Khan",
                        "suffix": ""
                    },
                    {
                        "first": "Elona",
                        "middle": [],
                        "last": "Dupont",
                        "suffix": ""
                    },
                    {
                        "first": "Aziz",
                        "middle": [],
                        "last": "Sk",
                        "suffix": ""
                    },
                    {
                        "first": "Kseniya",
                        "middle": [],
                        "last": "Ali",
                        "suffix": ""
                    },
                    {
                        "first": "Anis",
                        "middle": [],
                        "last": "Cherenkova",
                        "suffix": ""
                    },
                    {
                        "first": "Djamila",
                        "middle": [],
                        "last": "Kacem",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Aouada",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "IEEE Conf. Comput. Vis. Pattern Recog",
                "volume": "",
                "issue": "2",
                "pages": "4713--4722",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mohammad Sadil Khan, Elona Dupont, Sk Aziz Ali, Kseniya Cherenkova, Anis Kacem, and Djamila Aouada. Cad-signet: Cad language inference from point clouds using layer-wise sketch instance guided attention. In IEEE Conf. Comput. Vis. Pattern Recog., pages 4713-4722, 2024. 1, 2, 3, 4, 5, 6, 7, 8, 10, 11",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Abc: A big cad model dataset for geometric deep learning",
                "authors": [
                    {
                        "first": "Sebastian",
                        "middle": [],
                        "last": "Koch",
                        "suffix": ""
                    },
                    {
                        "first": "Albert",
                        "middle": [],
                        "last": "Matveev",
                        "suffix": ""
                    },
                    {
                        "first": "Zhongshi",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "Francis",
                        "middle": [],
                        "last": "Williams",
                        "suffix": ""
                    },
                    {
                        "first": "Alexey",
                        "middle": [],
                        "last": "Artemov",
                        "suffix": ""
                    },
                    {
                        "first": "Evgeny",
                        "middle": [],
                        "last": "Burnaev",
                        "suffix": ""
                    },
                    {
                        "first": "Marc",
                        "middle": [],
                        "last": "Alexa",
                        "suffix": ""
                    },
                    {
                        "first": "Denis",
                        "middle": [],
                        "last": "Zorin",
                        "suffix": ""
                    },
                    {
                        "first": "Daniele",
                        "middle": [],
                        "last": "Panozzo",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "IEEE Conf. Comput. Vis. Pattern Recog",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Sebastian Koch, Albert Matveev, Zhongshi Jiang, Francis Williams, Alexey Artemov, Evgeny Burnaev, Marc Alexa, Denis Zorin, and Daniele Panozzo. Abc: A big cad model dataset for geometric deep learning. In IEEE Conf. Comput. Vis. Pattern Recog., pages 9601-9611, 2019. 2, 4",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Reparamcad: Zero-shot cad re-parameterization for interactive manipulation",
                "authors": [
                    {
                        "first": "Milin",
                        "middle": [],
                        "last": "Kodnongbua",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Jones",
                        "suffix": ""
                    },
                    {
                        "first": "Maaz",
                        "middle": [],
                        "last": "Bin Safeer",
                        "suffix": ""
                    },
                    {
                        "first": "Vladimir",
                        "middle": [],
                        "last": "Ahmad",
                        "suffix": ""
                    },
                    {
                        "first": "Adriana",
                        "middle": [],
                        "last": "Kim",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Schulz",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "SIGGRAPH Asia 2023 Conference Papers",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Milin Kodnongbua, Benjamin Jones, Maaz Bin Safeer Ah- mad, Vladimir Kim, and Adriana Schulz. Reparamcad: Zero-shot cad re-parameterization for interactive manipula- tion. In SIGGRAPH Asia 2023 Conference Papers, New York, NY, USA, 2023. Association for Computing Machin- ery. 3",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Brepnet: A topological message passing system for solid models",
                "authors": [
                    {
                        "first": "Karl Dd",
                        "middle": [],
                        "last": "Joseph G Lambourne",
                        "suffix": ""
                    },
                    {
                        "first": "Pradeep",
                        "middle": [],
                        "last": "Willis",
                        "suffix": ""
                    },
                    {
                        "first": "Aditya",
                        "middle": [],
                        "last": "Kumar Jayaraman",
                        "suffix": ""
                    },
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Sanghi",
                        "suffix": ""
                    },
                    {
                        "first": "Hooman",
                        "middle": [],
                        "last": "Meltzer",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Shayani",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "IEEE Conf. Comput. Vis. Pattern Recog",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Joseph G Lambourne, Karl DD Willis, Pradeep Kumar Jayaraman, Aditya Sanghi, Peter Meltzer, and Hooman Shayani. Brepnet: A topological message passing system for solid models. In IEEE Conf. Comput. Vis. Pattern Recog., pages 12773-12782, 2021. 3, 5",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Reconstructing editable prismatic cad from rounded voxel models",
                "authors": [
                    {
                        "first": "Joseph",
                        "middle": [],
                        "last": "George Lambourne",
                        "suffix": ""
                    },
                    {
                        "first": "Karl",
                        "middle": [],
                        "last": "Willis",
                        "suffix": ""
                    },
                    {
                        "first": "Pradeep",
                        "middle": [],
                        "last": "Kumar Jayaraman",
                        "suffix": ""
                    },
                    {
                        "first": "Longfei",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Aditya",
                        "middle": [],
                        "last": "Sanghi",
                        "suffix": ""
                    },
                    {
                        "first": "Kamal",
                        "middle": [],
                        "last": "Rahimi Malekshan",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "SIGGRAPH Asia",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Joseph George Lambourne, Karl Willis, Pradeep Kumar Ja- yaraman, Longfei Zhang, Aditya Sanghi, and Kamal Rahimi Malekshan. Reconstructing editable prismatic cad from rounded voxel models. In SIGGRAPH Asia, pages 1-9, 2022. 3, 6, 12",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Supervised fitting of geometric primitives to 3d point clouds",
                "authors": [
                    {
                        "first": "Lingxiao",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Minhyuk",
                        "middle": [],
                        "last": "Sung",
                        "suffix": ""
                    },
                    {
                        "first": "Anastasia",
                        "middle": [],
                        "last": "Dubrovina",
                        "suffix": ""
                    },
                    {
                        "first": "Li",
                        "middle": [],
                        "last": "Yi",
                        "suffix": ""
                    },
                    {
                        "first": "Leonidas",
                        "middle": [
                            "J"
                        ],
                        "last": "Guibas",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "IEEE Conf. Comput. Vis. Pattern Recog",
                "volume": "",
                "issue": "",
                "pages": "2652--2660",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Lingxiao Li, Minhyuk Sung, Anastasia Dubrovina, Li Yi, and Leonidas J Guibas. Supervised fitting of geometric prim- itives to 3d point clouds. In IEEE Conf. Comput. Vis. Pattern Recog., pages 2652-2660, 2019.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Detecting design intent in approximate cad models using symmetry",
                "authors": [
                    {
                        "first": "Ming",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Ralph",
                        "middle": [
                            "R"
                        ],
                        "last": "Frank C Langbein",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Martin",
                        "suffix": ""
                    }
                ],
                "year": 2010,
                "venue": "Computer-Aided Design",
                "volume": "42",
                "issue": "3",
                "pages": "183--201",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ming Li, Frank C Langbein, and Ralph R Martin. Detect- ing design intent in approximate cad models using symme- try. Computer-Aided Design, 42(3):183-201, 2010.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Secad-net: Self-supervised cad reconstruction by learning sketch-extrude operations",
                "authors": [
                    {
                        "first": "Pu",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Jianwei",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaopeng",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Dong-Ming",
                        "middle": [],
                        "last": "Yan",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "IEEE Conf. Comput. Vis. Pattern Recog",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Pu Li, Jianwei Guo, Xiaopeng Zhang, and Dong-Ming Yan. Secad-net: Self-supervised cad reconstruction by learning sketch-extrude operations. In IEEE Conf. Comput. Vis. Pat- tern Recog., pages 16816-16826, 2023. 2, 3",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Sfmcad: Unsupervised cad reconstruction by learning sketch-based feature modeling operations",
                "authors": [
                    {
                        "first": "Pu",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Jianwei",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Huibin",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Bedrich",
                        "middle": [],
                        "last": "Benes",
                        "suffix": ""
                    },
                    {
                        "first": "Dong-Ming",
                        "middle": [],
                        "last": "Yan",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": "",
                "issue": "",
                "pages": "4671--4680",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Pu Li, Jianwei Guo, Huibin Li, Bedrich Benes, and Dong- Ming Yan. Sfmcad: Unsupervised cad reconstruction by learning sketch-based feature modeling operations. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4671-4680, 2024.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Fast industrial product design method and its application based on 3d cad system",
                "authors": [
                    {
                        "first": "Fei",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Computer-Aided Design and Applications",
                "volume": "18",
                "issue": "3",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Fei Liu. Fast industrial product design method and its appli- cation based on 3d cad system. Computer-Aided Design and Applications, 18(S3):118-128, 2020. 1",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Openshape: Scaling up 3d shape representation towards open-world understanding",
                "authors": [
                    {
                        "first": "Minghua",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Ruoxi",
                        "middle": [],
                        "last": "Shi",
                        "suffix": ""
                    },
                    {
                        "first": "Kaiming",
                        "middle": [],
                        "last": "Kuang",
                        "suffix": ""
                    },
                    {
                        "first": "Yinhao",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Xuanlin",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Shizhong",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    },
                    {
                        "first": "Hong",
                        "middle": [],
                        "last": "Cai",
                        "suffix": ""
                    },
                    {
                        "first": "Fatih",
                        "middle": [],
                        "last": "Porikli",
                        "suffix": ""
                    },
                    {
                        "first": "Hao",
                        "middle": [],
                        "last": "Su",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Advances in neural information processing systems",
                "volume": "36",
                "issue": "2",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Minghua Liu, Ruoxi Shi, Kaiming Kuang, Yinhao Zhu, Xu- anlin Li, Shizhong Han, Hong Cai, Fatih Porikli, and Hao Su. Openshape: Scaling up 3d shape representation towards open-world understanding. Advances in neural information processing systems, 36, 2024. 2",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Pc2wf: 3d wireframe reconstruction from raw point clouds",
                "authors": [
                    {
                        "first": "Yujia",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "D'",
                        "middle": [],
                        "last": "Stefano",
                        "suffix": ""
                    },
                    {
                        "first": "Konrad",
                        "middle": [],
                        "last": "Aronco",
                        "suffix": ""
                    },
                    {
                        "first": "Jan",
                        "middle": [
                            "Dirk"
                        ],
                        "last": "Schindler",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Wegner",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "ICLR",
                "volume": "3",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Yujia Liu, Stefano D'Aronco, Konrad Schindler, and Jan Dirk Wegner. Pc2wf: 3d wireframe reconstruction from raw point clouds. ICLR, 2021. 3",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "Multicad: Contrastive representation learning for multi-modal 3d computer-aided design models",
                "authors": [
                    {
                        "first": "Weijian",
                        "middle": [],
                        "last": "Ma",
                        "suffix": ""
                    },
                    {
                        "first": "Minyang",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Xueyang",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Xiangdong",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "CIKM",
                "volume": "2",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Weijian Ma, Minyang Xu, Xueyang Li, and Xiangdong Zhou. Multicad: Contrastive representation learning for multi-modal 3d computer-aided design models. In CIKM, New York, NY, USA, 2023. Association for Computing Ma- chinery. 2, 3, 4, 6",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "Draw step by step: Reconstructing cad construction sequences from point clouds via multimodal diffusion",
                "authors": [
                    {
                        "first": "Weijian",
                        "middle": [],
                        "last": "Ma",
                        "suffix": ""
                    },
                    {
                        "first": "Shuaiqi",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Yunzhong",
                        "middle": [],
                        "last": "Lou",
                        "suffix": ""
                    },
                    {
                        "first": "Xueyang",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Xiangdong",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "IEEE Conf. Comput. Vis. Pattern Recog",
                "volume": "",
                "issue": "",
                "pages": "27154--27163",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Weijian Ma, Shuaiqi Chen, Yunzhong Lou, Xueyang Li, and Xiangdong Zhou. Draw step by step: Reconstructing cad construction sequences from point clouds via multimodal diffusion. In IEEE Conf. Comput. Vis. Pattern Recog., pages 27154-27163, 2024. 1, 2, 3, 4, 6, 12",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "Sharp challenge 2023: Solving cad history and parameters recovery from point clouds and 3d scans. overview, datasets, metrics, and baselines",
                "authors": [
                    {
                        "first": "Dimitrios",
                        "middle": [],
                        "last": "Mallis",
                        "suffix": ""
                    },
                    {
                        "first": "Ali",
                        "middle": [],
                        "last": "Sk Aziz",
                        "suffix": ""
                    },
                    {
                        "first": "Elona",
                        "middle": [],
                        "last": "Dupont",
                        "suffix": ""
                    },
                    {
                        "first": "Kseniya",
                        "middle": [],
                        "last": "Cherenkova",
                        "suffix": ""
                    },
                    {
                        "first": "Ahmet",
                        "middle": [
                            "Serdar"
                        ],
                        "last": "Karadeniz",
                        "suffix": ""
                    },
                    {
                        "first": "Mohammad",
                        "middle": [],
                        "last": "Sadil Khan",
                        "suffix": ""
                    },
                    {
                        "first": "Anis",
                        "middle": [],
                        "last": "Kacem",
                        "suffix": ""
                    },
                    {
                        "first": "Gleb",
                        "middle": [],
                        "last": "Gusev",
                        "suffix": ""
                    },
                    {
                        "first": "Djamila",
                        "middle": [],
                        "last": "Aouada",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "CVPRW",
                "volume": "6",
                "issue": "9",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Dimitrios Mallis, Ali Sk Aziz, Elona Dupont, Kseniya Cherenkova, Ahmet Serdar Karadeniz, Mohammad Sadil Khan, Anis Kacem, Gleb Gusev, and Djamila Aouada. Sharp challenge 2023: Solving cad history and parameters recovery from point clouds and 3d scans. overview, datasets, metrics, and baselines. In CVPRW, 2023. 6, 9, 11",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "Pythonocc -3d cad/bim/plm/cam framework",
                "authors": [
                    {
                        "first": "Thomas",
                        "middle": [],
                        "last": "Paviot",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Thomas Paviot. Pythonocc -3d cad/bim/plm/cam frame- work, 2022. 9",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "Can large language models understand symbolic graphics programs?",
                "authors": [
                    {
                        "first": "Zeju",
                        "middle": [],
                        "last": "Qiu",
                        "suffix": ""
                    },
                    {
                        "first": "Weiyang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Haiwen",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    },
                    {
                        "first": "Zhen",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [
                            "Z"
                        ],
                        "last": "Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Katherine",
                        "middle": [
                            "M"
                        ],
                        "last": "Collins",
                        "suffix": ""
                    },
                    {
                        "first": "Joshua",
                        "middle": [
                            "B"
                        ],
                        "last": "Tenenbaum",
                        "suffix": ""
                    },
                    {
                        "first": "Adrian",
                        "middle": [],
                        "last": "Weller",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [
                            "J"
                        ],
                        "last": "Black",
                        "suffix": ""
                    },
                    {
                        "first": "Bernhard",
                        "middle": [],
                        "last": "Sch\u00f6lkopf",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2408.08313"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Zeju Qiu, Weiyang Liu, Haiwen Feng, Zhen Liu, Tim Z Xiao, Katherine M Collins, Joshua B Tenenbaum, Adrian Weller, Michael J Black, and Bernhard Sch\u00f6lkopf. Can large language models understand symbolic graphics programs? arXiv preprint arXiv:2408.08313, 2024. 3, 7, 16",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "Extrudenet: Unsupervised inverse sketchand-extrude for shape parsing",
                "authors": [
                    {
                        "first": "Daxuan",
                        "middle": [],
                        "last": "Ren",
                        "suffix": ""
                    },
                    {
                        "first": "Jianmin",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfei",
                        "middle": [],
                        "last": "Cai",
                        "suffix": ""
                    },
                    {
                        "first": "Jiatong",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Junzhe",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "Eur. Conf. Comput. Vis",
                "volume": "2",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Daxuan Ren, Jianmin Zheng, Jianfei Cai, Jiatong Li, and Junzhe Zhang. Extrudenet: Unsupervised inverse sketch- and-extrude for shape parsing. In Eur. Conf. Comput. Vis., pages 482-498. Springer, 2022. 2, 3",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Sanh",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:1910.01108"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "V Sanh. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108, 2019.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "Vitruvion: A generative model of parametric cad sketches",
                "authors": [
                    {
                        "first": "Ari",
                        "middle": [],
                        "last": "Seff",
                        "suffix": ""
                    },
                    {
                        "first": "Wenda",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Nick",
                        "middle": [],
                        "last": "Richardson",
                        "suffix": ""
                    },
                    {
                        "first": "Ryan",
                        "middle": [
                            "P"
                        ],
                        "last": "Adams",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "ICLR",
                "volume": "3",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Ari Seff, Wenda Zhou, Nick Richardson, and Ryan P Adams. Vitruvion: A generative model of parametric cad sketches. In ICLR, 2022. 3",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "Parsenet: A parametric surface fitting network for 3d point clouds",
                "authors": [
                    {
                        "first": "Gopal",
                        "middle": [],
                        "last": "Sharma",
                        "suffix": ""
                    },
                    {
                        "first": "Difan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Subhransu",
                        "middle": [],
                        "last": "Maji",
                        "suffix": ""
                    },
                    {
                        "first": "Evangelos",
                        "middle": [],
                        "last": "Kalogerakis",
                        "suffix": ""
                    },
                    {
                        "first": "Siddhartha",
                        "middle": [],
                        "last": "Chaudhuri",
                        "suffix": ""
                    },
                    {
                        "first": "Radom\u00edr",
                        "middle": [],
                        "last": "M\u011bch",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Eur. Conf. Comput. Vis",
                "volume": "",
                "issue": "",
                "pages": "261--276",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Gopal Sharma, Difan Liu, Subhransu Maji, Evangelos Kalogerakis, Siddhartha Chaudhuri, and Radom\u00edr M\u011bch. Parsenet: A parametric surface fitting network for 3d point clouds. In Eur. Conf. Comput. Vis., pages 261-276. Springer, 2020.",
                "links": null
            },
            "BIBREF42": {
                "ref_id": "b42",
                "title": "Industrial inspection and reverse engineering",
                "authors": [
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Tarek",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Sobh",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Owen",
                        "suffix": ""
                    },
                    {
                        "first": "Mohamed",
                        "middle": [],
                        "last": "Jaynes",
                        "suffix": ""
                    },
                    {
                        "first": "Thomas",
                        "middle": [
                            "C"
                        ],
                        "last": "Dekhil",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Henderson",
                        "suffix": ""
                    }
                ],
                "year": 1994,
                "venue": "Proceedings of 1994 IEEE 2nd CAD-Based Vision Workshop",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tarek M Sobh, J Owen, C Jaynes, Mohamed Dekhil, and Thomas C Henderson. Industrial inspection and reverse en- gineering. In Proceedings of 1994 IEEE 2nd CAD-Based Vision Workshop, pages 228-235. IEEE, 1994. 1",
                "links": null
            },
            "BIBREF43": {
                "ref_id": "b43",
                "title": "Qwen2-1",
                "authors": [],
                "year": 2009,
                "venue": "Qwen Team",
                "volume": "",
                "issue": "5",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Qwen Team. Qwen2-1.5b. https://huggingface. co/Qwen/Qwen2-1.5B, 2024. Accessed: Nov. 2024. 9",
                "links": null
            },
            "BIBREF44": {
                "ref_id": "b44",
                "title": "Point2cyl: Reverse engineering 3d objects from point clouds to extrusion cylinders",
                "authors": [
                    {
                        "first": "Angelina",
                        "middle": [],
                        "last": "Mikaela",
                        "suffix": ""
                    },
                    {
                        "first": "Yen-Yu",
                        "middle": [],
                        "last": "Uy",
                        "suffix": ""
                    },
                    {
                        "first": "Minhyuk",
                        "middle": [],
                        "last": "Chang",
                        "suffix": ""
                    },
                    {
                        "first": "Purvi",
                        "middle": [],
                        "last": "Sung",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Goel",
                        "suffix": ""
                    },
                    {
                        "first": "Tolga",
                        "middle": [],
                        "last": "Joseph G Lambourne",
                        "suffix": ""
                    },
                    {
                        "first": "Leonidas",
                        "middle": [
                            "J"
                        ],
                        "last": "Birdal",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Guibas",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "IEEE Conf. Comput. Vis. Pattern Recog",
                "volume": "",
                "issue": "2",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mikaela Angelina Uy, Yen-Yu Chang, Minhyuk Sung, Purvi Goel, Joseph G Lambourne, Tolga Birdal, and Leonidas J Guibas. Point2cyl: Reverse engineering 3d objects from point clouds to extrusion cylinders. In IEEE Conf. Comput. Vis. Pattern Recog., pages 11850-11860, 2022. 1, 2, 3, 6",
                "links": null
            },
            "BIBREF45": {
                "ref_id": "b45",
                "title": "Pie-net: Parametric inference of point cloud edges",
                "authors": [
                    {
                        "first": "Xiaogang",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Yuelang",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Kai",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Andrea",
                        "middle": [],
                        "last": "Tagliasacchi",
                        "suffix": ""
                    },
                    {
                        "first": "Bin",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Ali",
                        "middle": [],
                        "last": "Mahdavi-Amiri",
                        "suffix": ""
                    },
                    {
                        "first": "Hao",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Adv. Neural Inform. Process. Syst",
                "volume": "33",
                "issue": "",
                "pages": "20167--20178",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xiaogang Wang, Yuelang Xu, Kai Xu, Andrea Tagliasac- chi, Bin Zhou, Ali Mahdavi-Amiri, and Hao Zhang. Pie-net: Parametric inference of point cloud edges. Adv. Neural In- form. Process. Syst., 33:20167-20178, 2020.",
                "links": null
            },
            "BIBREF46": {
                "ref_id": "b46",
                "title": "Fusion 360 gallery: A dataset and environment for programmatic cad construction from human design sequences",
                "authors": [
                    {
                        "first": "Karl Dd",
                        "middle": [],
                        "last": "Willis",
                        "suffix": ""
                    },
                    {
                        "first": "Yewen",
                        "middle": [],
                        "last": "Pu",
                        "suffix": ""
                    },
                    {
                        "first": "Jieliang",
                        "middle": [],
                        "last": "Luo",
                        "suffix": ""
                    },
                    {
                        "first": "Hang",
                        "middle": [],
                        "last": "Chu",
                        "suffix": ""
                    },
                    {
                        "first": "Tao",
                        "middle": [],
                        "last": "Du",
                        "suffix": ""
                    },
                    {
                        "first": "Armando",
                        "middle": [],
                        "last": "Joseph G Lambourne",
                        "suffix": ""
                    },
                    {
                        "first": "Wojciech",
                        "middle": [],
                        "last": "Solar-Lezama",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Matusik",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "ACM TOG",
                "volume": "40",
                "issue": "4",
                "pages": "1--24",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Karl DD Willis, Yewen Pu, Jieliang Luo, Hang Chu, Tao Du, Joseph G Lambourne, Armando Solar-Lezama, and Wo- jciech Matusik. Fusion 360 gallery: A dataset and environ- ment for programmatic cad construction from human design sequences. ACM TOG, 40(4):1-24, 2021. 2, 3, 4, 6, 11",
                "links": null
            },
            "BIBREF47": {
                "ref_id": "b47",
                "title": "Deepcad: A deep generative network for computer-aided design models",
                "authors": [
                    {
                        "first": "Rundi",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Chang",
                        "middle": [],
                        "last": "Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Changxi",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "IEEE Conf. Comput. Vis. Pattern Recog",
                "volume": "",
                "issue": "3",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Rundi Wu, Chang Xiao, and Changxi Zheng. Deepcad: A deep generative network for computer-aided design models. In IEEE Conf. Comput. Vis. Pattern Recog., pages 6772- 6782, 2021. 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 16",
                "links": null
            },
            "BIBREF48": {
                "ref_id": "b48",
                "title": "Pointllm: Empowering large language models to understand point clouds",
                "authors": [
                    {
                        "first": "Runsen",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaolong",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Tai",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Yilun",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Jiangmiao",
                        "middle": [],
                        "last": "Pang",
                        "suffix": ""
                    },
                    {
                        "first": "Dahua",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "ECCV",
                "volume": "2",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Runsen Xu, Xiaolong Wang, Tai Wang, Yilun Chen, Jiang- miao Pang, and Dahua Lin. Pointllm: Empowering large lan- guage models to understand point clouds. In ECCV, 2024. 2, 8",
                "links": null
            },
            "BIBREF49": {
                "ref_id": "b49",
                "title": "Inferring cad modeling sequences using zone graphs",
                "authors": [
                    {
                        "first": "Xianghao",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Wenzhe",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    },
                    {
                        "first": "Chin-Yi",
                        "middle": [],
                        "last": "Cheng",
                        "suffix": ""
                    },
                    {
                        "first": "Karl Dd",
                        "middle": [],
                        "last": "Willis",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Ritchie",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "IEEE Conf. Comput. Vis. Pattern Recog",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xianghao Xu, Wenzhe Peng, Chin-Yi Cheng, Karl DD Willis, and Daniel Ritchie. Inferring cad modeling sequences using zone graphs. In IEEE Conf. Comput. Vis. Pattern Recog., pages 6062-6070, 2021. 2, 3",
                "links": null
            },
            "BIBREF50": {
                "ref_id": "b50",
                "title": "Skexgen: Autoregressive generation of cad construction sequences with disentangled codebooks",
                "authors": [
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Karl Dd",
                        "middle": [],
                        "last": "Willis",
                        "suffix": ""
                    },
                    {
                        "first": "Joseph",
                        "middle": [
                            "G"
                        ],
                        "last": "Lambourne",
                        "suffix": ""
                    },
                    {
                        "first": "Chin-Yi",
                        "middle": [],
                        "last": "Cheng",
                        "suffix": ""
                    },
                    {
                        "first": "Pradeep",
                        "middle": [],
                        "last": "Kumar Jayaraman",
                        "suffix": ""
                    },
                    {
                        "first": "Yasutaka",
                        "middle": [],
                        "last": "Furukawa",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "ICML",
                "volume": "3",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xiang Xu, Karl DD Willis, Joseph G Lambourne, Chin- Yi Cheng, Pradeep Kumar Jayaraman, and Yasutaka Fu- rukawa. Skexgen: Autoregressive generation of cad con- struction sequences with disentangled codebooks. In ICML, pages 24698-24724. PMLR, 2022. 3, 9",
                "links": null
            },
            "BIBREF51": {
                "ref_id": "b51",
                "title": "Hierarchical neural coding for controllable cad model generation",
                "authors": [
                    {
                        "first": "Xiang",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Pradeep",
                        "middle": [],
                        "last": "Kumar Jayaraman",
                        "suffix": ""
                    },
                    {
                        "first": "Joseph",
                        "middle": [
                            "G"
                        ],
                        "last": "Lambourne",
                        "suffix": ""
                    },
                    {
                        "first": "Karl Dd",
                        "middle": [],
                        "last": "Willis",
                        "suffix": ""
                    },
                    {
                        "first": "Yasutaka",
                        "middle": [],
                        "last": "Furukawa",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "ICML",
                "volume": "3",
                "issue": "6",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xiang Xu, Pradeep Kumar Jayaraman, Joseph G Lambourne, Karl DD Willis, and Yasutaka Furukawa. Hierarchical neural coding for controllable cad model generation. ICML, 2023. 3, 6, 12",
                "links": null
            },
            "BIBREF52": {
                "ref_id": "b52",
                "title": "Ulip: Learning a unified representation of language, images, and point clouds for 3d understanding",
                "authors": [
                    {
                        "first": "Le",
                        "middle": [],
                        "last": "Xue",
                        "suffix": ""
                    },
                    {
                        "first": "Mingfei",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Chen",
                        "middle": [],
                        "last": "Xing",
                        "suffix": ""
                    },
                    {
                        "first": "Roberto",
                        "middle": [],
                        "last": "Mart\u00edn-Mart\u00edn",
                        "suffix": ""
                    },
                    {
                        "first": "Jiajun",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Caiming",
                        "middle": [],
                        "last": "Xiong",
                        "suffix": ""
                    },
                    {
                        "first": "Ran",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Juan",
                        "middle": [
                            "Carlos"
                        ],
                        "last": "Niebles",
                        "suffix": ""
                    },
                    {
                        "first": "Silvio",
                        "middle": [],
                        "last": "Savarese",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "Proceedings of the IEEE/CVF conference on computer vision and pattern recognition",
                "volume": "",
                "issue": "",
                "pages": "1179--1189",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Le Xue, Mingfei Gao, Chen Xing, Roberto Mart\u00edn-Mart\u00edn, Jiajun Wu, Caiming Xiong, Ran Xu, Juan Carlos Niebles, and Silvio Savarese. Ulip: Learning a unified representation of language, images, and point clouds for 3d understanding. In Proceedings of the IEEE/CVF conference on computer vi- sion and pattern recognition, pages 1179-1189, 2023.",
                "links": null
            },
            "BIBREF53": {
                "ref_id": "b53",
                "title": "Ulip-2: Towards scalable multimodal pre-training for 3d understanding",
                "authors": [
                    {
                        "first": "Le",
                        "middle": [],
                        "last": "Xue",
                        "suffix": ""
                    },
                    {
                        "first": "Ning",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Shu",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Artemis",
                        "middle": [],
                        "last": "Panagopoulou",
                        "suffix": ""
                    },
                    {
                        "first": "Junnan",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Roberto",
                        "middle": [],
                        "last": "Mart\u00edn-Mart\u00edn",
                        "suffix": ""
                    },
                    {
                        "first": "Jiajun",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Caiming",
                        "middle": [],
                        "last": "Xiong",
                        "suffix": ""
                    },
                    {
                        "first": "Ran",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Juan",
                        "middle": [
                            "Carlos"
                        ],
                        "last": "Niebles",
                        "suffix": ""
                    },
                    {
                        "first": "Silvio",
                        "middle": [],
                        "last": "Savarese",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": "",
                "issue": "",
                "pages": "27091--27101",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Le Xue, Ning Yu, Shu Zhang, Artemis Panagopoulou, Jun- nan Li, Roberto Mart\u00edn-Mart\u00edn, Jiajun Wu, Caiming Xiong, Ran Xu, Juan Carlos Niebles, and Silvio Savarese. Ulip-2: Towards scalable multimodal pre-training for 3d understand- ing. In Proceedings of the IEEE/CVF Conference on Com- puter Vision and Pattern Recognition (CVPR), pages 27091- 27101, 2024.",
                "links": null
            },
            "BIBREF54": {
                "ref_id": "b54",
                "title": "Qwen2 technical report",
                "authors": [
                    {
                        "first": "An",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Baosong",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Binyuan",
                        "middle": [],
                        "last": "Hui",
                        "suffix": ""
                    },
                    {
                        "first": "Bo",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    },
                    {
                        "first": "Bowen",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Chang",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Chengpeng",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Chengyuan",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Dayiheng",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Fei",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Guanting",
                        "middle": [],
                        "last": "Dong",
                        "suffix": ""
                    },
                    {
                        "first": "Haoran",
                        "middle": [],
                        "last": "Wei",
                        "suffix": ""
                    },
                    {
                        "first": "Huan",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Jialong",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "Jialin",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Jian",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Jianhong",
                        "middle": [],
                        "last": "Tu",
                        "suffix": ""
                    },
                    {
                        "first": "Jianwei",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Jianxin",
                        "middle": [],
                        "last": "Ma",
                        "suffix": ""
                    },
                    {
                        "first": "Jianxin",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Jin",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Jingren",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Jinze",
                        "middle": [],
                        "last": "Bai",
                        "suffix": ""
                    },
                    {
                        "first": "Jinzheng",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Junyang",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Kai",
                        "middle": [],
                        "last": "Dang",
                        "suffix": ""
                    },
                    {
                        "first": "Keming",
                        "middle": [],
                        "last": "Lu",
                        "suffix": ""
                    },
                    {
                        "first": "Keqin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Kexin",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Mei",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Mingfeng",
                        "middle": [],
                        "last": "Xue",
                        "suffix": ""
                    },
                    {
                        "first": "Na",
                        "middle": [],
                        "last": "Ni",
                        "suffix": ""
                    },
                    {
                        "first": "Pei",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Peng",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Ru",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    },
                    {
                        "first": "Rui",
                        "middle": [],
                        "last": "Men",
                        "suffix": ""
                    },
                    {
                        "first": "Ruize",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Runji",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Shijie",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Shuai",
                        "middle": [],
                        "last": "Bai",
                        "suffix": ""
                    },
                    {
                        "first": "Sinan",
                        "middle": [],
                        "last": "Tan",
                        "suffix": ""
                    },
                    {
                        "first": "Tianhang",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Tianhao",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Tianyu",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Wenbin",
                        "middle": [],
                        "last": "Ge",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaodong",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaohuan",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Xingzhang",
                        "middle": [],
                        "last": "Ren",
                        "suffix": ""
                    },
                    {
                        "first": "Xinyu",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Xipin",
                        "middle": [],
                        "last": "Wei",
                        "suffix": ""
                    },
                    {
                        "first": "Xuancheng",
                        "middle": [],
                        "last": "Ren",
                        "suffix": ""
                    },
                    {
                        "first": "Xuejing",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Yang",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    },
                    {
                        "first": "Yang",
                        "middle": [],
                        "last": "Yao",
                        "suffix": ""
                    },
                    {
                        "first": "Yichang",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Yu",
                        "middle": [],
                        "last": "Wan",
                        "suffix": ""
                    },
                    {
                        "first": "Yunfei",
                        "middle": [],
                        "last": "Chu",
                        "suffix": ""
                    },
                    {
                        "first": "Yuqiong",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Zeyu",
                        "middle": [],
                        "last": "Cui",
                        "suffix": ""
                    },
                    {
                        "first": "Zhenru",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Zhifang",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Zhihao",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "2",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jian- wei Zhang, Jianxin Ma, Jianxin Yang, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tian- hao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Xuejing Liu, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zhifang Guo, and Zhihao Fan. Qwen2 technical report, 2024. 2, 4, 5",
                "links": null
            },
            "BIBREF55": {
                "ref_id": "b55",
                "title": "Shapegpt: 3d shape generation with a unified multi-modal language model",
                "authors": [
                    {
                        "first": "Fukun",
                        "middle": [],
                        "last": "Yin",
                        "suffix": ""
                    },
                    {
                        "first": "Xin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Chi",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Biao",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "Zibo",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Jiayuan",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    },
                    {
                        "first": "Gang",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Taihao",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Tao",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "",
                "volume": "2",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Fukun Yin, Xin Chen, Chi Zhang, Biao Jiang, Zibo Zhao, Ji- ayuan Fan, Gang Yu, Taihao Li, and Tao Chen. Shapegpt: 3d shape generation with a unified multi-modal language model, 2023. 2",
                "links": null
            },
            "BIBREF56": {
                "ref_id": "b56",
                "title": "Img2cad: Reverse engineering 3d cad models from images through vlm-assisted conditional factorization",
                "authors": [
                    {
                        "first": "Yang",
                        "middle": [],
                        "last": "You",
                        "suffix": ""
                    },
                    {
                        "first": "Mikaela",
                        "middle": [
                            "Angelina"
                        ],
                        "last": "Uy",
                        "suffix": ""
                    },
                    {
                        "first": "Jiaqi",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    },
                    {
                        "first": "Rahul",
                        "middle": [],
                        "last": "Thomas",
                        "suffix": ""
                    },
                    {
                        "first": "Haotong",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Suya",
                        "middle": [],
                        "last": "You",
                        "suffix": ""
                    },
                    {
                        "first": "Leonidas",
                        "middle": [],
                        "last": "Guibas",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2408.01437"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Yang You, Mikaela Angelina Uy, Jiaqi Han, Rahul Thomas, Haotong Zhang, Suya You, and Leonidas Guibas. Img2cad: Reverse engineering 3d cad models from images through vlm-assisted conditional factorization. arXiv preprint arXiv:2408.01437, 2024.",
                "links": null
            },
            "BIBREF57": {
                "ref_id": "b57",
                "title": "D2csg: Unsupervised learning of compact csg trees with dual complements and dropouts",
                "authors": [
                    {
                        "first": "Fenggen",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Qimin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Maham",
                        "middle": [],
                        "last": "Tanveer",
                        "suffix": ""
                    },
                    {
                        "first": "Ali",
                        "middle": [],
                        "last": "Mahdavi Amiri",
                        "suffix": ""
                    },
                    {
                        "first": "Hao",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "36",
                "issue": "",
                "pages": "22807--22819",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Fenggen Yu, Qimin Chen, Maham Tanveer, Ali Mah- davi Amiri, and Hao Zhang. D2csg: Unsupervised learning of compact csg trees with dual complements and dropouts. Advances in Neural Information Processing Systems, 36: 22807-22819, 2023.",
                "links": null
            },
            "BIBREF58": {
                "ref_id": "b58",
                "title": "D2csg: Unsupervised learning of compact csg trees with dual complements and dropouts",
                "authors": [
                    {
                        "first": "Fenggen",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Qimin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Maham",
                        "middle": [],
                        "last": "Tanveer",
                        "suffix": ""
                    },
                    {
                        "first": "Ali",
                        "middle": [],
                        "last": "Mahdavi Amiri",
                        "suffix": ""
                    },
                    {
                        "first": "Hao",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "36",
                "issue": "3",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Fenggen Yu, Qimin Chen, Maham Tanveer, Ali Mah- davi Amiri, and Hao Zhang. D2csg: Unsupervised learning of compact csg trees with dual complements and dropouts. Advances in Neural Information Processing Systems, 36, 2024. 3",
                "links": null
            },
            "BIBREF59": {
                "ref_id": "b59",
                "title": "Cadtalk: An algorithm and benchmark for semantic commenting of cad programs",
                "authors": [
                    {
                        "first": "Haocheng",
                        "middle": [],
                        "last": "Yuan",
                        "suffix": ""
                    },
                    {
                        "first": "Jing",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Hao",
                        "middle": [],
                        "last": "Pan",
                        "suffix": ""
                    },
                    {
                        "first": "Adrien",
                        "middle": [],
                        "last": "Bousseau",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Niloy",
                        "suffix": ""
                    },
                    {
                        "first": "Changjian",
                        "middle": [],
                        "last": "Mitra",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": "",
                "issue": "",
                "pages": "3753--3762",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Haocheng Yuan, Jing Xu, Hao Pan, Adrien Bousseau, Niloy J Mitra, and Changjian Li. Cadtalk: An algorithm and benchmark for semantic commenting of cad programs. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3753-3762, 2024.",
                "links": null
            },
            "BIBREF60": {
                "ref_id": "b60",
                "title": "Pointclip: Point cloud understanding by clip",
                "authors": [
                    {
                        "first": "Renrui",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Ziyu",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Kunchang",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Xupeng",
                        "middle": [],
                        "last": "Miao",
                        "suffix": ""
                    },
                    {
                        "first": "Bin",
                        "middle": [],
                        "last": "Cui",
                        "suffix": ""
                    },
                    {
                        "first": "Yu",
                        "middle": [],
                        "last": "Qiao",
                        "suffix": ""
                    },
                    {
                        "first": "Peng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Hongsheng",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "Proceedings of the IEEE/CVF conference on computer vision and pattern recognition",
                "volume": "",
                "issue": "",
                "pages": "8552--8562",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Renrui Zhang, Ziyu Guo, Wei Zhang, Kunchang Li, Xu- peng Miao, Bin Cui, Yu Qiao, Peng Gao, and Hongsheng Li. Pointclip: Point cloud understanding by clip. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 8552-8562, 2022. 2",
                "links": null
            },
            "BIBREF61": {
                "ref_id": "b61",
                "title": "Michelangelo: Conditional 3d shape generation based on shape-image-text aligned latent representation",
                "authors": [
                    {
                        "first": "Zibo",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Wen",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Xin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Xianfang",
                        "middle": [],
                        "last": "Zeng",
                        "suffix": ""
                    },
                    {
                        "first": "Rui",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Pei",
                        "middle": [],
                        "last": "Cheng",
                        "suffix": ""
                    },
                    {
                        "first": "Bin",
                        "middle": [],
                        "last": "Fu",
                        "suffix": ""
                    },
                    {
                        "first": "Tao",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [
                            "U"
                        ],
                        "last": "Gang",
                        "suffix": ""
                    },
                    {
                        "first": "Shenghua",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "Thirtyseventh Conference on Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Zibo Zhao, Wen Liu, Xin Chen, Xianfang Zeng, Rui Wang, Pei Cheng, BIN FU, Tao Chen, Gang YU, and Shenghua Gao. Michelangelo: Conditional 3d shape generation based on shape-image-text aligned latent representation. In Thirty- seventh Conference on Neural Information Processing Sys- tems, 2023. 2, 5",
                "links": null
            },
            "BIBREF62": {
                "ref_id": "b62",
                "title": "Nerve: Neural volumetric edges for parametric curve extraction from point cloud",
                "authors": [
                    {
                        "first": "Xiangyu",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Dong",
                        "middle": [],
                        "last": "Du",
                        "suffix": ""
                    },
                    {
                        "first": "Weikai",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Zhiyou",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Yinyu",
                        "middle": [],
                        "last": "Nie",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoguang",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "IEEE Conf. Comput. Vis. Pattern Recog",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xiangyu Zhu, Dong Du, Weikai Chen, Zhiyou Zhao, Yinyu Nie, and Xiaoguang Han. Nerve: Neural volumetric edges for parametric curve extraction from point cloud. In IEEE Conf. Comput. Vis. Pattern Recog., pages 13601-13610, 2023. 3",
                "links": null
            },
            "BIBREF63": {
                "ref_id": "b63",
                "title": "Pointclip v2: Prompting clip and gpt for powerful 3d open-world learning",
                "authors": [
                    {
                        "first": "Xiangyang",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Renrui",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Bowei",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Ziyu",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Ziyao",
                        "middle": [],
                        "last": "Zeng",
                        "suffix": ""
                    },
                    {
                        "first": "Zipeng",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    },
                    {
                        "first": "Shanghang",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Peng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": "",
                "issue": "",
                "pages": "2639--2650",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xiangyang Zhu, Renrui Zhang, Bowei He, Ziyu Guo, Ziyao Zeng, Zipeng Qin, Shanghang Zhang, and Peng Gao. Point- clip v2: Prompting clip and gpt for powerful 3d open-world learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 2639-2650, 2023.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "text": "Figure 1. 3D CAD reverse engineering is a process of converting a point cloud into a CAD model (top). Existing methods are constrained by the use of method-specific CAD representations and limited hand-crafted training datasets (a). On the contrary, CAD-Recode employs a pre-trained LLM with a lightweight projector that translates point clouds into executable Python code and is trained on a procedurally generated dataset (b).",
                "fig_num": "1",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF1": {
                "text": "Figure 2. Sketch-extrude sequence (top) in DeepCAD representation (middle) and our CadQuery code (bottom).",
                "fig_num": "1",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF2": {
                "text": "Interpretability and LLM Compatibility: The proposed representation, based on Python and CadQuery syntax, presents an alternative to abstract numerical encodings with improved interpretability. Its code-based format facilitates model editing both programmatically and through CAD software. Importantly, this representation aligns with pretrained LLMs' demonstrated proficiency in Python code generation and manipulation. Indeed, state-of-the-art proprietary LLMs like GPT-4 [36] achieve over 90% accuracy on the Python code HumanEval benchmark [5], while even lightweight open-source models such as Qwen2-1.5B [55] show promising code generation capabilities. Hence, this code representation facilitates fine-tuning of pre-trained LLMs for the specific task of reverse engineering point clouds into CAD Python code and opens the doors for new capabilities with off-the-shelf LLMs.",
                "fig_num": "3",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF3": {
                "text": "Figure 3. Examples of procedurally generated CAD models.",
                "fig_num": "3",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF5": {
                "text": "Figure 4. Overview of CAD-Recode. The pipeline comprises two parts: (1) a point cloud projector (marked blue) (2) a fine-tuned pretrained LLM (yellow). An input point cloud is processed using (1), and outputs are then passed to an LLM (2), which predicts a CAD sketch-extrude sequence in the form of executable Python code.",
                "fig_num": "4",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF6": {
                "text": "Figure 6. Interactive editing of a CAD model. Given the code output from CAD-Recode and a generic prompt, GPT-4o allows automated and interactive editing of the CAD model.",
                "fig_num": "6",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF7": {
                "text": "Figure 13 illustrates the predicted code sequences and their corresponding reconstructed shapes. The predicted codes have a syntax that is consistent with the procedurally generated training examples, showing that CAD-Recode successfully learns both the features and CAD design patterns established in the training set.",
                "fig_num": "7",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF8": {
                "text": "Figure 7. Examples from our procedurally generated training dataset. Each row contains CadQuery Python code and a corresponding CAD model. Examples contain not only basic line, circle, and arc primitives, but also higher-level abstractions such as rect, box, and cylinder.",
                "fig_num": "7",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF9": {
                "text": "Figure 8. Our 1 M procedurally generated training dataset displays distributions CAD models that are skewed towards models with larger edge and face count per model than the DeepCAD dataset (160 k models).",
                "fig_num": "8",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF10": {
                "text": "Figure 9. Example models from real-world CC3D dataset. The scans exhibits numerous artifacts such as surface noise, missing parts and smoothed edges. In the CC3D experiments reported in the main paper, the input point clouds are sampled from the scans. Zoom in for better details.",
                "fig_num": "9",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF11": {
                "text": "Figure 10. Qualitative results on the DeepCAD dataset.",
                "fig_num": "101112",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF12": {
                "text": "cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, -16)) r = w0.sketch().arc((-46, -23), (-95, -74), (-27, -56)).segment((30, -56)) .arc((96, -72), (44, -25)).segment((44, -12)).arc((31, 14), (30, 42)) .arc((1, 92), (-31, 44)).arc((-32, 43), (-33, 43)).arc((-31, 20),(-39, -2)) .segment((-39, -12)).segment((-43, -12)).arc((-45, -17),(-46, -23)).assemble() .push([(-64, -56)]).circle(28, mode='s').push([(0, 56)]).circle(28, mode='s') .push([(0, -19)]).circle(28, mode='s').push([(65, -56)])",
                "fig_num": "13",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF13": {
                "text": "Figure 13. CAD-Recode predictions on DeepCAD (top 2 rows), Fusion360 (mid 3 rows), and CC3D (last row) datasets. Each row contains predicted CadQuery Python code and its result after execution in Python interpreter.",
                "fig_num": "13",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF14": {
                "text": "Figure 14. Examples of invalid predictions. Each row contains the ground-truth CAD model (left) and an invalid predicted CadQuery Python code (right). The CAD models in (a) and (b) are taken from the DeepCAD dataset and the CC3D dataset for (c) and (d). Invalid predictions mostly take place when the ground-truth contains features of very small dimension with respect to the size of the CAD model as in (a) and (b), or when the ground-truth model contains operations other than the ones supported as in (c) and (d).",
                "fig_num": "14",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF15": {
                "text": "Figure 15. CAD-Recode predictions from different point cloud sampling on DeepCAD, Fusion360, and real-world CC3D datasets. For each prediction, 256 points are sampled randomly from the input point cloud.",
                "fig_num": "15",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF16": {
                "text": "Figure 16. Example of a CAD question from SGP-Bench in the DeepCAD representation (b) and using the CadQuery representation (c).When asking the question in CadQuery format no hint is provided, while in DeepCAD format a long interpretative hint is required. The choice of answers are A) 6, B) 4, C) 8 and D) 5. The correct answer is A) 6.",
                "fig_num": "16",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "FIGREF17": {
                "text": "Figure 17. Example of Point cloud CAD-QA (a) and answers provided by PointLLM (b), CADSIGNet and GPT-4o (c) and CAD-Recode and GPT-4o (d).",
                "fig_num": "17",
                "num": null,
                "uris": null,
                "type_str": "figure"
            },
            "TABREF1": {
                "html": null,
                "text": "Comparison of CAD reverse engineering methods on DeepCAD and Fusion360 datasets. Our CAD-Recode trained on the 160 k DeepCAD dataset demonstrates an improvement over existing state-of-the-art methods both in terms of geometric fidelity and validity of the generated sketch-extrude sequences. Our procedurally generated dataset provides a significant boost in the prediction quality.",
                "num": null,
                "type_str": "table",
                "content": "<table><tr><td>Method</td><td colspan=\"10\">Train Dataset Name Size Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR \u2193 Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 DeepCAD Test Set Fusion360 Test Set</td></tr><tr><td>DeepCAD [48]</td><td colspan=\"2\">DeepCAD 160k</td><td>42.5</td><td>9.64</td><td>46.7</td><td>7.1</td><td>330</td><td>89.2</td><td colspan=\"2\">39.9 25.2</td></tr><tr><td>PrismCAD [25]</td><td colspan=\"2\">DeepCAD 127k</td><td>-</td><td>4.28</td><td colspan=\"2\">72.1 16.2</td><td>-</td><td>4.75</td><td colspan=\"2\">65.3 18.0</td></tr><tr><td>Point2Cyl [45]</td><td colspan=\"2\">DeepCAD 35k</td><td>-</td><td>4.27</td><td>73.8</td><td>3.9</td><td>-</td><td>4.18</td><td>67.5</td><td>3.2</td></tr><tr><td>HNC-CAD [52]</td><td colspan=\"2\">DeepCAD 125k</td><td>-</td><td>8.64</td><td>65.3</td><td>5.6</td><td>-</td><td>36.8</td><td>63.5</td><td>7.3</td></tr><tr><td>MultiCAD [33]</td><td colspan=\"2\">DeepCAD 160k</td><td>-</td><td>8.09</td><td>-</td><td>11.5</td><td>-</td><td>42.2</td><td>-</td><td>16.5</td></tr><tr><td>TransCAD [12]</td><td colspan=\"2\">DeepCAD 140k</td><td>32.3</td><td>4.51</td><td>65.5</td><td>1.1</td><td>78.6</td><td>33.4</td><td>60.2</td><td>2.4</td></tr><tr><td colspan=\"3\">CAD-Diffuser [34] DeepCAD 160k</td><td>-</td><td>3.02</td><td>74.3</td><td>1.5</td><td>-</td><td>3.85</td><td>63.2</td><td>1.7</td></tr><tr><td colspan=\"3\">CAD-SIGNet [21] DeepCAD 160k</td><td>3.43</td><td>0.28</td><td>77.6</td><td>0.9</td><td>7.37</td><td>0.48</td><td>65.6</td><td>1.6</td></tr><tr><td>CAD-Recode</td><td colspan=\"2\">DeepCAD 160k</td><td>1.98</td><td>0.27</td><td>80.7</td><td>0.0</td><td>3.37</td><td>0.52</td><td>67.6</td><td>0.1</td></tr><tr><td>CAD-Recode</td><td>Ours</td><td>1M</td><td>0.30</td><td>0.16</td><td colspan=\"2\">92.0 0.4</td><td>0.35</td><td>0.15</td><td colspan=\"2\">87.8 0.5</td></tr></table>"
            },
            "TABREF3": {
                "html": null,
                "text": "is a benchmark of 1000 CAD-specific Question Answering (CAD-QA) tasks that test LLMs' understanding of CAD model geometry from sketch-extrude se-Ablation of training data and test-time sampling. The results demonstrate the advantage of training on our procedurally generated data, while the test-time sampling helps reducing the invalidity ratio. CD stands for mean Chamfer distance.",
                "num": null,
                "type_str": "table",
                "content": "<table><tr><td>Method</td><td/><td colspan=\"7\">Train Dataset Name Size Sampling CD\u2193 IoU\u2191 IR\u2193 CD\u2193 IoU\u2191 IR\u2193 CD\u2193 IoU\u2191 IR\u2193 Test-time DeepCAD Fusion360 Real-World CC3D</td></tr><tr><td colspan=\"4\">Previous best [21] DeepCAD 160 k</td><td>\u2713</td><td colspan=\"3\">3.43 77.6 0.9 7.37 65.6 1.6 14.80 42.6</td><td>4.4</td></tr><tr><td colspan=\"2\">CAD-Recode</td><td colspan=\"2\">DeepCAD 160 k</td><td>\u2713</td><td>1.98 80.7 0.0 3.37 67.6 0.1</td><td>3.79</td><td>56.4</td><td>0.0</td></tr><tr><td colspan=\"2\">CAD-Recode</td><td>Ours</td><td>160 k</td><td>\u2713</td><td>0.54 88.3 0.3 0.66 82.0 0.1</td><td>1.27</td><td>69.0</td><td>0.2</td></tr><tr><td colspan=\"2\">CAD-Recode</td><td>Ours</td><td>1 M</td><td>\u2713</td><td colspan=\"4\">0.30 92.0 0.4 0.35 87.8 0.5 0.76 74.2 0.3</td></tr><tr><td colspan=\"4\">Previous best [21] DeepCAD 160 k</td><td>\u2717</td><td colspan=\"4\">6.81 77.3 4.4 14.5 58.4 9.3 32.59 39.1 15.5</td></tr><tr><td colspan=\"2\">CAD-Recode</td><td>Ours</td><td>1 M</td><td>\u2717</td><td colspan=\"4\">0.75 89.3 4.9 0.89 84.2 8.7 3.05 65.6 16.8</td></tr><tr><td>Points</td><td>Model Size</td><td colspan=\"4\">DeepCAD CD\u2193 IoU\u2191 CD\u2193 IoU\u2191 CD\u2193 IoU\u2191 Fusion360 CC3D</td><td/><td/></tr><tr><td>128</td><td>0.5 B</td><td colspan=\"4\">0.18 89.9 0.18 84.3 0.38 71.9</td><td/><td/></tr><tr><td>256</td><td>0.5 B</td><td/><td/><td/><td/><td/><td/></tr></table>"
            },
            "TABREF5": {
                "html": null,
                "text": "Ablation of architecture details.",
                "num": null,
                "type_str": "table",
                "content": "<table><tr><td>1</td></tr></table>"
            }
        }
    }
}