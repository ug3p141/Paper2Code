[{"role": "system", "content": "You are an expert researcher, strategic analyzer and software engineer with a deep understanding of experimental design and reproducibility in scientific research.\nYou will receive a research paper in JSON format, an overview of the plan, a design in JSON format consisting of \"Implementation approach\", \"File list\", \"Data structures and interfaces\", and \"Program call flow\", followed by a task in JSON format that includes \"Required packages\", \"Required other language third-party packages\", \"Logic Analysis\", and \"Task list\", along with a configuration file named \"config.yaml\". \n\nYour task is to conduct a comprehensive logic analysis to accurately reproduce the experiments and methodologies described in the research paper. \nThis analysis must align precisely with the paper's methodology, experimental setup, and evaluation criteria.\n\n1. Align with the Paper: Your analysis must strictly follow the methods, datasets, model configurations, hyperparameters, and experimental setups described in the paper.\n2. Be Clear and Structured: Present your analysis in a logical, well-organized, and actionable format that is easy to follow and implement.\n3. Prioritize Efficiency: Optimize the analysis for clarity and practical implementation while ensuring fidelity to the original experiments.\n4. Follow design: YOU MUST FOLLOW \"Data structures and interfaces\". DONT CHANGE ANY DESIGN. Do not use public member functions that do not exist in your design.\n5. REFER TO CONFIGURATION: Always reference settings from the config.yaml file. Do not invent or assume any values\u2014only use configurations explicitly provided.\n"}, {"role": "user", "content": "## Paper\n{'paper_id': 'cadrecode', 'title': 'CAD-Recode: Reverse Engineering CAD Code from Point Clouds', 'abstract': 'Computer-Aided Design (CAD) models are typically constructed by sequentially drawing parametric sketches and applying CAD operations to obtain a 3D model. The problem of 3D CAD reverse engineering consists of reconstructing the sketch and CAD operation sequences from 3D representations such as point clouds. In this paper, we address this challenge through novel contributions across three levels: CAD sequence representation, network design, and training dataset. In particular, we represent CAD sketch-extrude sequences as Python code. The proposed CAD-Recode translates a point cloud into Python code that, when executed, reconstructs the CAD model. Taking advantage of the exposure of pre-trained Large Language Models (LLMs) to Python code, we leverage a relatively small LLM as a decoder for CAD-Recode and combine it with a lightweight point cloud projector. CAD-Recode is trained on a procedurally generated dataset of one million CAD sequences. CAD-Recode significantly outperforms existing methods across the DeepCAD, Fusion360 and realworld CC3D datasets. Furthermore, we show that our CAD Python code output is interpretable by off-the-shelf LLMs, enabling CAD editing and CAD-specific question answering from point clouds.', 'pdf_parse': {'paper_id': 'cadrecode', 'abstract': [{'text': 'Computer-Aided Design (CAD) models are typically constructed by sequentially drawing parametric sketches and applying CAD operations to obtain a 3D model. The problem of 3D CAD reverse engineering consists of reconstructing the sketch and CAD operation sequences from 3D representations such as point clouds. In this paper, we address this challenge through novel contributions across three levels: CAD sequence representation, network design, and training dataset. In particular, we represent CAD sketch-extrude sequences as Python code. The proposed CAD-Recode translates a point cloud into Python code that, when executed, reconstructs the CAD model. Taking advantage of the exposure of pre-trained Large Language Models (LLMs) to Python code, we leverage a relatively small LLM as a decoder for CAD-Recode and combine it with a lightweight point cloud projector. CAD-Recode is trained on a procedurally generated dataset of one million CAD sequences. CAD-Recode significantly outperforms existing methods across the DeepCAD, Fusion360 and realworld CC3D datasets. Furthermore, we show that our CAD Python code output is interpretable by off-the-shelf LLMs, enabling CAD editing and CAD-specific question answering from point clouds.', 'section': 'Abstract', 'sec_num': None}], 'body_text': [{'text': \"Computer-Aided Design (CAD) modeling is the standard approach for designing manufactured objects, ranging from furniture to mechanical components [3, 30] . However, creating a 3D CAD model is a time-consuming task that demands specialized expertise, as the model must not only capture the object's shape but also maintain its functional requirements-commonly referred to as the design intent [4, 27] . To streamline this process, 3D CAD reverse engineering aims at generating CAD models directly from 3D scanned objects, offering a faster and more accessible pathway to CAD creation [17] . Automated 3D CAD reverse engineering has a long history in the fields of computer vision and graphics [13, 43] , with goals evolving alongside advancements in the field. These objectives have progressed from identifying CAD parts in 3D point clouds [43] to predicting the sequence of steps a designer may take to recreate a 3D scanned object in CAD software [21, 34] . This latter goal is particularly appealing, as it aims not only to produce a final CAD parametric model but also to capture the design steps behind it, enabling further editing within CAD software [21, 45] . In CAD software, designers typically construct their CAD model as feature-based design sequences, where a sequence of 2D sketches is transformed into 3D objects via opera-tions such as extrusion and revolution [47, 50] . Following the release of large CAD datasets [7, 22, 47] , recent works have focused on learning feature-based CAD sequences from input point clouds, specifically as sketchextrude sequences [12, 21, 28, 33, 39, 45, 48] . As depicted in Figure 1 (a), although varying in methodology, these approaches share a common pipeline: (1) crafting a CAD sketch-extrude sequence representation, (2) converting raw CAD data [22, 47] into this format, and (3) training dedicated neural networks to output these representations from input point clouds.\", 'section': 'Introduction', 'sec_num': '1.'}, {'text': 'Despite recent advances in feature-based CAD reverse engineering, key limitations constrain the broader applicability of existing approaches. Firstly, existing methods often use customized CAD representations, such as custom CAD languages [12, 21, 34, 48] or simplified extrusion shapes [28, 39, 45] , to facilitate model training. These representations are difficult to interpret, require postprocessing to be compatible with CAD tools, and restrict design capabilities to basic operations. Secondly, these approaches typically rely on designing networks that output language-like CAD representations [12, 21] and training them from scratch. This requires the networks to learn not only the geometry of the point clouds, but also the syntax of the CAD sequence representation.', 'section': 'Introduction', 'sec_num': '1.'}, {'text': 'In this paper, we pose the following question: In view of the recent breakthrough performance of Large Language Models (LLMs), how can their advanced language understanding be leveraged for CAD reverse engineering?', 'section': 'Introduction', 'sec_num': '1.'}, {'text': 'To address this question, we base our approach on three key observations: (1) LLMs can generate valid Python code [36, 55] , (2) modern CAD software increasingly supports modeling through Python scripting [10] , and (3) recent efforts have shown that LLMs can be fine-tuned to process point clouds [49, 61] . As shown in Figure 1 (b), we propose CAD-Recode, a solution for CAD reverse engineering by fine-tuning an LLM to map input point clouds into CAD sketch-extrude sequences represented as Python code. In particular, instead of crafting a CAD representation, we base our representation on the existing Python CadQuery library [10] . This code-based representation is not only interpretable but also inherently allows for incorporating modular CAD features and design practices such as reusing design elements and abstracting low-level design steps (e.g. 3D box to represent a four-line sketch of a square and its extrusion). To learn the mapping between point clouds and CAD Python code, we fine-tune a pre-trained LLM, Qwen2-1.5B [55], augmented with a lightweight, trainable point cloud projector. To train CAD-Recode, a potential approach could be using existing sketch-extrude datasets [47, 48] and converting them to Python CadQuery code. However, these datasets are limited in size and design features included due to the efforts required to con-vert their original proprietary representation into one that is suitable for learning. As a solution, we propose a procedurally generated training dataset composed of one million CAD sketch-extrude sequences as Python CadQuery code. This dataset consists of CadQuery Python scripts generated following predefined heuristics with randomized parameter selection. The execution of each generated script results in a parametric CAD model. Unlike existing CAD datasets, this procedurally generated dataset provides an alternative for learning the mapping between point clouds and CAD sketch-extrude sequences in Python code, with full control over the design features, patterns and dataset size included during training. Our contributions can be summarized to: \u2022 A CAD sketch-extrude sequence representation in Python code using CadQuery [10] for CAD reverse engineering.', 'section': 'Introduction', 'sec_num': '1.'}, {'text': '\u2022 CAD-Recode, the first LLM-based CAD reverse engineering model designed to predict CAD Python code from point clouds. The model, consisting of a pre-trained LLM and a point cloud projector is trained end-to-end to generate code that reconstructs the input geometry. \u2022 A one million procedurally generated training dataset of CAD sketch-extrude sequences as CadQuery Python code. This provides precise control over dataset size, features, and design patterns included during training, re-', 'section': 'Introduction', 'sec_num': '1.'}, {'text': 'sulting in significant performance improvement. We will make this dataset publicly accessible. \u2022 Extensive experiments on three publicly available datasets show that CAD-Recode achieves substantial improvements over state-of-the-art methods in CAD reverse engineering. Moreover, we show that CAD-Recode, when operating on point clouds and generating CAD code, can be integrated with an off-the-shelf LLM to perform CAD Question Answering (CAD-QA) and CAD editing from point clouds. Paper Organization: The rest of the paper is organized as follows. Section 2 reviews related works. Section 3 introduces the CAD code representation and the proposed synthetic dataset. CAD-Recode is formulated and described in Section 4. Experiments are presented in Section 5. Finally, conclusions and future works are given in Section 6.', 'section': 'Introduction', 'sec_num': '1.'}, {'text': 'LLM, Point Cloud and CAD: Recent works have explored integrating point clouds with LLMs for various tasks, including 3D generation [56, 62] , captioning [16, 18, 49] , and question answering [6, 19] . These approaches typically employ complex point cloud encoders, either aligning with CLIP embeddings [31, 53, 54, 61, 64] or directly with LLM feature spaces [49] . Such methods require two-stage training: first pre-training the point cloud encoder, then finetuning with the LLM through instruction-based prompts.', 'section': 'Related Works', 'sec_num': '2.'}, {'text': \"In parallel, recent works have started exploring LLMs' capabilities in a range of CAD-related tasks. Reparam-CAD [23] infers shape variations from parametric models and text descriptions, while CADTalk [60] generates semantic descriptions of CAD parts. The works in [1, 2] focus on the generation of CAD models from text using LLMs, and SGP-Benchmark [38] evaluates LLMs' understanding of CAD sketch-extrude sequences using CADspecific question answering. While Img2CAD [57] attempts CAD reverse engineering from images using GPT-4V [36] , it still requires a separate transformer for parameter inference. In contrast, CAD-Recode introduces the first approach for point cloud to CAD reconstruction combining point clouds with the sequence modeling capabilities of pre-trained LLMs.\", 'section': 'Related Works', 'sec_num': '2.'}, {'text': 'CAD Reverse Engineering from Point Cloud: CAD reverse engineering aims to reconstruct parametric CAD models from 3D shapes (e.g., meshes or point clouds) in a compatible representation with CAD software. A key challenge lies in the choice of this representation. A line of works attempts to address sub-problems of the CAD reverse engineering task by focusing on parameter estimation for edges and surface primitives [8, 9, 15, 26, 32, 42, 46, 63] or reconstructing B-Rep construction history [11, 24, 47, 50] .', 'section': 'Related Works', 'sec_num': '2.'}, {'text': 'In order to obtain a representation that is closer to CAD modelling, several methods [14, 20, 29, 58, 59 ] use Constructive Solid Geometry (CSG), representing models as compositions of 3D primitives and Boolean operations. While this enables reconstruction, the CSG representation diverges from modern CAD workflows [50] .', 'section': 'Related Works', 'sec_num': '2.'}, {'text': 'Recent works have adopted the more CAD-aligned sketch-extrude representation, introduced by Deep-CAD [48] for CAD generation [51, 52] or predicting extrusion cylinder [39, 45] . Considering the sequential nature of sketch-extrude operations, methods have explored a template-based approach [25] given a rounded voxel input representation. Furthermore, transformer architectures have been investigated for both autoregressive [21] and non-autoregressive [12, 48] prediction of sketch-extrude sequences from point clouds. The work in [34] combines a lightweight pre-trained language model [40] with a point cloud encoder using a diffusion-based approach. Alternative methods using self-supervised [28] or unsupervised [29] learning still face integration challenges due to their non-standard sketch representations (e.g., signed distance functions). In contrast to these approaches that require full parameter learning of specialized networks for both CAD geometry and representation syntax, we leverage pre-trained LLMs that have been exposed to programming patterns through large-scale training on code repositories. Our method outputs Python code using the CadQuery library [10] that is directly executable and can easily be interpreted. Additionally, we address the data limitation through automated generation of a large-scale training dataset, enabling full control over design features included during training. Modern feature-based CAD modeling relies on sequences of 2D sketches and operations to create 3D models. Designers first draw geometric primitives (lines, arcs, circles) on a selected plane, then apply operations like extrusion or revolution to generate 3D geometry [50] . As depicted in Figure 2 (a), we focus on sketch-extrusion sequences, a fundamental CAD modeling pattern widely adopted in previous works [21, 48, 51] . Below, we present our CAD representation, highlighting its advantages over existing language-like encodings, and describe our procedurally generated training data.', 'section': 'Related Works', 'sec_num': '2.'}, {'text': 'Recent approaches in CAD language modeling [12, 21, 33, 48, 51] encode sketch-extrude sequences as numerical vectors representing features and their parameters as shown in Figure 2(b) . However, this representation constrains the modeling to specific CAD practices, lacks interpretability, and requires post-processing for CAD kernel compatibility. We propose using CadQuery [10] Python code to represent sketch-extrude sequences for CAD reverse engineering, offering the following advantages:', 'section': 'CadQuery Code', 'sec_num': '3.1.'}, {'text': 'Modularity of CAD Features and Design Practices: Existing language-based CAD reverse engineering methods rely on custom representations of low-level geometric features (lines, arcs, circles) for sketch construction [41, 48] . This approach inherently limits the range of implementable features and design practices. In contrast, CadQuery provides comprehensive built-in CAD functionality, encom-passing both low-level features and higher-level geometries like cylinders and boxes as shown in Figure 2(c ). Furthermore, its programmatic nature enables variable reuse and code modularity. This allows reusing common design features or practices across models, as illustrated by the shared center coordinates across two circles in Figure 2 (c) . This representation naturally accommodates diverse CAD features and design practices without requiring complex custom encodings or post-processing steps. The training of current CAD sketch-extrude reverse engineering methods [12, 21, 33, 34, 48] predominantly rely on datasets collected from CAD model repositories [7, 22, 47] . Considerable efforts are required to parse the CAD models from their original proprietary representations to a suitable one for deep learning [47, 48] . As a result, existing datasets are restricted not only in scale, but also in control over the design features and patterns included in training.', 'section': 'CadQuery Code', 'sec_num': '3.1.'}, {'text': 'To address these limitations, we propose to procedurally generate a training dataset of one million CAD models in the form of sketch-extrude sequences written in Python CadQuery [10] code. Our proposed pipeline randomly generates sketch and CAD operation parameters guided by topological and geometrical heuristics to ensure control over the amount of generated models and the features in the generated codes. The algorithm outlining the steps of this generation pipeline is provided in the supplementary materials along with further statistical analysis of the generated dataset. The modularity of CAD features is incorporated by utilizing both low-level primitives (i.e. circles, lines, and arcs) and their abstractions (i.e. boxes, cylinders, and rectangles) as well as reusing design elements within the generated sequences. In this work, we focus on some aspects of modularity (i.e., reusing point coordinates, extrusion planes, and abstracting basic shapes such as boxes and cylinders). Further modularity features (e.g., reusing functions corresponding to arbitrary CAD parts, additional CAD operations) can also be integrated in the future. Note that although our generated dataset does not include sequences from human-designed CAD models, it offers significant control over the features and design patterns to which the network is exposed during training. Examples of generated CAD models are shown in Figure 3 .', 'section': 'Procedurally Generated Training Dataset', 'sec_num': '3.2.'}, {'text': 'Building on the introduced CAD code representation and generated training dataset outlined in the previous section, this section introduces CAD-Recode, our proposed model for predicting CAD sketch-extrude sequences as code from input 3D point clouds. We formalize the problem of CAD code prediction, describe the architecture of CAD-Recode, and detail its training and inference processes.', 'section': 'CAD-Recode', 'sec_num': '4.'}, {'text': 'Let us denote the set of all possible code strings as \u03a3 * , where each code string is composed of elements from the finite set of alphanumeric characters and operators in the programming language \u03a3. Let \u03d5 syn : \u03a3 * \u2192 {True, False} represent the syntactic validation function for Python programming rules (e.g., variable declarations, expression syntax, and statement structure), and \u03d5 cad : \u03a3 * \u2192 {True, False} denote the validation function for CAD-specific rules. The latter includes the syntactic validity of the code w.r.t. to the CAD library, i.e. CadQuery [10] , and the geometric validity of the reconstructed model from the code (e.g., an extrusion can only be applied on a closed loop of 2D primitives, a circle radius cannot be negative). An executable valid CAD code can be formally described by a code string C \u2208 C, where', 'section': 'Problem Statement', 'sec_num': '4.1.'}, {'text': 'C = {w \u2208 \u03a3 * | \u03d5 syn (w) \u2227 \u03d5 cad (w)} ,', 'section': 'Problem Statement', 'sec_num': '4.1.'}, {'text': 'represents the set of all valid CAD codes. This formulation ensures that any code string w in C satisfies both the syntactic requirements of Python (\u03d5 syn ) and the CAD code validation rules (\u03d5 cad ). Let P = {p i } n i=1 \u2208 R n\u00d73 denote an input point cloud, where each point p i \u2208 R 3 represents 3D Cartesian coordinates. The objective of CAD-Recode is to learn a mapping', 'section': 'Problem Statement', 'sec_num': '4.1.'}, {'text': \"... Point Cloud CAD model <s> import cadquery ... extrude(15) Large Language Model import ... Python interpreter Tokenizer ... ... Linear Layer finalize().extrude(15)<e> \u03a8 : R n\u00d73 \u2192 C, C = \u03a8(P) , that maps the input point cloud to a valid CAD code C \u2208 C such that the code, when executed, produces a CAD model geometrically approximating the input point cloud P. Note that the CAD code execution results in a Boundary-Representation (B-Rep) [24]. Unlike meshes or point clouds, B-Rep is a parametric representation of the CAD model's geometry, enabling seamless integration into modern CAD software and allowing for further modifications. The goal of CAD-Recode is to infer the CAD code describing the design steps of the CAD model, that when executed results in a B-Rep.\", 'section': 'Problem Statement', 'sec_num': '4.1.'}, {'text': 'CAD-Recode builds on pre-trained LLMs and their prior exposure to Python code, augmenting these with point cloud processing capabilities and CAD-specific Python code knowledge. As shown in Figure 4 , its architecture consists of two components: (1) a point cloud projector mapping the 3D point cloud into learnable tokens, and (2) a pretrained LLM-based auto-regressive CAD code decoder.', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': 'Point Cloud Projection Module: CAD-Recode introduces a lightweight projection module \u03a8 p that directly maps a dense point cloud P \u2208 R n\u00d7dp , where d p = 3 corresponds to the dimension of point coordinates, into a sequence of n p \u226a n query tokens', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': 'Q p = [q 1 p , . . . , q np p ] \u2208 R np\u00d7dq , of embedding dimension d q .', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': 'The point cloud projector, trained in an end-to-end manner with the CAD code decoder module, consists of three simple components:', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': '(1) furthest point sampling to downsample the input point clouds to n p points, (2) Fourier positional encoding [62] of coordinates, and (3) a linear layer projecting the encoded coordinatesinto Q p .', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': \"LLM as CAD Code Decoder: Our CAD code decoder, denoted as \u03a8 LLM , adapts a pre-trained LLM for the specific task of CAD code generation. We leverage the Qwen2-1.5B model [55] as our LLM backbone, chosen for its balanced trade-off between model capacity and computational re-quirements. The decoder's input consists of point query tokens Q p from the point cloud projector, augmented with n t code tokens Q t \u2208 R nt\u00d7dq obtained by tokenizing the input code as in [55]. The complete input sequence is denoted as\", 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': '[Q p ; Q t ] \u2208 R (np+nt)\u00d7dq', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': ', where semicolon indicates concatenation along the sequence dimension. The LLM decoder generates the CAD code sequence through next-token prediction. As in [55], each predicted token is mapped to a symbol from the vocabulary \u03a3, which includes alphanumeric characters and operators.', 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': \"Overall, CAD-Recode repurposes the LLM's sequence modeling capabilities for the specialized task of translating geometric point clouds into executable CAD code.\", 'section': 'Proposed Model Architecture', 'sec_num': '4.2.'}, {'text': 'Training Strategy: Our training process consists of a single stage. The model operates on query tokens of dimension d q = 1536 and processes input point clouds downsampled to n p = 256 points. Gaussian noise with mean zero and standard deviation of 0.01 is added to the coordinates of the input points with a probability of 0.5 per model. The network is trained on the procedurally generated CAD codes, hence exposed to the CAD features and design practices that were included in the algorithm. The training objective minimizes the Negative Log-Likelihood (NLL) of the target CAD code sequence, using special tokens (<s> and <e>) to demarcate sequence boundaries. The point cloud projector \u03a8 p learns geometric features from scratch, while the pre-trained decoder \u03a8 LLM is fine-tuned for CAD code generation.', 'section': 'Training and Inference Details', 'sec_num': '4.3.'}, {'text': 'Inference Strategy: At inference time, the point cloud projector \u03a8 p processes the input point cloud P to generate query tokens Q p , which are then fed to the decoder along with the start token <s>. The model autoregressively generates CAD code tokens until producing a complete code sequence C ending with token <e>. Following [21] , we employ a test-time sampling approach where we generate ten distinct CAD code candidates, each from a different sampling of the input point cloud. For each candidate, we sam- ', 'section': 'Training and Inference Details', 'sec_num': '4.3.'}, {'text': 'In order to validate the effectiveness of CAD-Recode, we conduct a series of experiments across two different scenarios. The first scenario focuses on the reverse engineering task, where the goal is to reconstruct a CAD sketch-extrude sequence in Python code from a given input point cloud.', 'section': 'Experiments', 'sec_num': '5.'}, {'text': 'The second assesses the interpretability and editibility of the generated CAD code with a proprietary LLM [36] .', 'section': 'Experiments', 'sec_num': '5.'}, {'text': 'Experimental Setup: CAD-Recode is evaluated on three test datasets: DeepCAD [48] (8046 models), Fu-sion360 [47] (1725 models), and the real-world CC3D [35] (2973 models). The point clouds are obtained by sampling points on the meshes for DeepCAD and Fusion360. The CC3D dataset provides a real-world scenario with input point clouds sampled from actual 3D scans of CAD models containing surface noise, smoothed edges and missing parts (see supplementary materials for more details). Implementation details are provided in the supplementary.', 'section': 'Reverse Engineering', 'sec_num': '5.1.'}, {'text': 'To evaluate the quality of the predicted CAD sketch-extrude sequences, we use three metrics: Chamfer Distance (CD) [21] , Intersection over Union (IoU) [34] , and Invalidity Ratio (IR) [48] . We report both mean and median CD values computed using 8192 points to assess geometric accuracy. Reported CD values have been multiplied by 10 3 . The IoU is computed from the resulting CAD model meshes and expressed as a percentage. The IR indicates the percentage of generated sequences that fail to produce a valid CAD model.', 'section': 'Metrics:', 'sec_num': None}, {'text': 'Results & Analysis: Table 1 presents results on the test sets of DeepCAD and Fusion360 datasets, where CAD-Recode establishes new state-of-the-art performance across all metrics. Note that the results of stateof-the-art methods in Table 1 are borrowed from [34] , except for CAD-SIGNet [21] , MultiCAD [33] , Tran-sCAD [12] , and DeepCAD [48] which were taken from [21] and [12] . First, we convert the DeepCAD dataset (160 k models) to CadQuery Python code and use it to train CAD-Recode (results are in row before last of Table 1 ). When trained on DeepCAD dataset as existing methods, CAD-Recode outperforms them in almost all metrics. These results showcase the effectiveness of CAD-Recode and the proposed CAD code representation.', 'section': 'Metrics:', 'sec_num': None}, {'text': 'Training on 1 M generated samples results in substantial improvements in CD and IoU metrics while maintaining a negligibly low invalidity ratio (last row of Table 1 ), reflecting significantly better geometric fidelity in the predicted CAD models. CAD-Recode demonstrates a ten-fold improvement in mean CD and an increase of IoU by over 10% on both DeepCAD and Fusion360 datasets compared to the existing best methods. These results confirm that our largescale procedurally generated training dataset provides substantial benefits.', 'section': 'Metrics:', 'sec_num': None}, {'text': 'As illustrated in Figure 5 , this translates to consistent reconstruction quality, where CAD-Recode reliably produces CAD models that accurately capture the geometry from the input point cloud. In contrast, CAD-SIGNet [21] can generate shapes that deviate significantly from the target geometry, further highlighting the advantages of our approach.', 'section': 'Metrics:', 'sec_num': None}, {'text': 'In Table 2 , we evaluate DeepCAD Dataset Fusion360 Dataset Real-world CC3D Dataset Point Cloud CAD-SIGNet CAD-Recode GT Figure 5. Qualitative results on the DeepCAD, Fusion360, and CC3D datasets. For each input point cloud (first row), we compare CAD models produced by CAD-SIGNet (second) and our CAD-Recode trained on our dataset (third) with a ground truth CAD model (bottom row). While CAD-SIGNet often fails to restore the general shape, CAD-Recode outputs only slightly deviate from ground truth in most cases. Method Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 DeepCAD [48] -263 -12.7 CAD-SIGNet [21] 14.82 2.90 42.6 2.5 CAD-Recode 0.76 0.31 74.2 0.3 Table 2. Results on the CC3D dataset, where input point clouds are sampled from real 3D scans. CAD-Recode significantly outperforms DeepCAD, and CAD-SIGNet.', 'section': 'Real-world Scenario:', 'sec_num': None}, {'text': 'CAD-Recode on the real-world CC3D dataset, where input point clouds are sampled from 3D scans and contain artifacts such as surface noise, smooth edges, and missing parts. Even under these challenging conditions, our method achieves significant improvements over CAD-SIGNet [21] , with a 89% lower median CD and a 30% higher IoU, while maintaining a low IR. From the CC3D qualitative results in Figure 5 , CAD-Recode is able to recover geometries that are much closer to the ground truth than current state-of-the-art. However, it can be observed that CAD-Recode still lacks the expressiveness to model complex shapes that contain operations beyond the extrusion operation such as revolution and fillet. This can be attributed to the choice of features and design practices in the procedurally generated training dataset. Nevertheless, we believe that this can be addressed in future works by incorporating further features in the dataset generation procedure. Our results on CC3D are compared with methods previously reported for this dataset [21] , namely CAD-SIGNet and DeepCAD.', 'section': 'Real-world Scenario:', 'sec_num': None}, {'text': 'Ablation Study: To evaluate the different components of CAD-Recode, we conduct a comprehensive ablation study on the amount of training data, test-time sampling, and the number of input points and model parameters.', 'section': 'Real-world Scenario:', 'sec_num': None}, {'text': 'Training CAD-Recode on 160 k procedurally generated samples using the method described in Section 3.2 leads to significant improvements in geometric fidelity of the predicted samples over training on the DeepCAD dataset with the same amount of data (see row 2 and 3 of Table 3 ). Furthermore, scaling our training dataset to 1 M samples provides further improvements across all datasets (row 4 of Table 3 ). As compared to DeepCAD training dataset, our procedural dataset generation provides a better way of learning the mapping between point clouds and CAD codes which can be further improved by scaling up the dataset size.', 'section': 'Real-world Scenario:', 'sec_num': None}, {'text': 'We investigate the effectiveness of the test-time sampling approach that generates multiple CAD code predictions through different point cloud samplings, as described in Section 4.3. As shown in the third and last row of Table 3 , the test-time sampling approach mainly helps reducing the ratio of invalid predicted CAD codes (IR). For comparison, CAD-SIGNet [21] employs a probability-based sampling. Yet, even without test-time sampling our method still performs better on the reconstruction metrics than CAD-SIGNet [21] .', 'section': 'Real-world Scenario:', 'sec_num': None}, {'text': 'Results in Table 4 show an ablation of the input point cloud size and the number of parameters of the LLM backbone. It can be observed that using an input point cloud of 256 points and Qwen1.5b results in the highest IoU. This setting with a relatively small input point cloud and lightweight LLM backbone provides the best balance between prediction accuracy and memory requirements. Results on all metrics are included in the supplementary materials.', 'section': 'Real-world Scenario:', 'sec_num': None}, {'text': \"CAD-QA and LLM Interpretability: CAD SGP-Bench [38] quences encoded as in DeepCAD [48] . These questions require analyzing various geometric aspects, such as relative sizes and 3D primitive types. We extend this benchmark to evaluate CAD reverse engineering methods by using point clouds as input instead of CAD sequences. Our evaluation follows a two-stage process: first predicting sketch-extrude sequences from point clouds as CadQuery code with CAD-Recode, then using GPT-4o [36] to answer CAD-specific questions. Without requiring additional interpretation hints, our approach achieves 76.5% accuracy on this CAD-QA task (Table 5 ). For comparison, we evaluate two baseline approaches: CAD-SIGNet [21] and PointLLM [49] . When using CAD-SIGNet's output with GPT-4o, even with provided interpretation hints explaining the sequence format, the accuracy reaches only 63.2%.\", 'section': 'CAD-QA and Editability', 'sec_num': '5.2.'}, {'text': 'PointLLM, which directly processes point clouds for language tasks, achieves 42.3% accuracy when prompted with the CAD-specific questions. These results demonstrate that CAD-Recode effectively captures CAD geometric information while generating an output in a format that proprietary LLMs can naturally interpret and process.', 'section': 'CAD-QA and Editability', 'sec_num': '5.2.'}, {'text': 'Editing Pipeline: Leveraging the interpretable nature of our code-based output, we present an automated editing pipeline using GPT-4o [36] . Through a simple prompt, the system refactors the generated code to expose geometric parameters via interactive sliders, enabling direct manipulation of the reconstructed model. As shown in Figure 6 , the resulting code can be directly executed in a Python environment to provide an interactive editing interface. Implementation details are provided in the supplementary materials. ', 'section': 'CAD-QA and Editability', 'sec_num': '5.2.'}, {'text': 'This work rethinks the problem of feature-based CAD reverse engineering by approaching it through pre-trained LLMs taking advantage of CAD Python-based representation. Our key contributions include a new CAD code representation for reverse engineering sketch-extrude sequences, very large-scale procedurally generated training dataset in the form of CAD programs, and a point cloud-to-CAD code model. We demonstrate that CAD-Recode outperforms existing methods by a large margin on three datasets, including the real-world CC3D dataset. We also showcase that combining pre-trained LLMs with geometric understanding enables powerful new workflows, where designers can reconstruct CAD models from point clouds and modify them through natural language. We believe that this work will open new perspectives for CAD reverse engineering.', 'section': 'Conclusion', 'sec_num': '6.'}, {'text': 'We identify the following interesting future works: (1) further exploiting the modularity of the proposed CAD code representation, (2) scaling up the LLM and the dataset to enable reverse engineering of more complex CAD models.', 'section': 'Conclusion', 'sec_num': '6.'}, {'text': 'Acknowledgement: The present project is supported by the National Research Fund, Luxembourg under the BRIDGES2021/IS/16849599/FREE-3D and IF/17052459/CASCADES projects, and by Artec 3D.', 'section': 'Conclusion', 'sec_num': '6.'}, {'text': 'The CAD-Recode implementation uses Qwen2-1.5B as the LLM decoder. The training configuration employs the AdamW optimizer with a learning rate of 0.0002 and weight decay of 0.01, while maintaining other parameters at their default values from the HuggingFace implementation [44] , including the cosine learning rate scheduler. The training process is conducted for 100 k iterations, incorporating an initial warmup period of 1 k iterations. Using a single NVIDIA H100 GPU with a batch size of 18, the complete training process takes approximately 12 hours. For ablation study examining decoder size impact (Section 5.1 of the main paper), we utilize Qwen2-0.5B.', 'section': 'Appendix A. Training Details', 'sec_num': None}, {'text': 'In Section 3.2, the procedurally generated training dataset is presented. The main advantage of generating data over using the existing DeepCAD dataset for training is that the algorithm allows full control over the amount of data as well as the features and design patterns that the network is exposed to during training. We generate one million valid Python CadQuery code snippets, through an automated pipeline leveraging PythonOCC [37] and CadQuery [10] .', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': 'The generation process consists of two primary components: (1) a sketch profile generator (Algorithm 1) that creates valid 2D sketches, and (2) a CAD model generator (Algorithm 2) that produces 3D CAD models from these sketches.', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': 'The sketch generation process combines primitive shapes (circles and rectangles) through boolean operations (union and cut). From each generated sketch, we extract the primitives (lines, arcs, and circles) from both inner and outer loops. The validity of the generated sketch is ensured through multiple verification steps, including verifying that loops do not intersect, and each primitive has a length greater than zero. Finally, we ensure that the randomly generated CAD code has not previously been generated using the duplicate detection protocol outlined in [51] . This ensures that each sample in the dataset is unique.', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': 'The CAD model generation procedure extrudes the validated sketches and combines them through union operations. The planes on which the sketches lie are randomly generated by choosing one of the three canonical planes translated by a random amount. Each resulting model undergoes normalization to fit within a unit bounding box centered at the origin. The parameters are quantized so that the coordinates of any point on the CAD surface are within the range -100 to 100 with a minimum resolution of 1 unit. We then simplify the sequence using higher level abstractions (rectangle, box, and cylinder) by considering the sequence parameters. Our validation framework verifies that a generated code w executes without errors (\u03d5 syn ). Furthermore, we check that the executed code produces a geometric valid CAD model (\u03d5 cad ) using the BRepCheck Analyzer function from PythonOCC as in [48] . Invalid models are excluded from the dataset.', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': 'Figure 7 presents examples of CAD models alongside their corresponding CadQuery Python code from our procedurally generated dataset. It is worth noting that the generated codes are fairly compact, this was designed to facilitate training. All code examples are directly executable using a standard Python interpreter with the CadQuery library. The codes follow a consistent three-part structure:', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': '(1) necessary library import, (2) definition of sketch planes, and (3) sketch-extrude operations combined through union.', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': 'The training dataset generation procedure provides full control over the features included. In Figure 8 , it can be observed that the distribution of our CAD models is skewed towards models with larger face and edge count per model with interquartile ranges. As a result, our procedurally generated dataset provides a larger variety of models.', 'section': 'B. Training Dataset Generation Algorithm', 'sec_num': None}, {'text': 'Results on the real-world CC3D [7, 35] dataset are presented in Table 3 of the main paper. This scenario provides an experimental evaluation in a realistic setting, as the input point clouds are sampled from actual 3D scans of CAD models. Sample models are depicted in Figure 9 , where artifacts such as surface noise, smoothed edges, and missing parts can be observed. Furthermore, several models from the CC3D dataset are constructed using a range of operations beyond simple extrusion, including revolution, chamfer, and fillet. Consequently, the real-world CC3D dataset provides a challenging set of inputs that enables robust inthe-wild evaluation of our proposed method.', 'section': 'C. Real-World CC3D Dataset', 'sec_num': None}, {'text': 'Qualitative Results: Additional qualitative results for the reverse engineering of CAD models from point clouds are presented for DeepCAD (Figure 10 ), Fusion360 (Figure 11 ), and real-world CC3D (Figure 12 ) datasets. As de-', 'section': 'D. Further Experimental Results', 'sec_num': None}, {'text': 'Algorithm 1 Generate2DSketch 1: function GENERATE2DSKETCH 2: numP rimitives \u2190 RandInt(3, 8) \u25b7 Choose random number of shape primitives 3: compositeShape \u2190 \u2205 \u25b7 Initialize empty shape 4: for i \u2190 1 to numP rimitives do \u25b7 Build shape by combining primitives 5: primitive \u2190 random from {Circle, RotatedRectangle} 6: booleanOperation \u2190 random from {Union, Cut} \u25b7 Union adds, Cut subtracts 7: compositeShape \u2190 ApplyOperation(compositeShape, primitive, booleanOperation) 8: end for 9: boundaryLoops \u2190 ExtractBoundaryLoops(compositeShape) \u25b7 Extract shape boundaries 10: boundaryComponents \u2190 \u2205 11: for loop \u2208 boundaryLoops do \u25b7 Process each boundary loop 12: (edgeSequence, isOuter) \u2190 AnalyzeBoundary(loop) \u25b7 List of parametric curves (lines, arcs, circles) 13: boundaryComponents.Append((edgeSequence, isOuter)) 14: end for 15: boundaryComponents \u2190 V alidateShapeT opology(boundaryComponents) \u25b7 Ensure valid shape topology 16: return boundaryComponents \u25b7 Returns list of (edges, boolean) tuples 17: end function Algorithm 2 GenerateCAD 1: function GENERATECAD 2: cadM odel \u2190 \u2205 \u25b7 Initialize empty CAD model 3: planes \u2190 GenerateRandomP lanes() \u25b7 Create set of reference planes 4: sketches \u2190 Generate2DSketch() \u25b7 Get sketches from Algorithm 1 5: for sketch \u2208 sketches do \u25b7 Create 3D volumes from sketches 6: plane \u2190 RandomSelect(planes) \u25b7 Select random reference plane 7: volume \u2190 ExtrudeSketch(sketch, plane) \u25b7 Create 3D volume by extrusion 8: cadM odel \u2190 BooleanU nion(cadM odel, volume) \u25b7 Add volume to model 9: end for 10: cadM odel \u2190 N ormalizeM odel(cadM odel) \u25b7 Ensure the model fits within a unit box 11: cadM odel \u2190 QuantizeP arameters(cadM odel) \u25b7 Discretize model parameters 12: cadM odel \u2190 Simplif yCADM odel(cadM odel) \u25b7 Identify high-level abstractions (rectangle, box, and cylinder) 13: cadM odel \u2190 V alidateCADM odel(cadM odel) \u25b7 Ensure validity of CadQuery code and CAD model geometry 14: cadM odel \u2190 CheckDuplicate(cadM odel) \u25b7 Ensure that the sequence has not previously been generated. 15:', 'section': 'D. Further Experimental Results', 'sec_num': None}, {'text': 'return cadM odel 16: end function tailed in Section 5.1 of the main paper, CAD-Recode consistently generates shapes that closely approximate the input point cloud geometry, whereas CAD-SIGNet [21] can generate predictions that greatly differ from the input. Ablation Results: Table 6 shows the architecture ablation results on all metrics, complementing Table 4 of the main paper. Results show that for the same size of input point clouds Qwen1.5b always produces better geometric performance (median CD and IoU) than Qwen0.5b. This can be attributed to the higher number of parameters as well as to the better ability of the model to produce valid python code before fine-tuning. Furthermore, increasing the size of the input point cloud demonstrates a similar pattern, with Qwen1.5b with an 256 input points appears to be the set of architecture parameters leading to the best performance.', 'section': 'D. Further Experimental Results', 'sec_num': None}, {'text': 'Note that the mean CD is a metric that is very sensitive to outlier predictions. While Qwen1.5b with 256 input points appears to result in the highest IR, it is negligibly low on all datasets (less 0.5%). This can also be explained by the fact that this setting produces more complex CAD sketchextrude sequences, making them more susceptible to errors. Note that a key idea of our method is to leverage pre-trained LLMs as decoder of Python code. In the absence of LLMbased CAD reverse engineering methods, we compare our approach to SOTA methods despite the difference in model sizes. For reference, CAD-SIGNet contains 6 M parameters.', 'section': 'Code Outputs:', 'sec_num': None}, {'text': \"Command & Parameter Accuracy: In order to evaluate the ability of CAD-Recode to predict numerical values and sequences that are consistent with the training set, we evaluate CAD-Recode trained on the DeepCAD dataset converted to CADQuery python codes with the Acc command and Acc parameter as introduced in [48] . The results on the DeepCAD testing set are presented in Table 7 . It can be observed that CAD-Recode achieves comparable performance to the state-of-the-art on the commnad type accuracy import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, -13, 0)) r = w0.workplane(offset=-87 / 2).moveTo(52.5, 10.5).box (57, 83, 87) .union(w0.workplane(offset=23 / 2).moveTo(-29, 0).cylinder (23, 30) )\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': '.union(w0.workplane(offset=113 / 2).moveTo(-29, 0).cylinder(113, 52))', 'section': 'Code Outputs:', 'sec_num': None}, {'text': \"import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, -30, 0)) r = w0.sketch().segment((-30, -27),(-18, -31)).segment((-19, -31)).segment((-19, -100))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': '.segment((38, -100)).segment((38, -31)).segment((10, -31)).segment((13, -23))', 'section': 'Code Outputs:', 'sec_num': None}, {'text': \".arc((30, -13), (23, 5) ).segment ((33, 33) ).segment ((16, 39) ).arc((-12, 99),(-9, 33)) .close().assemble().finalize().extrude (60) import cadquery as cq w0 = cq.Workplane('YZ', origin=(-14, 0, 0)) r = w0.workplane(offset=17 / 2).moveTo(4, -73.5).box(104, 53, 17) .union(w0.sketch().segment((-78, 23), (2, -55)).segment((40, -17))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': '.arc((42, -24),(48, -30)).segment((48, 5)).segment((61, 5))', 'section': 'Code Outputs:', 'sec_num': None}, {'text': \".segment ((78, 22) ).segment((-2, 100)).close().assemble() .push([(0, 22)]).circle(50, mode='s').finalize().extrude( 29))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': \"import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, 42)) w1 = cq.Workplane('YZ', origin=(-17, 0, 0)) r = w0.sketch().arc((-12, 6), (34, -29),(-1, 16)).segment((5, 4)).segment((-8, -2)) .close().assemble().finalize().extrude(56) .union(w0.sketch().arc((-42, 54), (-12, 71), (19, 54)).segment((19, 78))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': '.segment((-42, 78)).close().assemble().finalize().extrude(58)) .union(w1.sketch().segment((-44, -100), (51, -100)).segment((51, 5)).segment((27, 5))', 'section': 'Code Outputs:', 'sec_num': None}, {'text': \".arc((-58, 40),(-44, -51)).close().assemble().reset() .face(w1.sketch().arc((-54, -17), (-26, -34),(3, -17)).close() .assemble(), mode='s').reset().face(w1.sketch().segment((-54, 14), (3, 14))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': \".arc((-26, 31), (-54, 14)).assemble(), mode='s').finalize().extrude(-13))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': \"import cadquery as cq w0 = cq.Workplane('YZ', origin=(-22, 0, 0)) w1 = cq.Workplane('ZX', origin=(0, -19, 0)) r = w0.sketch().segment((-100, -83),(-67, -83)).segment((-80, -52)).segment((-75, -50))\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': '.segment((-75, 62)).segment((17, 62)).segment((17, -62)).segment((-40, -62))', 'section': 'Code Outputs:', 'sec_num': None}, {'text': '.segment((-37, -71)).segment((-65, -83)).segment((43, -83))', 'section': 'Code Outputs:', 'sec_num': None}, {'text': \".segment((43,83)).segment((-100,83)).close().assemble().finalize().extrude(8) .union(w1.sketch().segment((-77, -53),(76, -53)).arc((76, -48),(77, -42)) .segment((77, 53)).segment((-77, 53)).close().assemble() .push([(38.5, 2.5)]).rect(9, 57, mode='s').finalize().extrude(119)) 5 10 15 20 25 30 35 40 Number of faces per model DeepCAD Our Dataset (a) Box-plot graph of the distribution of the number of faces per model. 0 20 40 60 80 100 Number of edges per model DeepCAD Our Dataset (b) Box-plot graph of the distribution of the number of edges per model. and significantly higher performance on the parameter accuracy. This demonstrates that CAD-Recode is able to predict numerical values accurately. Note that, those metrics were originally developed to evaluate autoencoding ability. However, there may exist many different possible valid CAD sequences to construct the same CAD model and these metrics do not take this into account. As a result, these metrics were omitted in recent works (CAD-SIGNet [21] and TransCAD [12] ).\", 'section': 'Code Outputs:', 'sec_num': None}, {'text': 'The invalidity rate of CAD-Recode predictions is very low, below 1% on the DeepCAD [48] , Fusion360 [47] and real-world CC3D [35] dataset. Some examples of invalid code predictions are presented in Figure 14 . Invalid predictions happen when the CAD model contains features of dimension smaller than the resolution induced by quantization (Figure 14 Points Model DeepCAD Fusion360 CC3D Size Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 64 0.5 B 0.42 0.20 88.5 0.1 0.58 0.22 82.1 0.1 0.87 0.45 70.1 0. DeepCAD [48] 80.4 69.6 PrismCAD [25] 73.0 66.8 HNC-CAD [52] 82.7 74.6 CAD-Diffuser [34] 88.5 82.9 CAD-Recode 83.9 92.1', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': 'Table 7 . Command and parameter accuracy results [48] Point Cloud CAD-SIGNet CAD-Recode GT Figure 11. Qualitative results on the Fusion360 dataset. Point Cloud CAD-SIGNet CAD-Recode GT .segment((48, 100)).segment((-48, 100)).close().assemble().finalize().extrude(20) .union(w0.sketch().segment((-82, -100),(-27, -100)).segment((-27, 80)).segment ((27, 80) )', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.segment((27, -100)).segment((82, -100)).segment((82, -79)).segment((48, -79))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.segment((48, 100)).segment((-48, 100)).segment((-48, -79)).segment((-82, -79))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \".close().assemble().finalize().extrude (34) ) .circle(28, mode='s').finalize().extrude (32) import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, 40, 0)) w1 = cq.Workplane('XY', origin=(0, 0, -19)) r = w0.sketch().arc((-24, -47), (41, -99),(87, -32)).segment((88, -32)).segment((88, 100))\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': 'import', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.segment((82, 100)).segment((82, -52)).arc((34, -94), (-18, -52)).segment((-18, 100))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \".segment((-24, 100)).close().assemble().finalize().extrude(-80) .union(w1.workplane(offset=-69 / 2).moveTo (52, 0) .cylinder(69, 32)) import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, 31, 0)) r = w0.workplane(offset=-75 / 2).cylinder (75, 62) .union(w0.workplane(offset=-25 / 2).cylinder (25, 81) )\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.union(w0.workplane(offset=13 / 2).cylinder(13, 100))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \"import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, 69, 0)) w1 = cq.Workplane('ZX', origin=(0, -85, 0)) r = w0.workplane(offset=-150 / 2).cylinder (150, 15) .union(w0.workplane(offset=10 / 2).cylinder (10, 31) )\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.union(w0.workplane(offset=31 / 2).cylinder (31, 8) )', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \".union(w1.workplane(offset=-15/2).cylinder (15, 46) ) import cadquery as cq w0 = cq.Workplane('ZX', origin=(0, 20, 0)) r = w0.sketch().circle(61).circle(25, mode='s').push([(34, 4)]) .circle(4, mode='s').finalize().extrude(-41) .union(w0.sketch().segment((-100, 19), (-88, 11) ).segment((-97, -34)).segment((-67, -41))\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.segment((-77, -66)).segment((-57, -74)).segment((-57, -72)).segment((-56, -72))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \". import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, 0)) w1 = cq.Workplane('YZ', origin=(0, 0, 0)) r = w0.workplane(offset=0 / 2).cylinder(0, 98) .union(w1.workplane(offset=0 / 2).cylinder(0, 100)) (a) The ground truth model contains three very thin cylinders with height smaller than 1. As a result, CAD-Recode is not able to predict heights with sufficient precision due to quantization and predicts cylinders with height 0, producing an invalid model. import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, 0)) r = w0.sketch().rect(200, 124).push([(-63.5, 25)]).rect(51, 60, mode='s') .push([(55, -25)]).rect(50, 60, mode='s').finalize().extrude(0) (b) As the ground-truth model has thickness less than 1, CAD-Recode predicts an extrusion distance of 0 as a quantized approximation (highlighted in yellow), resulting in an invalid CAD model. import cadquery as cq w0 = cq.Workplane('YZ', origin=(34, 0, 0)) w1 = cq.Workplane('XY', origin=(0, 0, 44)) r = w0.sketch().segment((-7, -35), (11, -36)).segment((11, -24)).arc((1, (6, -2)).segment((-1, 19)).segment((11, 23)).segment((11, 28))\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.segment ((11, 29) ).segment ((12, 29) ).segment ((12, 35) ) .segment((-4, 36)).close().assemble().finalize().extrude(-133) .union(w0.sketch().segment((5, -7), (14, -2)).segment ((8, 8) ).arc((7, 0),', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '(5, -7)).assemble().finalize().extrude( 63)) .union(w1.sketch().arc((-100, 12), (-85, 10), (-70, 5)).arc((-68, 6), (-66, 5)).arc((-59, 4), (-52, 2)).arc((-51, 3), (-50, 4)).arc((-72, 7), (-90, 12)).close().assemble().finalize().extrude(-88))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '(c) The ground-truth CAD model is created with B-spline primitives. Since CAD-Recode supports only arc, circle and line primitives, it tries to approximate the solution with multiple arcs, but fails to provide a valid CAD model. In particular, the prediction contains an arc constructed from three co-linear points (highlighted in yellow), which raises an error in CadQuery.', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \"import cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, -79)) r = w0.sketch().segment((-100, -1), (-91, -1)).arc((0, -93),(91, -1))\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': \".segment((100, -1)).segment((100, 1)).segment((91, 1)).arc((0, 99), (-91, 1)).segment((-100, 1)).close().assemble().push([(0, -2)]) .circle(90, mode='s').finalize().extrude(-2) .union(w0.workplane(offset=140 / 2).cylinder(140, 72)) .union(w0.sketch().segment((-51, 15), (-50, 15) ).arc((0, -53), (50, 15) )\", 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '.segment ((51, 15) ).segment ((51, 27) ).segment ((48, 27) ).arc((0, -53), (-48, 27) ).segment((-51, 27)).close().assemble().finalize().extrude( 159))', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': '(d) The ground-truth CAD model is created with a revolution operation. Since CAD-Recode supports only extrusion operation, it tries to approximate the solution with multiple arcs. However, one of the sketch (highlighted in yellow) results in a self-intersecting loop, which is not a valid face. ', 'section': 'Invalid Predictions:', 'sec_num': None}, {'text': 'The ablation study in Section 5.1 of the main paper demonstrates the effectiveness of our test-time sampling strategy. This approach generates multiple plausible solutions by sampling different input point clouds. Figure 15 illustrates the qualitative results from different sampling instances. While CAD-Recode successfully captures the overall geometry across different samplings, fine-grained details may vary in reconstruction quality due to the relatively sparse point cloud input. However, this can be effectively addressed by leveraging multiple sampling iterations to capture different aspects of the input geometry.', 'section': 'E. Test-time Sampling', 'sec_num': None}, {'text': 'In this section, we provide further details on the CAD-QA experiments reported in Section 5.2 of the main paper. We start by providing more details on the SGP-Bench benchmark [38] . Then, we present results further results and examples of GPT-4o outputs.', 'section': 'F. Interpretability and CAD-QA', 'sec_num': None}, {'text': 'The goal of the SGP-Bench benchmark is to evaluate the spatial-semantic reasoning skills of LLMs from symbolic graphics programs [38] . One aspect of the benchmark is a set of 1000 multiple choice questions on 3D CAD models given their corresponding sketch-extrude sequence in the DeepCAD [48] format. An example is depicted in Figure 16 .', 'section': 'F.1. Representation and CAD-QA', 'sec_num': None}, {'text': 'To evaluate the interpretability of our code-based CAD representation, we translated the 1000 questions of SGP-Bench from the DeepCAD representation (Figure 16(a) ) to the CadQuery code format (Figure 16(b) ). Using the same protocol as in SGP-Bench [38] , and GPT-4o [36] , we found that the accuracy on the multiple choice question in Cad-Query format is 82.4%. This is about 4% higher than using the DeepCAD format with an interpretative hint. This suggests the proposed code representation provides a more structured and naturally LLM-interpretable representation of CAD models.', 'section': 'F.1. Representation and CAD-QA', 'sec_num': None}, {'text': 'In Table 6 of the main paper, the results for point cloud CAD-QA are presented. Figure 17 (a) depicts an example of point cloud and question that was used to obtain these results. In this particular question, the task is to deduce the number of holes present in the CAD model given the point cloud as input. Figure 17(b ), the answer provided by PointLLM is shown and it can be observed that PointLLM is unable to retrieve the correct answer. It is worth noting that PointLLM is a network trained to answer semantic questions about object given its point cloud representation, as result in most cases the network is unable to describe geometric CAD-specific questions. For both CAD-SIGNet and CAD-Recode, the point cloud CAD-QA is done in a two step process. First the sketch-extrude is sequence is predicted from each network, then the sequence along with the question is passed through GPT-4o. Note that for CAD-SIGNet an interpretative hint is provided to provide context on the structure of the sequence. A sample output for CAD-SIGNet and GPT-4o can be found in Figure 17 (c), and in Figure 17 (d) for CAD-Recode and GPT4-o. As the sequence was incorrectly predicted by CAD-SIGNet the answer to the question is wrong (1 hole), whereas the prediction from CAD-Recode captured better the geometry of the input point cloud leading to a correct answer. It is worth noting, that despite not being provided any information about CadQuery Python code in the prompt, GPT-4o is able to breakdown the predicted sequence into its primitive components and provide correct and accurate geometric descriptions. This can be explained by the fact that LLMs are exposed to large amounts of code data during training. As a result, the CadQuery Python representation of CAD models is appropriate for', 'section': 'F.2. Point Cloud and CAD-QA', 'sec_num': None}, {'text': \"We provide more details on the editing pipeline presented in Section 5.2 of the main paper. The goal of this pipeline is to integrate automated editability capabilities to CAD-Recode. To this end, we present a simple process using an off-the-shelf LLM, GPT-4o [36] . Starting from an output CAD Python code from CAD-Recode as shown in Figure 18a , we prepare a simple and generic prompt (Figure 18b ) for the LLM to generate a refactored version of the code such that when executed the user can change with the dimensions of each primitive. As seen in Figure 18c , the LLM is able to generate a code with comments that describe the different primitives semanticallly and include appropriate variables for the dimensions of each of the primitive, such as the height and the diameter of each cylinder. The code generated by the LLM, can be directly executed in a Jupyter notebook with the CadQuery and ipywidgets libraries. Figure 6 of the main paper shows the generated sliders and how can the shape be then edited. This demonstrates that the CAD representation as Python code within a reverse engineering scenario opens the door to new applications when combined with LLMs. Examine the following CAD code carefully to understand the 3D object it generates and answer the question based on your interpretation of the rendered image of that object. SOL; Line:(221,128); Line:(221,223) ;Line:(128,223); Line:(128,128); Ext: (128,128,128,32,110,128,98,167,128, Newbody, One-sided); EOS Hint: the CAD code has the following syntax: CAD code consists of a sequence of CAD commands that describe a 3D object. The commands fall into two categories: sketch and extrusion. Sketch commands are used to specify closed curves on a 2D plane in 3D space. Each closed curve is referred as a loop, and one or more loops form a closed region called a profile. A loop always starts with an indicator command <SOL> followed by a series of curve commands. All the curves on the loop are in counterclockwise order, beginning with the curve whose starting point is at the most bottom-left. In total, there are three possible curve commands: Line, Arc, and Circle. Line(x, y): a line, with x, y as line end-point. Arc(x, y, u, f): an arc, with x,y as arc end-point, u as sweep angle and f as whether it is counter-clockwise, f=0 means it is counter-clockwise, f=1 means it is not counter-clockwise. Circle(x, y, r): a circle, with x,y as the center point and r as the radius. The extrusion command has two purposes: 1) It extrudes a sketch profile from a 2D plane into a 3D body, and the extrusion type can be either one-sided, symmetric, or two-sided with respect to the profile's sketch plane. 2) The command also specifies (through the parameter b in Ext) how to merge the newly extruded 3D body with the previously created shape by one of the boolean operations: either creating a new body, or joining, cutting or intersecting with the existing body. Ext(x, y, z, o, p, q, s, e, f, b, u): extrude operation, with x, y, z as the sketch plane orientation, o, p, q as the sketch plane origin, s as the scale of the associated sketch profile, e, f as the extrude distances towards both sides, b as the type of merge operation (could be New-body operation, join operation, cut operation and intersect operation) and u as the extrude type (could be one-sided, symmetric or two-sided). <EOS> means the end of the code. Question: How many faces does the CAD object in the image have? (a) DeepCAD Representation Examine the following CAD code carefully to understand the 3D object it generates and answer the question based on your interpretation of the rendered image of that object.\", 'section': 'G. Editing Pipeline Details', 'sec_num': None}, {'text': \"import cadquery as cq def make shape(): plane0 = cq.Plane(origin = (-0.75,-0.1406,0.0),xDir = (1.0,0.0,0.0),normal = (0.0,0.0,1.0)) w0 = cq.Workplane(plane0) face0 = w0.sketch().face(w0.sketch().segment( (0.0, 0.0), (0.7495, 0.0)).segment((0.7495, 0.0), (0.7495, 0.7656)).segment((0.7495, 0.7656), (0.0, 0.7656)).segment((0.0, 0.7656), (0.0, 0.0)).assemble(), mode = 'a').finalize() shape0 = face0.extrude(0.3046875, both=False) return shape0\", 'section': 'G. Editing Pipeline Details', 'sec_num': None}, {'text': \"Question: How many faces does the CAD object in the image have? Question: How many holes does the CAD object in the image have? A) Two, B) Three, C) Four, D) Five Correct Answer: B (a) Point cloud and corresponding CAD-specific question The CAD object in the image has five holes. (b) PointLLM output from point cloud To determine the number of holes in the CAD object, let's break down the CAD code step by step: 1. Extrusion Command: Start;Ext:(128,130,128,128,130,128,128,128,NewBody,96); This command sets up an extrusion with specific parameters and indicates that a new body will be created. 2. First Loop: Line:(43,0);Arc:(213,0,255,43);Line:(213,85);Arc:(43,85,0,43);EOL; -Line:(43,0) -A line from the starting point to (43,0). -Arc:(213,0,255,43) -An arc with midpoint (213,0) and endpoint (255,43). -Line:(213,85) -A line from the previous endpoint to (213,85). -Arc:(43,85,0,43) -An arc with midpoint (43,85) and endpoint (0,43). -EOL -End of the loop. This forms a closed loop, which is a profile for extrusion. 3. Second Loop: Circle:(43,43,43,51);EOL; -Circle:(43,43,43,51) -A circle with the most left point at (43,43) and the most top point at (43,51). -EOL -End of the loop. This forms another closed loop, which is another profile for extrusion. 4. End of Sketch and Extrusion: EOF;EOS;End; -EOF -End of face.\", 'section': 'G. Editing Pipeline Details', 'sec_num': None}, {'text': '-EOS -End of sketch.', 'section': 'G. Editing Pipeline Details', 'sec_num': None}, {'text': '-End -End of the code. From the above analysis, we can see that the CAD object consists of:', 'section': 'G. Editing Pipeline Details', 'sec_num': None}, {'text': '-One main profile formed by the first loop.', 'section': 'G. Editing Pipeline Details', 'sec_num': None}, {'text': \"-One circular profile formed by the second loop. The circular profile represents a hole within the main profile. Since there is only one circular profile, the CAD object has one hole. Answer: A (c) GPT-4o output from CAD-SIGNet prediction Let's break down the CAD code step by step to understand the 3D object it generates and determine the number of holes. 1. Workplane Creation: w0 = cq.Workplane('XY', origin=(0,0,1)) This line creates a workplane on the XY plane with an origin at (0,0,1). 2. Sketching the Shape: r = w0.sketch() This initializes a sketch on the workplane. 3. Defining the Shape: .segment((-66,-34), (50,-34) ) .segment((50,-32)) .arc((100,0), (50, 32) ) .segment ((50,34) ) .segment((-66,34)) .segment((-66,32)) .arc((-100,0),(-66,-32)) .close() These lines define a closed shape with segments and arcs. The shape appears to be symmetrical along the Y-axis. 4. Adding Holes: .assemble() .push([(-66,0)]).circle(10, mode='s') .push([(0,0)]).circle(10, mode='s') .push([(66,0)]).circle(10, mode='s') .finalize() These lines add three circles (holes) to the shape at positions (-66,0), (0,0), and (66,0). 5. Extruding the Shape: .extrude(-4) This line extrudes the shape by -4 units, creating a 3D object with the defined shape and holes. From the code, we can see that three circles (holes) are added to the shape. Therefore, the CAD object has three holes. Answer: B (d) GPT-4o output from CAD-Recode prediction \", 'section': 'G. Editing Pipeline Details', 'sec_num': None}], 'back_matter': [{'text': 'import cadquery as cq w0 = cq.Workplane(\\'XY\\', origin=(0, 0, 0)) r = w0.workplane(offset=-100 / 2).cylinder (100, 100) .union(w0.workplane(offset=100 / 2).cylinder(100, 34))(a) CAD-Recode output as CadQuery Python code.Refactor the code, add functions and variables that can make the code easier to edit and more interpretable. Add in the code, sliders to edit the size of each primitive: import cadquery as cq w0=cq.Workplane(\\'XY\\',origin=(0,0,0)) r=w0.workplane(offset=-100/2).cylinder(100,100 \"\"\"Creates a cylinder on the specified workplane with a given diameter, height, and offset.\"\"\" return workplane.workplane(offset=offset).cylinder(height, diameter / 2) def build_model(base_diameter=default_base_diameter, base_height=default_base_height, top_diameter=default_top_diameter, top_height=default_top_height): \"\"\"Builds the model with adjustable base and top cylinder dimensions.\"\"\" # Initialize the main workplane w0 = cq.Workplane(\"XY\", origin=(0, 0, 0)) ', 'section': 'annex', 'sec_num': None}], 'ref_entries': {'FIGREF0': {'text': 'Figure 1. 3D CAD reverse engineering is a process of converting a point cloud into a CAD model (top). Existing methods are constrained by the use of method-specific CAD representations and limited hand-crafted training datasets (a). On the contrary, CAD-Recode employs a pre-trained LLM with a lightweight projector that translates point clouds into executable Python code and is trained on a procedurally generated dataset (b).', 'fig_num': '1', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF1': {'text': 'Figure 2. Sketch-extrude sequence (top) in DeepCAD representation (middle) and our CadQuery code (bottom).', 'fig_num': '1', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF2': {'text': \"Interpretability and LLM Compatibility: The proposed representation, based on Python and CadQuery syntax, presents an alternative to abstract numerical encodings with improved interpretability. Its code-based format facilitates model editing both programmatically and through CAD software. Importantly, this representation aligns with pretrained LLMs' demonstrated proficiency in Python code generation and manipulation. Indeed, state-of-the-art proprietary LLMs like GPT-4 [36] achieve over 90% accuracy on the Python code HumanEval benchmark [5], while even lightweight open-source models such as Qwen2-1.5B [55] show promising code generation capabilities. Hence, this code representation facilitates fine-tuning of pre-trained LLMs for the specific task of reverse engineering point clouds into CAD Python code and opens the doors for new capabilities with off-the-shelf LLMs.\", 'fig_num': '3', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF3': {'text': 'Figure 3. Examples of procedurally generated CAD models.', 'fig_num': '3', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF5': {'text': 'Figure 4. Overview of CAD-Recode. The pipeline comprises two parts: (1) a point cloud projector (marked blue) (2) a fine-tuned pretrained LLM (yellow). An input point cloud is processed using (1), and outputs are then passed to an LLM (2), which predicts a CAD sketch-extrude sequence in the form of executable Python code.', 'fig_num': '4', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF6': {'text': 'Figure 6. Interactive editing of a CAD model. Given the code output from CAD-Recode and a generic prompt, GPT-4o allows automated and interactive editing of the CAD model.', 'fig_num': '6', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF7': {'text': 'Figure 13 illustrates the predicted code sequences and their corresponding reconstructed shapes. The predicted codes have a syntax that is consistent with the procedurally generated training examples, showing that CAD-Recode successfully learns both the features and CAD design patterns established in the training set.', 'fig_num': '7', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF8': {'text': 'Figure 7. Examples from our procedurally generated training dataset. Each row contains CadQuery Python code and a corresponding CAD model. Examples contain not only basic line, circle, and arc primitives, but also higher-level abstractions such as rect, box, and cylinder.', 'fig_num': '7', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF9': {'text': 'Figure 8. Our 1 M procedurally generated training dataset displays distributions CAD models that are skewed towards models with larger edge and face count per model than the DeepCAD dataset (160 k models).', 'fig_num': '8', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF10': {'text': 'Figure 9. Example models from real-world CC3D dataset. The scans exhibits numerous artifacts such as surface noise, missing parts and smoothed edges. In the CC3D experiments reported in the main paper, the input point clouds are sampled from the scans. Zoom in for better details.', 'fig_num': '9', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF11': {'text': 'Figure 10. Qualitative results on the DeepCAD dataset.', 'fig_num': '101112', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF12': {'text': \"cadquery as cq w0 = cq.Workplane('XY', origin=(0, 0, -16)) r = w0.sketch().arc((-46, -23), (-95, -74), (-27, -56)).segment((30, -56)) .arc((96, -72), (44, -25)).segment((44, -12)).arc((31, 14), (30, 42)) .arc((1, 92), (-31, 44)).arc((-32, 43), (-33, 43)).arc((-31, 20),(-39, -2)) .segment((-39, -12)).segment((-43, -12)).arc((-45, -17),(-46, -23)).assemble() .push([(-64, -56)]).circle(28, mode='s').push([(0, 56)]).circle(28, mode='s') .push([(0, -19)]).circle(28, mode='s').push([(65, -56)])\", 'fig_num': '13', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF13': {'text': 'Figure 13. CAD-Recode predictions on DeepCAD (top 2 rows), Fusion360 (mid 3 rows), and CC3D (last row) datasets. Each row contains predicted CadQuery Python code and its result after execution in Python interpreter.', 'fig_num': '13', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF14': {'text': 'Figure 14. Examples of invalid predictions. Each row contains the ground-truth CAD model (left) and an invalid predicted CadQuery Python code (right). The CAD models in (a) and (b) are taken from the DeepCAD dataset and the CC3D dataset for (c) and (d). Invalid predictions mostly take place when the ground-truth contains features of very small dimension with respect to the size of the CAD model as in (a) and (b), or when the ground-truth model contains operations other than the ones supported as in (c) and (d).', 'fig_num': '14', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF15': {'text': 'Figure 15. CAD-Recode predictions from different point cloud sampling on DeepCAD, Fusion360, and real-world CC3D datasets. For each prediction, 256 points are sampled randomly from the input point cloud.', 'fig_num': '15', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF16': {'text': 'Figure 16. Example of a CAD question from SGP-Bench in the DeepCAD representation (b) and using the CadQuery representation (c).When asking the question in CadQuery format no hint is provided, while in DeepCAD format a long interpretative hint is required. The choice of answers are A) 6, B) 4, C) 8 and D) 5. The correct answer is A) 6.', 'fig_num': '16', 'num': None, 'uris': None, 'type_str': 'figure'}, 'FIGREF17': {'text': 'Figure 17. Example of Point cloud CAD-QA (a) and answers provided by PointLLM (b), CADSIGNet and GPT-4o (c) and CAD-Recode and GPT-4o (d).', 'fig_num': '17', 'num': None, 'uris': None, 'type_str': 'figure'}, 'TABREF1': {'html': None, 'text': 'Comparison of CAD reverse engineering methods on DeepCAD and Fusion360 datasets. Our CAD-Recode trained on the 160 k DeepCAD dataset demonstrates an improvement over existing state-of-the-art methods both in terms of geometric fidelity and validity of the generated sketch-extrude sequences. Our procedurally generated dataset provides a significant boost in the prediction quality.', 'num': None, 'type_str': 'table', 'content': '<table><tr><td>Method</td><td colspan=\"10\">Train Dataset Name Size Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR \u2193 Mean CD\u2193 Med. CD\u2193 IoU\u2191 IR\u2193 DeepCAD Test Set Fusion360 Test Set</td></tr><tr><td>DeepCAD [48]</td><td colspan=\"2\">DeepCAD 160k</td><td>42.5</td><td>9.64</td><td>46.7</td><td>7.1</td><td>330</td><td>89.2</td><td colspan=\"2\">39.9 25.2</td></tr><tr><td>PrismCAD [25]</td><td colspan=\"2\">DeepCAD 127k</td><td>-</td><td>4.28</td><td colspan=\"2\">72.1 16.2</td><td>-</td><td>4.75</td><td colspan=\"2\">65.3 18.0</td></tr><tr><td>Point2Cyl [45]</td><td colspan=\"2\">DeepCAD 35k</td><td>-</td><td>4.27</td><td>73.8</td><td>3.9</td><td>-</td><td>4.18</td><td>67.5</td><td>3.2</td></tr><tr><td>HNC-CAD [52]</td><td colspan=\"2\">DeepCAD 125k</td><td>-</td><td>8.64</td><td>65.3</td><td>5.6</td><td>-</td><td>36.8</td><td>63.5</td><td>7.3</td></tr><tr><td>MultiCAD [33]</td><td colspan=\"2\">DeepCAD 160k</td><td>-</td><td>8.09</td><td>-</td><td>11.5</td><td>-</td><td>42.2</td><td>-</td><td>16.5</td></tr><tr><td>TransCAD [12]</td><td colspan=\"2\">DeepCAD 140k</td><td>32.3</td><td>4.51</td><td>65.5</td><td>1.1</td><td>78.6</td><td>33.4</td><td>60.2</td><td>2.4</td></tr><tr><td colspan=\"3\">CAD-Diffuser [34] DeepCAD 160k</td><td>-</td><td>3.02</td><td>74.3</td><td>1.5</td><td>-</td><td>3.85</td><td>63.2</td><td>1.7</td></tr><tr><td colspan=\"3\">CAD-SIGNet [21] DeepCAD 160k</td><td>3.43</td><td>0.28</td><td>77.6</td><td>0.9</td><td>7.37</td><td>0.48</td><td>65.6</td><td>1.6</td></tr><tr><td>CAD-Recode</td><td colspan=\"2\">DeepCAD 160k</td><td>1.98</td><td>0.27</td><td>80.7</td><td>0.0</td><td>3.37</td><td>0.52</td><td>67.6</td><td>0.1</td></tr><tr><td>CAD-Recode</td><td>Ours</td><td>1M</td><td>0.30</td><td>0.16</td><td colspan=\"2\">92.0 0.4</td><td>0.35</td><td>0.15</td><td colspan=\"2\">87.8 0.5</td></tr></table>'}, 'TABREF3': {'html': None, 'text': \"is a benchmark of 1000 CAD-specific Question Answering (CAD-QA) tasks that test LLMs' understanding of CAD model geometry from sketch-extrude se-Ablation of training data and test-time sampling. The results demonstrate the advantage of training on our procedurally generated data, while the test-time sampling helps reducing the invalidity ratio. CD stands for mean Chamfer distance.\", 'num': None, 'type_str': 'table', 'content': '<table><tr><td>Method</td><td/><td colspan=\"7\">Train Dataset Name Size Sampling CD\u2193 IoU\u2191 IR\u2193 CD\u2193 IoU\u2191 IR\u2193 CD\u2193 IoU\u2191 IR\u2193 Test-time DeepCAD Fusion360 Real-World CC3D</td></tr><tr><td colspan=\"4\">Previous best [21] DeepCAD 160 k</td><td>\u2713</td><td colspan=\"3\">3.43 77.6 0.9 7.37 65.6 1.6 14.80 42.6</td><td>4.4</td></tr><tr><td colspan=\"2\">CAD-Recode</td><td colspan=\"2\">DeepCAD 160 k</td><td>\u2713</td><td>1.98 80.7 0.0 3.37 67.6 0.1</td><td>3.79</td><td>56.4</td><td>0.0</td></tr><tr><td colspan=\"2\">CAD-Recode</td><td>Ours</td><td>160 k</td><td>\u2713</td><td>0.54 88.3 0.3 0.66 82.0 0.1</td><td>1.27</td><td>69.0</td><td>0.2</td></tr><tr><td colspan=\"2\">CAD-Recode</td><td>Ours</td><td>1 M</td><td>\u2713</td><td colspan=\"4\">0.30 92.0 0.4 0.35 87.8 0.5 0.76 74.2 0.3</td></tr><tr><td colspan=\"4\">Previous best [21] DeepCAD 160 k</td><td>\u2717</td><td colspan=\"4\">6.81 77.3 4.4 14.5 58.4 9.3 32.59 39.1 15.5</td></tr><tr><td colspan=\"2\">CAD-Recode</td><td>Ours</td><td>1 M</td><td>\u2717</td><td colspan=\"4\">0.75 89.3 4.9 0.89 84.2 8.7 3.05 65.6 16.8</td></tr><tr><td>Points</td><td>Model Size</td><td colspan=\"4\">DeepCAD CD\u2193 IoU\u2191 CD\u2193 IoU\u2191 CD\u2193 IoU\u2191 Fusion360 CC3D</td><td/><td/></tr><tr><td>128</td><td>0.5 B</td><td colspan=\"4\">0.18 89.9 0.18 84.3 0.38 71.9</td><td/><td/></tr><tr><td>256</td><td>0.5 B</td><td/><td/><td/><td/><td/><td/></tr></table>'}, 'TABREF5': {'html': None, 'text': 'Ablation of architecture details.', 'num': None, 'type_str': 'table', 'content': '<table><tr><td>1</td></tr></table>'}}}}\n\n-----\n\n## Overview of the plan\n# CAD-Recode Reproduction Plan\n\n## Overview\nCAD-Recode is a method that translates point clouds into executable Python CadQuery code for CAD reverse engineering. The approach combines a lightweight point cloud projector with a pre-trained LLM (Qwen2-1.5B) and is trained on a procedurally generated dataset of 1M CAD sequences.\n\n## 1. Key Methodology Components\n\n### 1.1 CAD Representation\n- **Target Format**: CadQuery Python code representing sketch-extrude sequences\n- **Key Advantages**: \n  - Modularity (supports both low-level primitives and high-level abstractions)\n  - Direct executability \n  - LLM interpretability\n- **Supported Operations**: \n  - Primitives: lines, arcs, circles\n  - High-level: boxes, cylinders, rectangles\n  - Operations: extrusion, union, boolean operations\n\n### 1.2 Problem Formulation\n- **Input**: Point cloud P \u2208 R^(n\u00d73)\n- **Output**: Valid CAD code C \u2208 C where C = {w \u2208 \u03a3* | \u03c6_syn(w) \u2227 \u03c6_cad(w)}\n- **Validation Functions**:\n  - \u03c6_syn: Python syntax validation\n  - \u03c6_cad: CAD-specific validation (CadQuery syntax + geometric validity)\n\n### 1.3 Architecture Components\n\n#### Point Cloud Projector (\u03a8_p)\n1. **Furthest Point Sampling**: Downsample to n_p = 256 points\n2. **Fourier Positional Encoding**: Encode 3D coordinates\n3. **Linear Projection**: Map to query tokens Q_p \u2208 R^(n_p \u00d7 d_q) where d_q = 1536\n\n#### LLM Decoder (\u03a8_LLM)\n- **Base Model**: Qwen2-1.5B\n- **Input**: Concatenated tokens [Q_p; Q_t] where Q_t are tokenized code tokens\n- **Output**: Next-token prediction for CAD code generation\n- **Special Tokens**: <s> (start), <e> (end)\n\n## 2. Training Dataset Generation\n\n### 2.1 Procedural Generation Pipeline\n- **Target Size**: 1 million CAD sequences\n- **Generation Strategy**: \n  - Algorithm 1: Generate2DSketch (3-8 primitives per sketch)\n  - Algorithm 2: GenerateCAD (extrude sketches, apply unions)\n- **Primitives**: Circles, rotated rectangles combined via union/cut operations\n- **Validation**: Multiple checks for geometric validity and uniqueness\n\n### 2.2 Dataset Characteristics\n- **Parameter Quantization**: Coordinates in range [-100, 100] with resolution 1\n- **Normalization**: Models fit within unit bounding box\n- **Modularity Features**: \n  - Reuse of point coordinates\n  - Abstraction to higher-level shapes (boxes, cylinders)\n  - Variable reuse in code\n\n### 2.3 Code Structure\nAll generated codes follow consistent pattern:\n1. Library import (`import cadquery as cq`)\n2. Workplane definition\n3. Sketch-extrude operations with union combinations\n\n## 3. Training Strategy\n\n### 3.1 Training Configuration\n- **Optimizer**: AdamW\n- **Learning Rate**: 0.0002\n- **Weight Decay**: 0.01\n- **Scheduler**: Cosine learning rate scheduler\n- **Iterations**: 100k with 1k warmup\n- **Batch Size**: 18\n- **Hardware**: Single NVIDIA H100 GPU\n- **Training Time**: ~12 hours\n\n### 3.2 Data Augmentation\n- **Gaussian Noise**: \u03c3 = 0.01, applied with probability 0.5\n- **Point Cloud Sampling**: Random sampling to 256 points\n\n### 3.3 Loss Function\n- **Objective**: Negative Log-Likelihood (NLL) of target CAD code sequence\n- **Training Mode**: End-to-end (point cloud projector from scratch, LLM fine-tuned)\n\n## 4. Inference Strategy\n\n### 4.1 Test-Time Sampling\n- **Multiple Candidates**: Generate 10 different CAD code candidates\n- **Sampling Strategy**: Different point cloud samplings for each candidate\n- **Selection**: Choose best candidate based on validation metrics\n\n### 4.2 Inference Pipeline\n1. Point cloud projector processes input \u2192 query tokens Q_p\n2. LLM generates code autoregressively starting with <s>\n3. Generation stops at <e> token\n4. Validate generated code for syntax and geometric validity\n\n## 5. Experimental Setup\n\n### 5.1 Datasets\n**Test Datasets**:\n- **DeepCAD**: 8,046 models\n- **Fusion360**: 1,725 models  \n- **CC3D**: 2,973 models (real-world scans with noise/artifacts)\n\n**Point Cloud Generation**:\n- DeepCAD/Fusion360: Sample points from meshes\n- CC3D: Use provided point clouds from 3D scans\n\n### 5.2 Evaluation Metrics\n- **Chamfer Distance (CD)**: Mean and median, computed with 8,192 points, multiplied by 10\u00b3\n- **Intersection over Union (IoU)**: Percentage from resulting CAD model meshes\n- **Invalidity Ratio (IR)**: Percentage of sequences failing to produce valid CAD models\n\n### 5.3 Baseline Comparisons\n- CAD-SIGNet [21]\n- DeepCAD [48]\n- TransCAD [12]\n- CAD-Diffuser [34]\n- MultiCAD [33]\n- Point2Cyl [45]\n- HNC-CAD [52]\n- PrismCAD [25]\n\n## 6. Implementation Requirements\n\n### 6.1 Dependencies\n- **Core Libraries**: \n  - PyTorch/HuggingFace Transformers\n  - CadQuery library\n  - PythonOCC\n- **Model**: Qwen2-1.5B from HuggingFace\n- **Point Cloud Processing**: Furthest point sampling implementation\n- **Evaluation**: Chamfer distance computation utilities\n\n### 6.2 Data Processing Pipeline\n1. **Dataset Conversion**: Convert existing datasets (DeepCAD, Fusion360) to CadQuery format\n2. **Procedural Generation**: Implement Algorithms 1 & 2 for synthetic data creation\n3. **Validation Framework**: Implement \u03c6_syn and \u03c6_cad validation functions\n4. **Point Cloud Sampling**: Mesh to point cloud conversion for test datasets\n\n### 6.3 Model Implementation\n1. **Point Cloud Projector**: \n   - Furthest point sampling module\n   - Fourier positional encoding\n   - Linear projection layer\n2. **LLM Integration**: \n   - Load pre-trained Qwen2-1.5B\n   - Modify for concatenated input tokens\n   - Implement fine-tuning pipeline\n3. **Training Loop**: \n   - End-to-end training with NLL loss\n   - Gradient accumulation if needed\n   - Validation during training\n\n### 6.4 Evaluation Pipeline\n1. **Metrics Computation**: Implement CD, IoU, IR calculations\n2. **Code Validation**: Syntax and geometric validation\n3. **Visualization**: Point cloud and CAD model rendering\n4. **Comparison Framework**: Standardized evaluation against baselines\n\n## 7. Additional Experiments\n\n### 7.1 CAD Question Answering\n- **Dataset**: SGP-Bench (1000 questions)\n- **Pipeline**: CAD-Recode \u2192 GPT-4o for QA\n- **Baseline**: PointLLM, CAD-SIGNet + GPT-4o\n\n### 7.2 Interactive Editing\n- **Goal**: Generate editable code with parameter sliders\n- **Implementation**: GPT-4o refactoring of CAD-Recode output\n- **Interface**: Jupyter notebook with ipywidgets\n\n### 7.3 Ablation Studies\n- **Training Data Size**: 160k vs 1M samples\n- **Test-time Sampling**: With/without multiple candidates\n- **Architecture**: Point cloud size (64, 128, 256), LLM size (0.5B vs 1.5B)\n- **Dataset Comparison**: DeepCAD vs procedurally generated\n\n## 8. Potential Implementation Challenges\n\n### 8.1 Unclear Aspects\n- **Exact Fourier Encoding**: Specific implementation details not provided\n- **Duplicate Detection**: Protocol referenced but not detailed\n- **Code Simplification**: \"Simplify using higher level abstractions\" - exact algorithm unclear\n- **Quantization Details**: Specific method for parameter discretization\n\n### 8.2 Technical Challenges\n- **CadQuery Integration**: Ensuring proper installation and compatibility\n- **Memory Requirements**: Large point clouds + LLM may require optimization\n- **Validation Speed**: Real-time code execution validation may be slow\n- **Dataset Scale**: Generating 1M samples requires significant computational resources\n\n### 8.3 Evaluation Challenges\n- **Baseline Reproduction**: Some baseline results may be difficult to reproduce exactly\n- **Metric Implementation**: Ensuring consistent CD/IoU computation with prior work\n- **Real-world Data**: CC3D dataset access and preprocessing\n\nThis comprehensive plan provides the foundation for implementing CAD-Recode, covering all major components from data generation through evaluation, while highlighting areas that may require additional research or clarification during implementation.\n\n-----\n\n## Design\n[CONTENT]\n{\n    \"Implementation approach\": \"We will implement CAD-Recode using PyTorch and HuggingFace Transformers for the LLM backbone (Qwen2-1.5B), with a custom point cloud projector module. The system will include procedural dataset generation using CadQuery, end-to-end training with NLL loss, and comprehensive evaluation on multiple datasets. We'll use open3d for point cloud processing, transformers for the LLM, and implement custom validation for generated CAD code. The architecture separates data generation, model training, and evaluation into distinct modules for clarity and maintainability.\",\n    \n    \"File list\": [\n        \"main.py\",\n        \"config.py\",\n        \"data/dataset_generator.py\",\n        \"data/dataset_loader.py\",\n        \"models/point_cloud_projector.py\",\n        \"models/cad_recode_model.py\",\n        \"training/trainer.py\",\n        \"evaluation/evaluator.py\",\n        \"evaluation/metrics.py\",\n        \"utils/cad_validation.py\",\n        \"utils/point_cloud_utils.py\",\n        \"utils/fourier_encoding.py\",\n        \"experiments/run_experiments.py\"\n    ],\n    \n    \"Data structures and interfaces\": \"\nclassDiagram\n    class Config {\n        +model_config: dict\n        +training_config: dict\n        +data_config: dict\n        +evaluation_config: dict\n        +__init__()\n        +load_from_file(path: str) -> Config\n    }\n    \n    class DatasetGenerator {\n        +config: dict\n        +__init__(config: dict)\n        +generate_sketch() -> dict\n        +generate_cad_model() -> str\n        +validate_code(code: str) -> bool\n        +generate_dataset(size: int) -> List[dict]\n    }\n    \n    class DatasetLoader {\n        +config: dict\n        +tokenizer: Any\n        +__init__(config: dict, tokenizer: Any)\n        +load_procedural_data() -> Dataset\n        +load_deepcad_data() -> Dataset\n        +load_fusion360_data() -> Dataset\n        +load_cc3d_data() -> Dataset\n        +preprocess_point_cloud(pc: np.ndarray) -> torch.Tensor\n    }\n    \n    class FourierEncoding {\n        +num_freqs: int\n        +__init__(num_freqs: int)\n        +encode(coords: torch.Tensor) -> torch.Tensor\n    }\n    \n    class PointCloudProjector {\n        +num_points: int\n        +embed_dim: int\n        +fourier_encoder: FourierEncoding\n        +linear_proj: nn.Linear\n        +__init__(num_points: int, embed_dim: int)\n        +forward(point_cloud: torch.Tensor) -> torch.Tensor\n        +furthest_point_sampling(pc: torch.Tensor, num_points: int) -> torch.Tensor\n    }\n    \n    class CADRecodeModel {\n        +point_projector: PointCloudProjector\n        +llm: AutoModelForCausalLM\n        +tokenizer: AutoTokenizer\n        +config: dict\n        +__init__(config: dict)\n        +forward(point_cloud: torch.Tensor, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor\n        +generate_code(point_cloud: torch.Tensor, max_length: int) -> str\n        +validate_generated_code(code: str) -> bool\n    }\n    \n    class Trainer {\n        +model: CADRecodeModel\n        +train_loader: DataLoader\n        +val_loader: DataLoader\n        +optimizer: torch.optim.Optimizer\n        +scheduler: Any\n        +config: dict\n        +__init__(model: CADRecodeModel, train_loader: DataLoader, val_loader: DataLoader, config: dict)\n        +train_epoch() -> float\n        +validate() -> float\n        +train(num_epochs: int) -> None\n        +save_checkpoint(path: str) -> None\n        +load_checkpoint(path: str) -> None\n    }\n    \n    class Metrics {\n        +__init__()\n        +compute_chamfer_distance(pred_pc: np.ndarray, gt_pc: np.ndarray) -> float\n        +compute_iou(pred_mesh: Any, gt_mesh: Any) -> float\n        +compute_invalidity_ratio(codes: List[str]) -> float\n        +execute_cad_code(code: str) -> Any\n    }\n    \n    class CADValidator {\n        +__init__()\n        +validate_syntax(code: str) -> bool\n        +validate_cad_semantics(code: str) -> bool\n        +validate_geometric(code: str) -> bool\n        +is_valid_code(code: str) -> bool\n    }\n    \n    class Evaluator {\n        +model: CADRecodeModel\n        +test_loaders: dict\n        +metrics: Metrics\n        +validator: CADValidator\n        +config: dict\n        +__init__(model: CADRecodeModel, test_loaders: dict, config: dict)\n        +evaluate_dataset(dataset_name: str) -> dict\n        +generate_multiple_candidates(point_cloud: torch.Tensor, num_candidates: int) -> List[str]\n        +evaluate_all_datasets() -> dict\n        +save_results(results: dict, path: str) -> None\n    }\n    \n    class ExperimentRunner {\n        +config: Config\n        +__init__(config: Config)\n        +run_training_experiment() -> None\n        +run_evaluation_experiment() -> None\n        +run_ablation_studies() -> None\n        +run_cad_qa_experiment() -> None\n    }\n    \n    class Main {\n        +config: Config\n        +__init__()\n        +setup_logging() -> None\n        +run() -> None\n    }\n    \n    Config --> Main\n    Main --> ExperimentRunner\n    ExperimentRunner --> DatasetGenerator\n    ExperimentRunner --> DatasetLoader\n    ExperimentRunner --> CADRecodeModel\n    ExperimentRunner --> Trainer\n    ExperimentRunner --> Evaluator\n    CADRecodeModel --> PointCloudProjector\n    PointCloudProjector --> FourierEncoding\n    Trainer --> CADRecodeModel\n    Evaluator --> CADRecodeModel\n    Evaluator --> Metrics\n    Evaluator --> CADValidator\n    DatasetLoader --> CADValidator\n\",\n    \n    \"Program call flow\": \"\nsequenceDiagram\n    participant M as Main\n    participant C as Config\n    participant ER as ExperimentRunner\n    participant DG as DatasetGenerator\n    participant DL as DatasetLoader\n    participant CM as CADRecodeModel\n    participant PCP as PointCloudProjector\n    participant T as Trainer\n    participant E as Evaluator\n    participant MT as Metrics\n    participant CV as CADValidator\n    \n    M->>C: __init__()\n    M->>C: load_from_file(config_path)\n    C-->>M: return config\n    M->>ER: __init__(config)\n    M->>ER: run_training_experiment()\n    \n    ER->>DG: __init__(config.data_config)\n    ER->>DG: generate_dataset(1000000)\n    DG->>DG: generate_sketch()\n    DG->>DG: generate_cad_model()\n    DG->>CV: validate_code(code)\n    CV-->>DG: validation_result\n    DG-->>ER: return dataset\n    \n    ER->>DL: __init__(config.data_config, tokenizer)\n    ER->>DL: load_procedural_data()\n    DL->>DL: preprocess_point_cloud(pc)\n    DL-->>ER: return train_loader, val_loader\n    \n    ER->>CM: __init__(config.model_config)\n    CM->>PCP: __init__(num_points, embed_dim)\n    PCP-->>CM: projector_initialized\n    CM-->>ER: return model\n    \n    ER->>T: __init__(model, train_loader, val_loader, config)\n    ER->>T: train(num_epochs)\n    loop Training Loop\n        T->>T: train_epoch()\n        T->>CM: forward(point_cloud, input_ids, attention_mask)\n        CM->>PCP: forward(point_cloud)\n        PCP-->>CM: query_tokens\n        CM-->>T: loss\n        T->>T: validate()\n        T->>CM: generate_code(point_cloud, max_length)\n        CM-->>T: generated_code\n    end\n    T->>T: save_checkpoint(path)\n    T-->>ER: training_complete\n    \n    ER->>E: __init__(model, test_loaders, config)\n    ER->>E: evaluate_all_datasets()\n    loop For each dataset\n        E->>E: evaluate_dataset(dataset_name)\n        E->>E: generate_multiple_candidates(point_cloud, 10)\n        E->>CM: generate_code(point_cloud, max_length)\n        CM-->>E: candidate_code\n        E->>CV: is_valid_code(code)\n        CV-->>E: validation_result\n        E->>MT: compute_chamfer_distance(pred_pc, gt_pc)\n        MT-->>E: cd_score\n        E->>MT: compute_iou(pred_mesh, gt_mesh)\n        MT-->>E: iou_score\n        E->>MT: compute_invalidity_ratio(codes)\n        MT-->>E: ir_score\n    end\n    E->>E: save_results(results, path)\n    E-->>ER: return evaluation_results\n    \n    ER-->>M: experiment_complete\n\",\n    \n    \"Anything UNCLEAR\": \"1. The exact implementation details of the Fourier positional encoding are not specified in the paper. 2. The specific heuristics used in the procedural dataset generation algorithms (Algorithm 1 and 2) need more detailed specification. 3. The paper mentions 'duplicate detection protocol' but doesn't provide implementation details. 4. The exact quantization method for parameters (range [-100, 100] with resolution 1) needs clarification. 5. The test-time sampling strategy for selecting the best candidate among 10 generated codes is not clearly specified. 6. Integration details with CadQuery library for code execution and validation may require additional error handling not covered in the paper.\"\n}\n[/CONTENT]\n\n-----\n\n## Task\n[CONTENT]\n{\n    \"Required packages\": [\n        \"torch>=2.0.0\",\n        \"transformers>=4.30.0\",\n        \"numpy>=1.21.0\",\n        \"open3d>=0.17.0\",\n        \"cadquery>=2.3.0\",\n        \"pythonic-cadquery>=2.3.0\",\n        \"scikit-learn>=1.0.0\",\n        \"tqdm>=4.64.0\",\n        \"wandb>=0.15.0\",\n        \"matplotlib>=3.5.0\",\n        \"pyyaml>=6.0\",\n        \"scipy>=1.9.0\",\n        \"trimesh>=3.15.0\",\n        \"pymeshlab>=2022.2\",\n        \"plotly>=5.0.0\",\n        \"ipywidgets>=8.0.0\",\n        \"jupyter>=1.0.0\"\n    ],\n    \"Required Other language third-party packages\": [\n        \"OpenCASCADE (required by CadQuery for CAD operations)\",\n        \"FreeCAD (optional, for additional CAD validation)\",\n        \"Blender (optional, for mesh processing and visualization)\"\n    ],\n    \"Logic Analysis\": [\n        [\n            \"config.py\",\n            \"Configuration management class that handles all hyperparameters, model settings, and experimental configurations. Contains Config class with methods to load from YAML files, validate parameters, and provide default values. Critical for reproducibility as it centralizes all paper-specified hyperparameters like learning rate (0.0002), batch size (18), embedding dimension (1536), number of points (256), etc. No dependencies on other modules.\"\n        ],\n        [\n            \"utils/fourier_encoding.py\", \n            \"Implements Fourier positional encoding for 3D point coordinates as mentioned in the paper. Contains FourierEncoding class with encode() method that transforms 3D coordinates into higher-dimensional representations. This is a foundational component needed by the point cloud projector. Dependencies: torch, numpy. Critical for point cloud feature extraction.\"\n        ],\n        [\n            \"utils/point_cloud_utils.py\",\n            \"Utility functions for point cloud processing including furthest point sampling, normalization, noise addition, and coordinate transformations. Contains functions like furthest_point_sampling(), add_gaussian_noise(), normalize_point_cloud(). Used by multiple components including dataset loader and point cloud projector. Dependencies: torch, numpy, open3d.\"\n        ],\n        [\n            \"utils/cad_validation.py\",\n            \"CAD code validation utilities implementing \u03c6_syn and \u03c6_cad validation functions from the paper. Contains CADValidator class with methods validate_syntax(), validate_cad_semantics(), validate_geometric(), and is_valid_code(). Critical for ensuring generated code is executable and geometrically valid. Dependencies: cadquery, ast (for Python syntax validation), subprocess for code execution.\"\n        ],\n        [\n            \"data/dataset_generator.py\",\n            \"Implements procedural dataset generation following Algorithm 1 and 2 from the paper. Contains DatasetGenerator class with methods generate_sketch(), generate_cad_model(), validate_code(), and generate_dataset(). Generates 1M CAD sequences as CadQuery Python code with controlled features and design patterns. Dependencies: cadquery, random, numpy, utils/cad_validation.py. This is a standalone component that creates the training dataset.\"\n        ],\n        [\n            \"models/point_cloud_projector.py\",\n            \"Implements the point cloud projector module (\u03a8_p) from the paper architecture. Contains PointCloudProjector class with forward() method that processes point clouds through furthest point sampling, Fourier encoding, and linear projection to generate query tokens. Dependencies: torch, utils/fourier_encoding.py, utils/point_cloud_utils.py. Core component of the CAD-Recode architecture.\"\n        ],\n        [\n            \"data/dataset_loader.py\",\n            \"Handles loading and preprocessing of all datasets (procedural, DeepCAD, Fusion360, CC3D). Contains DatasetLoader class with methods for each dataset type, point cloud preprocessing, and PyTorch Dataset/DataLoader creation. Implements data augmentation (Gaussian noise) and tokenization. Dependencies: torch, transformers, utils/point_cloud_utils.py, utils/cad_validation.py, data/dataset_generator.py.\"\n        ],\n        [\n            \"models/cad_recode_model.py\",\n            \"Main model implementation combining point cloud projector with pre-trained LLM (Qwen2-1.5B). Contains CADRecodeModel class with forward(), generate_code(), and validate_generated_code() methods. Implements the core architecture from Figure 4 of the paper. Dependencies: torch, transformers, models/point_cloud_projector.py, utils/cad_validation.py.\"\n        ],\n        [\n            \"evaluation/metrics.py\",\n            \"Implements all evaluation metrics from the paper: Chamfer Distance, IoU, and Invalidity Ratio. Contains Metrics class with compute_chamfer_distance(), compute_iou(), compute_invalidity_ratio(), and execute_cad_code() methods. Critical for reproducing paper results. Dependencies: torch, numpy, trimesh, open3d, cadquery, utils/cad_validation.py.\"\n        ],\n        [\n            \"training/trainer.py\",\n            \"Training loop implementation with end-to-end training strategy from the paper. Contains Trainer class with train_epoch(), validate(), train(), save_checkpoint(), and load_checkpoint() methods. Implements NLL loss, AdamW optimizer, cosine scheduler, and all training hyperparameters from the paper. Dependencies: torch, transformers, models/cad_recode_model.py, wandb for logging.\"\n        ],\n        [\n            \"evaluation/evaluator.py\",\n            \"Comprehensive evaluation pipeline implementing test-time sampling and multi-dataset evaluation. Contains Evaluator class with evaluate_dataset(), generate_multiple_candidates(), evaluate_all_datasets() methods. Implements the 10-candidate sampling strategy from the paper. Dependencies: torch, models/cad_recode_model.py, evaluation/metrics.py, utils/cad_validation.py.\"\n        ],\n        [\n            \"experiments/run_experiments.py\",\n            \"Orchestrates all experiments including training, evaluation, ablation studies, and CAD-QA tasks. Contains ExperimentRunner class with methods for each experiment type. Handles experimental workflow and result collection. Dependencies: all previous modules, particularly training/trainer.py and evaluation/evaluator.py.\"\n        ],\n        [\n            \"main.py\",\n            \"Entry point that sets up logging, loads configuration, and runs experiments. Contains Main class with setup_logging() and run() methods. Coordinates the entire experimental pipeline and handles command-line arguments. Dependencies: config.py, experiments/run_experiments.py, logging setup.\"\n        ]\n    ],\n    \"Task list\": [\n        \"config.py\",\n        \"utils/fourier_encoding.py\",\n        \"utils/point_cloud_utils.py\", \n        \"utils/cad_validation.py\",\n        \"data/dataset_generator.py\",\n        \"models/point_cloud_projector.py\",\n        \"data/dataset_loader.py\",\n        \"models/cad_recode_model.py\",\n        \"evaluation/metrics.py\",\n        \"training/trainer.py\",\n        \"evaluation/evaluator.py\",\n        \"experiments/run_experiments.py\",\n        \"main.py\"\n    ],\n    \"Full API spec\": \"\",\n    \"Shared Knowledge\": \"Configuration parameters are centralized in config.py and include: model_config (embedding_dim=1536, num_points=256, num_freqs for Fourier encoding), training_config (learning_rate=0.0002, weight_decay=0.01, batch_size=18, num_epochs=100000, warmup_steps=1000), data_config (dataset paths, augmentation settings, noise_std=0.01), evaluation_config (num_candidates=10, metrics settings). Point cloud preprocessing pipeline is shared across dataset_loader.py and evaluator.py including furthest point sampling to 256 points, Fourier positional encoding, and Gaussian noise augmentation. CAD code validation logic is shared between dataset_generator.py, dataset_loader.py, and evaluator.py through utils/cad_validation.py. Tokenization and LLM handling use HuggingFace transformers with Qwen2-1.5B model consistently across training and evaluation. Metrics computation (Chamfer Distance, IoU, Invalidity Ratio) follows paper specifications with 8192 points for CD calculation and mesh-based IoU computation. Test-time sampling strategy generates 10 candidates through different point cloud samplings and selects best valid result.\",\n    \"Anything UNCLEAR\": \"1. Exact Fourier encoding implementation details (number of frequencies, encoding formula) are not specified in the paper. 2. Specific heuristics for procedural dataset generation algorithms need clarification on parameter ranges and geometric constraints. 3. The duplicate detection protocol mentioned in the paper lacks implementation details. 4. Test-time candidate selection criteria among 10 generated codes is not clearly specified. 5. Integration with CadQuery library may require specific version compatibility and error handling strategies. 6. Hardware requirements for generating 1M dataset samples and training on H100 GPU equivalent setup. 7. Exact preprocessing steps for converting DeepCAD/Fusion360 datasets to CadQuery format.\"\n}\n[/CONTENT]\n\n-----\n\n## Configuration file\n```yaml\n# CAD-Recode Configuration\n# Based on paper: \"CAD-Recode: Reverse Engineering CAD Code from Point Clouds\"\n\nmodel:\n  # LLM Configuration\n  llm_model_name: \"Qwen/Qwen2-1.5B\"  # Pre-trained LLM as specified in paper\n  embedding_dim: 1536  # Query token embedding dimension (d_q)\n  \n  # Point Cloud Projector Configuration\n  num_points: 256  # Number of points after furthest point sampling (n_p)\n  fourier_encoding:\n    num_freqs: 64  # Number of frequencies for Fourier positional encoding\n  \n  # Special tokens\n  start_token: \"<s>\"\n  end_token: \"<e>\"\n\ntraining:\n  # Training hyperparameters from paper Section 4.3 and Appendix A\n  learning_rate: 0.0002  # AdamW learning rate\n  weight_decay: 0.01  # AdamW weight decay\n  batch_size: 18  # Batch size for single H100 GPU\n  num_iterations: 100000  # Total training iterations (100k)\n  warmup_steps: 1000  # Initial warmup period (1k iterations)\n  \n  # Optimizer settings\n  optimizer: \"AdamW\"\n  scheduler: \"cosine\"  # Cosine learning rate scheduler\n  \n  # Data augmentation\n  noise_probability: 0.5  # Probability of adding Gaussian noise\n  noise_std: 0.01  # Standard deviation of Gaussian noise (mean=0, std=0.01)\n  \n  # Training strategy\n  training_mode: \"end_to_end\"  # Point cloud projector from scratch, LLM fine-tuned\n  loss_function: \"nll\"  # Negative Log-Likelihood loss\n\ndata:\n  # Dataset configuration\n  procedural_dataset:\n    size: 1000000  # 1 million procedurally generated CAD sequences\n    num_primitives_range: [3, 8]  # Number of primitives per sketch (Algorithm 1)\n    coordinate_range: [-100, 100]  # Parameter quantization range\n    coordinate_resolution: 1  # Minimum resolution for coordinates\n    \n  # Test datasets\n  datasets:\n    deepcad:\n      test_size: 8046  # Test set size\n      train_size: 160000  # Training set size when using DeepCAD data\n    fusion360:\n      test_size: 1725  # Test set size\n    cc3d:\n      test_size: 2973  # Real-world test set size\n  \n  # Point cloud processing\n  point_cloud:\n    num_sample_points: 8192  # Points for Chamfer Distance computation\n    normalization: \"unit_box\"  # Normalize to unit bounding box\n\nevaluation:\n  # Test-time sampling strategy from Section 4.3\n  num_candidates: 10  # Generate 10 different CAD code candidates\n  sampling_strategy: \"different_point_cloud_sampling\"\n  \n  # Metrics from paper Section 5.1\n  metrics:\n    chamfer_distance:\n      num_points: 8192  # Points for CD computation\n      scale_factor: 1000  # Multiply CD values by 10^3 as reported\n    intersection_over_union:\n      compute_from: \"meshes\"  # Compute IoU from resulting CAD model meshes\n    invalidity_ratio:\n      check_syntax: true  # \u03c6_syn validation\n      check_cad_semantics: true  # \u03c6_cad validation\n\n# Hardware and system configuration\nsystem:\n  device: \"cuda\"  # GPU training\n  mixed_precision: false  # Not specified in paper\n  num_workers: 4  # DataLoader workers\n  pin_memory: true\n\n# Logging and checkpointing\nlogging:\n  log_interval: 100  # Log every 100 iterations\n  save_interval: 5000  # Save checkpoint every 5000 iterations\n  wandb_project: \"cad-recode\"\n  \n# Paths\npaths:\n  data_dir: \"./data\"\n  checkpoints_dir: \"./checkpoints\"\n  results_dir: \"./results\"\n  logs_dir: \"./logs\"\n\n# CadQuery specific settings\ncadquery:\n  library_import: \"import cadquery as cq\"\n  validation_timeout: 30  # Timeout for code execution validation (seconds)\n  \n# Ablation study configurations\nablation:\n  point_cloud_sizes: [64, 128, 256]  # From Table 4 in paper\n  model_sizes: [\"Qwen/Qwen2-0.5B\", \"Qwen/Qwen2-1.5B\"]  # From ablation study\n  dataset_sizes: [160000, 1000000]  # DeepCAD size vs full procedural dataset\n```\n-----\n\n## Instruction\nConduct a Logic Analysis to assist in writing the code, based on the paper, the plan, the design, the task and the previously specified configuration file (config.yaml). \nYou DON'T need to provide the actual code yet; focus on a thorough, clear analysis.\n\nWrite the logic analysis in 'utils/fourier_encoding.py', which is intended for 'Implements Fourier positional encoding for 3D point coordinates as mentioned in the paper. Contains FourierEncoding class with encode() method that transforms 3D coordinates into higher-dimensional representations. This is a foundational component needed by the point cloud projector. Dependencies: torch, numpy. Critical for point cloud feature extraction.'.\n\n-----\n\n## Logic Analysis: utils/fourier_encoding.py"}, {"role": "assistant", "content": "# Logic Analysis: utils/fourier_encoding.py\n\n## 1. Purpose and Context\n\nThe `utils/fourier_encoding.py` module implements Fourier positional encoding for 3D point coordinates as a foundational component for the CAD-Recode point cloud projector. This encoding transforms raw 3D coordinates into higher-dimensional representations that help the neural network better understand spatial relationships and geometric patterns in point clouds.\n\n## 2. Paper Context and Requirements\n\n### 2.1 Paper References\n- **Section 4.2**: \"Fourier positional encoding [62] of coordinates\" as part of the point cloud projector pipeline\n- **Architecture**: Point cloud projector consists of: (1) furthest point sampling, (2) Fourier positional encoding, (3) linear projection\n- **Configuration**: From config.yaml - `fourier_encoding.num_freqs: 64` frequencies for encoding\n\n### 2.2 Mathematical Foundation\nBased on standard Fourier positional encoding literature (referenced as [62] in paper), the encoding typically follows:\n- For each coordinate dimension (x, y, z) and frequency index i:\n  - `sin(2^i * \u03c0 * coord)` and `cos(2^i * \u03c0 * coord)`\n- This creates a high-dimensional representation that captures both low and high-frequency spatial patterns\n\n## 3. Class Design and Interface\n\n### 3.1 FourierEncoding Class Structure\n```python\nclass FourierEncoding:\n    def __init__(self, num_freqs: int)\n    def encode(self, coords: torch.Tensor) -> torch.Tensor\n```\n\n### 3.2 Input/Output Specifications\n- **Input**: `coords` - torch.Tensor of shape `(batch_size, num_points, 3)` representing 3D coordinates\n- **Output**: torch.Tensor of shape `(batch_size, num_points, encoded_dim)` where `encoded_dim = 3 * 2 * num_freqs`\n- **Encoding Dimension**: Each 3D coordinate becomes `3 * 2 * num_freqs` dimensional (3 coords \u00d7 2 functions \u00d7 num_freqs)\n\n## 4. Implementation Logic\n\n### 4.1 Initialization Logic\n1. **Store Configuration**: Save `num_freqs` parameter from config\n2. **Frequency Generation**: Create frequency scales `2^i` for i in range(num_freqs)\n3. **Precompute Constants**: Store \u03c0 and other constants for efficiency\n4. **Device Handling**: Ensure frequency tensors are on correct device\n\n### 4.2 Encoding Logic\n1. **Input Validation**: \n   - Check input tensor shape (must be [..., 3] for 3D coordinates)\n   - Verify tensor is on correct device\n   - Handle batch dimensions properly\n\n2. **Frequency Application**:\n   - For each frequency scale f_i in [2^0, 2^1, ..., 2^(num_freqs-1)]\n   - For each coordinate dimension (x, y, z)\n   - Compute: `f_i * \u03c0 * coord`\n\n3. **Trigonometric Functions**:\n   - Apply sin() and cos() to scaled coordinates\n   - Result: 2 * num_freqs values per coordinate dimension\n   - Total: 3 * 2 * num_freqs values per point\n\n4. **Output Assembly**:\n   - Concatenate all encoded values along the last dimension\n   - Maintain original batch and point dimensions\n   - Return tensor of shape `(..., 3 * 2 * num_freqs)`\n\n### 4.3 Edge Cases and Error Handling\n1. **Input Validation**:\n   - Handle empty tensors gracefully\n   - Check for NaN/infinite coordinates\n   - Validate coordinate dimension is exactly 3\n\n2. **Device Consistency**:\n   - Ensure all computations happen on same device as input\n   - Handle CPU/GPU transfers if needed\n\n3. **Numerical Stability**:\n   - Handle potential overflow in high-frequency terms\n   - Consider coordinate normalization if needed\n\n## 5. Integration with Point Cloud Projector\n\n### 5.1 Usage in Pipeline\n```python\n# In PointCloudProjector.forward():\n# 1. Furthest point sampling -> (batch_size, 256, 3)\n# 2. Fourier encoding -> (batch_size, 256, 3*2*64) = (batch_size, 256, 384)\n# 3. Linear projection -> (batch_size, 256, 1536)\n```\n\n### 5.2 Configuration Integration\n- Read `num_freqs` from `config.model.fourier_encoding.num_freqs` (64)\n- Ensure consistency with point cloud projector expectations\n- Support different frequency counts for ablation studies\n\n## 6. Performance Considerations\n\n### 6.1 Computational Efficiency\n1. **Vectorized Operations**: Use torch operations for parallel computation\n2. **Memory Optimization**: Avoid unnecessary tensor copies\n3. **Batch Processing**: Handle arbitrary batch sizes efficiently\n\n### 6.2 Memory Usage\n- Input: `(batch_size, 256, 3)` - minimal memory\n- Output: `(batch_size, 256, 384)` - 128x expansion per coordinate\n- Consider memory implications for large batch sizes\n\n## 7. Testing and Validation\n\n### 7.1 Unit Tests\n1. **Shape Consistency**: Verify output dimensions match expected formula\n2. **Mathematical Correctness**: Test against known Fourier encoding implementations\n3. **Device Handling**: Test CPU/GPU consistency\n4. **Edge Cases**: Empty inputs, single points, large batches\n\n### 7.2 Integration Tests\n1. **Point Cloud Projector**: Ensure smooth integration with downstream components\n2. **Gradient Flow**: Verify backpropagation works correctly\n3. **Training Stability**: Check for numerical issues during training\n\n## 8. Dependencies and Imports\n\n### 8.1 Required Imports\n```python\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport math\nfrom typing import Optional\n```\n\n### 8.2 Dependency Justification\n- **torch**: Core tensor operations and neural network components\n- **numpy**: Mathematical constants and array operations if needed\n- **math**: Mathematical constants (\u03c0) and functions\n- **typing**: Type hints for better code documentation\n\n## 9. Configuration Parameters\n\n### 9.1 From config.yaml\n- `model.fourier_encoding.num_freqs: 64` - Number of frequency components\n- Potential future parameters:\n  - `scale_factor`: Coordinate scaling before encoding\n  - `learnable_freqs`: Whether to make frequencies learnable parameters\n\n### 9.2 Default Values\n- `num_freqs`: 64 (from paper configuration)\n- Frequency range: [2^0, 2^1, ..., 2^63] as powers of 2\n\n## 10. Error Handling Strategy\n\n### 10.1 Input Validation Errors\n- **ValueError**: For incorrect input shapes or dimensions\n- **TypeError**: For non-tensor inputs\n- **RuntimeError**: For device mismatch issues\n\n### 10.2 Numerical Issues\n- **Overflow Warning**: For very high frequency terms\n- **NaN Detection**: Check for invalid coordinate values\n- **Graceful Degradation**: Handle edge cases without crashing\n\n## 11. Future Extensions\n\n### 11.1 Potential Enhancements\n1. **Learnable Frequencies**: Make frequency scales trainable parameters\n2. **Adaptive Encoding**: Adjust encoding based on coordinate ranges\n3. **Alternative Functions**: Support other periodic functions beyond sin/cos\n4. **Coordinate Normalization**: Built-in coordinate preprocessing\n\n### 11.2 Ablation Study Support\n- Support different `num_freqs` values for experimental comparison\n- Easy parameter modification for hyperparameter tuning\n- Performance profiling hooks for optimization studies\n\nThis logic analysis provides a comprehensive foundation for implementing the Fourier encoding module that will serve as a critical component in the CAD-Recode point cloud processing pipeline, ensuring mathematical correctness, computational efficiency, and seamless integration with the overall architecture."}]